{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ef1489",
   "metadata": {},
   "source": [
    "# Economics 600a Fall 2025 Prof. P. Haile Homework Assignment 1\n",
    "\n",
    "## 1 Overview\n",
    "You will estimate demand and supply in a stylized model of the market for pay-TV services. You will use a matrix programming language of your choice to create your own fake data set for the industry and do some relatively simple estimation. Then, using the **pyBLP** package of Conlon and Gortmaker, you will estimate the model and perform some merger simulations.\n",
    "\n",
    "The pyBLP package has excellent documentation and a very helpful tutorial (which covers merger simulation), both easy to find via Google.\n",
    "\n",
    "Please submit (on canvas) a single PDF document presenting your answers to the questions below, requested results, and well documented code. Write this up nicely, with properly formatted tables and discussion of results. You may work in groups on the coding. However, your write-ups should be your own work, and you must describe all collaboration at the beginning of your submission; this includes any use of AI.\n",
    "\n",
    "## 2 Model\n",
    "There are $T$ markets, each with four inside goods $j \\in \\{1,2,3,4\\}$ and an outside option. Goods 1 and 2 are satellite television services (e.g., DirecTV and Dish); goods 3 and 4 are wired television services (e.g., Frontier and Comcast in New Haven). The conditional indirect utility of consumer $i$ for good $j$ in market $t$ is given by\n",
    "\n",
    "\\begin{align*}\n",
    "u_{ijt} &= \\beta^{(1)} x_{jt} + \\beta_i^{(2)} satellite_{jt} + \\beta_i^{(3)} wired_{jt} + \\alpha p_{jt} + \\xi_{jt} + \\epsilon_{ijt} \\quad j > 0 \\\\\n",
    "u_{i0t} &= \\epsilon_{i0t},\n",
    "\\end{align*}\n",
    "\n",
    "where $x_{jt}$ is a measure of good $j$'s quality, $p_{jt}$ is its price, $satellite_{jt}$ is an indicator equal to 1 for the two satellite services, and $wired_{jt}$ is an indicator equal to 1 for the two wired services. The remaining notation is as usual in the class notes, including the i.i.d. type-1 extreme value $\\epsilon_{ijt}$. Each consumer purchases the good giving them the highest conditional indirect utility.\n",
    "\n",
    "Goods are produced by single-product firms. Firm $j$'s (log) marginal cost in market $t$ is\n",
    "\n",
    "\\begin{equation*}\n",
    "\\ln mc_{jt} = \\gamma^{(0)} + w_{jt} \\gamma^{(1)} + \\omega_{jt}/8,\n",
    "\\end{equation*}\n",
    "\n",
    "where $w_{jt}$ is an observed cost shifter. Firms compete by simultaneously choosing prices in each market under complete information. Firm $j$ has profit\n",
    "\n",
    "\\begin{equation*}\n",
    "\\pi_{jt} = \\max_{p_{jt}} (p_{jt} - mc_{jt}) s_{jt}(p_t).\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ee1070",
   "metadata": {},
   "source": [
    "## 3 Generate Fake Data\n",
    "\n",
    "Generate a data set from the model above. Let\n",
    "\n",
    "\\begin{align*}\n",
    "\\beta^{(1)} &= 1, \\quad \\beta_i^{(k)} \\sim \\text{iid } N(4,1) \\text{ for } k=2,3 \\\\\n",
    "\\alpha &= -2 \\\\\n",
    "\\gamma^{(0)} &= 1/2, \\quad \\gamma^{(1)} = 1/4.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8744e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1.1.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "from scipy.special import logsumexp\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import time\n",
    "import IPython.display\n",
    "IPython.display.display(IPython.display.HTML('<style>pre { white-space: pre !important; }</style>'))\n",
    "import pyblp\n",
    "pyblp.options.digits = 3\n",
    "pd.options.display.precision = 3\n",
    "pd.options.display.max_columns = 50\n",
    "pyblp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12caa47",
   "metadata": {},
   "source": [
    "### 1. \n",
    "Draw the exogenous product characteristic $x_{jt}$ for $T=600$ geographically defined markets (e.g., cities). Assume each $x_{jt}$ is equal to the absolute value of an iid standard normal draw, as is each $w_{jt}$. Simulate demand and cost unobservables as well, specifying\n",
    "\n",
    "\\begin{equation*}\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "\\xi_{jt} \\\\\n",
    "\\omega_{jt}\n",
    "\\end{array}\n",
    "\\right) \\sim N\\left( \\left(\n",
    "\\begin{array}{c}\n",
    "0 \\\\\n",
    "0\n",
    "\\end{array}\n",
    "\\right), \\left(\n",
    "\\begin{array}{cc}\n",
    "1 & 0.25 \\\\\n",
    "0.25 & 1\n",
    "\\end{array}\n",
    "\\right) \\right) \\quad \\text{iid across } j,t.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9546c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 completed:\n",
      "Generated 2400 observations across 600 markets\n",
      "x range: 0.001 to 3.534\n",
      "w range: 0.000 to 3.621\n",
      "ξ-ω correlation: 0.240 (target: 0.25)\n",
      "Satellite products: 1200, Wired products: 1200\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1995)\n",
    "\n",
    "# Model parameters\n",
    "T, J = 600, 4\n",
    "alpha, beta1 = -2, 1\n",
    "beta2, beta3 = 4, 4  \n",
    "sigma_satellite, sigma_wired = 1, 1\n",
    "gamma0, gamma1 = 0.5, 0.25\n",
    "\n",
    "# Product data structure\n",
    "data = [\n",
    "    {'market_ids': t, 'firm_ids': j+1, 'product_ids': j} \n",
    "    for t in range(T) \n",
    "    for j in range(J)\n",
    "]\n",
    "product_data = pd.DataFrame(data)\n",
    "\n",
    "# Exogenous variables: x_jt and w_jt as absolute values of iid standard normal draws\n",
    "product_data['x'] = np.abs(\n",
    "    np.random.normal(0, 1, len(product_data))\n",
    ")\n",
    "product_data['w'] = np.abs(\n",
    "    np.random.normal(0, 1, len(product_data))\n",
    ")\n",
    "\n",
    "# Indicators\n",
    "product_data['satellite'] = (\n",
    "    product_data['firm_ids'].isin([1, 2]).astype(int)\n",
    ")\n",
    "product_data['wired'] = (\n",
    "    product_data['firm_ids'].isin([3, 4]).astype(int)\n",
    ")\n",
    "\n",
    "# Unobservables: ξ_jt and ω_jt with covariance matrix [[1, 0.25], [0.25, 1]]\n",
    "cov_matrix = np.array([[1, 0.25], [0.25, 1]])\n",
    "A = np.linalg.cholesky(cov_matrix)\n",
    "z = np.random.normal(0, 1, (len(product_data), 2))\n",
    "unobs = z @ A.T\n",
    "product_data['xi'] = unobs[:, 0]  # demand unobservable\n",
    "product_data['omega'] = unobs[:, 1]  # cost unobservable\n",
    "\n",
    "print(\"Question 1 completed:\")\n",
    "print(f\"Generated {len(product_data)} observations across {T} markets\")\n",
    "print(f'x range: {product_data[\"x\"].min():.3f} to {product_data[\"x\"].max():.3f}')\n",
    "print(f'w range: {product_data[\"w\"].min():.3f} to {product_data[\"w\"].max():.3f}')\n",
    "xi_omega_corr = product_data[['xi', 'omega']].corr().iloc[0,1]\n",
    "print(f\"ξ-ω correlation: {xi_omega_corr:.3f} (target: 0.25)\")\n",
    "sat_count = product_data[\"satellite\"].sum()\n",
    "wired_count = product_data[\"wired\"].sum()\n",
    "print(f\"Satellite products: {sat_count}, Wired products: {wired_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ed4c4c",
   "metadata": {},
   "source": [
    "### 2. Solve for the equilibrium prices for each good in each market.\n",
    "\n",
    "**(a)** Start by writing a procedure to approximate the derivatives of market shares with respect to prices (taking prices, shares, x, and demand parameters as inputs). The key steps are:\n",
    "\n",
    "(i) For each $jt$, write the choice probability for good $j$, $s_{jt}$, as a weighted average (integral) of the (multinomial logit) choice probabilities conditional on the value of each consumer's random coefficients;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693a0d7a",
   "metadata": {},
   "source": [
    "The market share for good $j$ in market $t$, $s_{jt}$, is the probability that a consumer chooses good $j$:\n",
    "\n",
    "$$s_{jt} = \\int P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)}) f(\\beta_i^{(2)}, \\beta_i^{(3)}) d\\beta_i^{(2)} d\\beta_i^{(3)}$$\n",
    "\n",
    "where $P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})$ is the multinomial logit choice probability conditional on the random coefficients.\n",
    "\n",
    "Given the random coefficients $\\beta_i^{(2)}$ and $\\beta_i^{(3)}$ (with means $\\beta^{(2)} = 4$, $\\beta^{(3)} = 4$ and variances $\\sigma_2^2 = 1$, $\\sigma_3^2 = 1$), the conditional utility becomes:\n",
    "\n",
    "$$u_{ijt} = \\beta^{(1)} x_{jt} + \\beta_i^{(2)} satellite_{jt} + \\beta_i^{(3)} wired_{jt} + \\alpha p_{jt} + \\xi_{jt} + \\epsilon_{ijt}$$\n",
    "\n",
    "Since $\\epsilon_{ijt}$ are i.i.d. Type-1 extreme value, the conditional choice probability follows the multinomial logit form:\n",
    "\n",
    "$$P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)}) = \\frac{\\exp(\\delta_{jt} + \\mu_{jt}^i)}{\\sum_{k=1}^J \\exp(\\delta_{kt} + \\mu_{kt}^i) + 1}$$\n",
    "\n",
    "where:\n",
    "- $\\delta_{jt} = \\beta^{(1)} x_{jt} + \\alpha p_{jt} + \\xi_{jt}$ (mean utility component)\n",
    "- $\\mu_{jt}^i = \\beta_i^{(2)} satellite_{jt} + \\beta_i^{(3)} wired_{jt}$ (random utility component)\n",
    "\n",
    "**Final Expression:**\n",
    "\n",
    "$$s_{jt} = \\int \\frac{\\exp(\\delta_{jt} + \\beta_i^{(2)} satellite_{jt} + \\beta_i^{(3)} wired_{jt})}{\\sum_{k=1}^J \\exp(\\delta_{kt} + \\beta_i^{(2)} satellite_{kt} + \\beta_i^{(3)} wired_{kt}) + 1} \\phi(\\beta_i^{(2)}, \\beta_i^{(3)}) d\\beta_i^{(2)} d\\beta_i^{(3)}$$\n",
    "\n",
    "where $\\phi(\\cdot, \\cdot)$ is the bivariate normal density with mean $(\\beta^{(2)}, \\beta^{(3)}) = (4, 4)$ and covariance matrix $\\text{diag}(1, 1)$.\n",
    "\n",
    "This integral is approximated in the code using Monte Carlo simulation with draws from the normal distribution of $(\\beta_i^{(2)}, \\beta_i^{(3)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfaf6df",
   "metadata": {},
   "source": [
    "(ii) Anticipating differentiation under the integral sign, derive the analytical expression for the derivative of the integrand with respect to each $p_{kt}$.\n",
    "\n",
    "The integrand is the conditional choice probability $P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})$, which depends on prices through the mean utility component $\\delta_{jt} = \\beta^{(1)} x_{jt} + \\alpha p_{jt} + \\xi_{jt}$.\n",
    "\n",
    "Since $p_{kt}$ appears in $\\delta_{kt}$, the derivative with respect to $p_{kt}$ affects the choice probability.\n",
    "\n",
    "For the multinomial logit model, the derivative of the choice probability with respect to a price is:\n",
    "\n",
    "$$\\frac{\\partial P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})}{\\partial p_{kt}} = \\alpha P(j|\\beta_i) \\left( I_{jk} - P(k|\\beta_i) \\right)$$\n",
    "\n",
    "where $I_{jk}$ is the indicator function equal to 1 if $j = k$.\n",
    "\n",
    "Therefore, the derivative of the integrand (conditional choice probability) with respect to $p_{kt}$ is:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial p_{kt}} \\left[ \\frac{\\exp(\\delta_{jt} + \\mu_{jt}^i)}{\\sum_{m=1}^J \\exp(\\delta_{mt} + \\mu_{mt}^i) + 1} \\right] = \\alpha \\cdot \\frac{\\exp(\\delta_{jt} + \\mu_{jt}^i)}{\\sum_{m=1}^J \\exp(\\delta_{mt} + \\mu_{mt}^i) + 1} \\left( I_{jk} - \\frac{\\exp(\\delta_{kt} + \\mu_{kt}^i)}{\\sum_{m=1}^J \\exp(\\delta_{mt} + \\mu_{mt}^i) + 1} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2c76a",
   "metadata": {},
   "source": [
    "3. Use the expression you obtained in (2) and simulation draws of the random coefficients to approximate the integral that corresponds to $\\partial s_{jt}/\\partial p_{kt}$ for each $j$ and $k$ (i.e., replace the integral with the mean over the values at each simulation draw). Recall the advice in the lecture regarding \"jittering.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24ba8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_shares_and_derivatives(prices, market_data, nu_draws):\n",
    "    \"\"\"\n",
    "    Compute shares, derivatives, and inside_shares_draws efficiently in one pass.\n",
    "    Returns: (shares, derivatives, inside_shares_draws)\n",
    "    \"\"\"\n",
    "    J = len(market_data)\n",
    "    x = market_data['x'].values\n",
    "    xi = market_data['xi'].values\n",
    "    sat = market_data['satellite'].values\n",
    "    wired = market_data['wired'].values\n",
    "    \n",
    "    # Compute utilities once\n",
    "    utilities = (\n",
    "        beta1 * x + xi + \n",
    "        nu_draws[:, 0:1] * sat + \n",
    "        nu_draws[:, 1:2] * wired + \n",
    "        alpha * prices\n",
    "    )\n",
    "    utilities = np.column_stack([utilities, np.zeros(nu_draws.shape[0])])\n",
    "    exp_u = np.exp(utilities - np.max(utilities, axis=1, keepdims=True))\n",
    "    choice_probs = exp_u / exp_u.sum(axis=1, keepdims=True)\n",
    "    inside_shares_draws = choice_probs[:, :J]\n",
    "    \n",
    "    # Shares: average over draws\n",
    "    shares = np.mean(inside_shares_draws, axis=0)\n",
    "    \n",
    "    # Derivatives: compute analytically from choice probabilities\n",
    "    derivatives = np.zeros((J, J))\n",
    "    for j in range(J):\n",
    "        for k in range(J):\n",
    "            indicator = float(j == k)\n",
    "            deriv_draws = (\n",
    "                alpha * inside_shares_draws[:, j] * \n",
    "                (indicator - inside_shares_draws[:, k])\n",
    "            )\n",
    "            derivatives[j, k] = np.mean(deriv_draws)\n",
    "    \n",
    "    return shares, derivatives, inside_shares_draws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc99991e",
   "metadata": {},
   "source": [
    "The derivative $\\partial s_{jt}/\\partial p_{kt}$ is approximated using Monte Carlo simulation. For each simulation draw $r = 1, \\dots, R$ of the random coefficients $(\\beta_i^{(2)}, \\beta_i^{(3)})$, compute the conditional choice probability $P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})$ and its derivative with respect to prices.\n",
    "\n",
    "The derivative of the conditional choice probability follows from the multinomial logit formula:\n",
    "\n",
    "$$\\frac{\\partial P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})}{\\partial p_{kt}} = \\alpha P(j|\\beta_i) \\left( \\delta_{jk} - P(k|\\beta_i) \\right)$$\n",
    "\n",
    "where $\\delta_{jk} = 1$ if $j = k` and 0 otherwise.\n",
    "\n",
    "Then, the market share derivative is approximated as:\n",
    "\n",
    "$$\\frac{\\partial s_{jt}}{\\partial p_{kt}} \\approx \\frac{1}{R} \\sum_{r=1}^R \\frac{\\partial P(\\text{choose } j | \\beta_i^{(2,r)}, \\beta_i^{(3,r)})}{\\partial p_{kt}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab755210",
   "metadata": {},
   "source": [
    "Regarding \"jittering\": When solving for equilibrium prices iteratively, redrawing simulation draws in each iteration introduces random noise that can prevent convergence. To avoid this, pre-draw a fixed set of simulation draws for each market and reuse them throughout the solution process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26550341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-draw simulation draws (to avoid jittering)\n",
    "np.random.seed(1995) \n",
    "n_draws = 10000\n",
    "all_nu_draws = [\n",
    "    np.random.multivariate_normal(\n",
    "        [beta2, beta3], \n",
    "        np.diag([sigma_satellite, sigma_wired]), \n",
    "        size=n_draws\n",
    "    ) \n",
    "    for _ in range(T)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1ed54",
   "metadata": {},
   "source": [
    "(iv) Experiment to see how many simulation draws you need to get precise approximations and check this again at the equilibrium shares and prices you obtained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ed79e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00804081, 0.00537121, 0.00372863, 0.00253488, 0.0016517 ,\n",
       "       0.00107223, 0.00052512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_convergence(prices, market_data, nu_draws_full, draw_counts, n_reps=100):\n",
    "    \"\"\"Test derivative stability across different numbers of simulation draws.\"\"\"\n",
    "    np.random.seed(1995) \n",
    "    stds = []\n",
    "    n_available = len(nu_draws_full)\n",
    "    \n",
    "    for n_draws in draw_counts:\n",
    "        deriv_list = []\n",
    "        for rep in range(n_reps):\n",
    "            # Randomly sample n_draws from the pre-drawn samples\n",
    "            indices = np.random.choice(n_available, size=n_draws, replace=False)\n",
    "            nu_draws = nu_draws_full[indices]\n",
    "            _, derivs, _ = market_shares_and_derivatives(\n",
    "                prices, market_data, nu_draws\n",
    "            )\n",
    "            deriv_list.append(derivs)\n",
    "        stds.append(np.std(deriv_list, axis=0).mean())\n",
    "    return np.array(stds)\n",
    "\n",
    "# Test at initial prices (p = MC)\n",
    "product_data['mc'] = np.exp(\n",
    "    gamma0 + gamma1 * product_data['w'] + product_data['omega'] / 8\n",
    ")\n",
    "# Test at initial prices (p = MC) for market 0\n",
    "market_0 = product_data[product_data['market_ids'] == 0]\n",
    "prices_init = market_0['mc'].values\n",
    "draw_counts = [50, 100, 200, 500, 1000, 2000, 5000]\n",
    "stds = test_convergence(prices_init, market_0, all_nu_draws[0], draw_counts)\n",
    "stds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5aa25a",
   "metadata": {},
   "source": [
    "(b) The FOC for firm $j$'s profit maximization problem in market $t$ is\n",
    "\n",
    "\\begin{align}\n",
    "(p_{jt} - mc_{jt}) \\frac{\\partial s_{jt}}{\\partial p_{jt}} + s_{jt} &= 0 \\notag \\\\\n",
    "\\implies p_{jt} - mc_{jt} &= -\\left( \\frac{\\partial s_{jt}}{\\partial p_{jt}} \\right)^{-1} s_{jt}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59c91cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC range: 1.135 to 4.652\n",
      "MC mean: 2.058, median: 1.994\n",
      "FOC: (p_jt - mc_jt) * ∂s_jt/∂p_jt + s_jt = 0\n",
      "Rearranged: p_jt - mc_jt = - (∂s_jt/∂p_jt)⁻¹ * s_jt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"MC range: {product_data['mc'].min():.3f} to {product_data['mc'].max():.3f}\")\n",
    "print(f\"MC mean: {product_data['mc'].mean():.3f}, median: {product_data['mc'].median():.3f}\")\n",
    "print(\"FOC: (p_jt - mc_jt) * ∂s_jt/∂p_jt + s_jt = 0\")\n",
    "print(\"Rearranged: p_jt - mc_jt = - (∂s_jt/∂p_jt)⁻¹ * s_jt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4676b052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(product_data['mc'], bins=50);\n",
    "plt.legend([\"Marginal Costs\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5bec32",
   "metadata": {},
   "source": [
    "(c) Substituting in your approximation of each $\\partial s_{jt}/\\partial p_{jt}$, solve the system of equations above ($J$ equations per market) for the equilibrium prices in each market.\n",
    "\n",
    "**i.** First do this using Matlab's \"fsolve\" operator. Check the exit flag from fsolve to be sure whether you found a solution for each market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36519e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2(c)i completed:\n",
      "Direct nonlinear solver (root): 600/600 markets solved successfully\n",
      "Success rate: 100.0%\n",
      "Price range: 2.346 to 5.698\n",
      "Price mean: 3.318, std: 0.435\n"
     ]
    }
   ],
   "source": [
    "def solve_prices_direct(market_data, mc_market, nu_draws):\n",
    "    \"\"\"Solve for equilibrium prices using direct nonlinear solver with robust matrix inversion\"\"\"\n",
    "    J = len(market_data)\n",
    "    \n",
    "    def foc_residual(prices):\n",
    "        \"\"\"FOC residuals: p - mc + (∂s/∂p)^{-1} s = 0\"\"\"\n",
    "        # Compute shares and derivatives at current prices\n",
    "        shares, derivatives, _ = market_shares_and_derivatives(\n",
    "            prices, market_data, nu_draws\n",
    "        )\n",
    "\n",
    "        # Inversion of derivative matrix\n",
    "        invD = np.linalg.inv(derivatives)\n",
    "\n",
    "        # FOC residuals: p - mc + inv(∂s/∂p) @ s\n",
    "        residuals = prices - mc_market + invD @ shares\n",
    "        return residuals\n",
    "    # Initial guess: marginal costs\n",
    "    p0 = mc_market.copy()\n",
    "    # Solve using root finder (hybr method)\n",
    "    sol = opt.root(foc_residual, p0, method='hybr', tol=1e-8)\n",
    "    prices_sol = sol.x\n",
    "    success = sol.success\n",
    "    # Additional check: verify that residuals are small\n",
    "    final_residuals = foc_residual(prices_sol)\n",
    "    if np.max(np.abs(final_residuals)) > 1e-6:\n",
    "        success = False\n",
    "    return prices_sol, success\n",
    "\n",
    "# Solve using direct method\n",
    "equilibrium_prices_direct = []\n",
    "success_flags_direct = []\n",
    "for t in range(T):\n",
    "    market_data = product_data[product_data['market_ids'] == t]\n",
    "    mc_market = market_data['mc'].values\n",
    "    nu_draws = all_nu_draws[t]\n",
    "    prices_direct, success = solve_prices_direct(\n",
    "        market_data, mc_market, nu_draws\n",
    "    )\n",
    "    equilibrium_prices_direct.append(prices_direct)\n",
    "    success_flags_direct.append(success)\n",
    "equilibrium_prices_direct = np.array(equilibrium_prices_direct)\n",
    "success_count = sum(success_flags_direct)\n",
    "print(\"Question 2(c)i completed:\")\n",
    "print(f\"Direct nonlinear solver (root): {success_count}/{T} markets solved successfully\")\n",
    "print(f\"Success rate: {success_count/T:.1%}\")\n",
    "price_range_text = (\n",
    "    f\"Price range: {equilibrium_prices_direct.min():.3f} to \"\n",
    "    f\"{equilibrium_prices_direct.max():.3f}\"\n",
    ")\n",
    "print(price_range_text)\n",
    "price_stats_text = (\n",
    "    f\"Price mean: {equilibrium_prices_direct.mean():.3f}, \"\n",
    "    f\"std: {equilibrium_prices_direct.std():.3f}\"\n",
    ")\n",
    "print(price_stats_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca3eea",
   "metadata": {},
   "source": [
    "ii. Do this again using the algorithm of Morrow and Skerlos (2011), discussed in section 3.6 of Conlon and Gortmaker (2019) (and in the pyBLP \"problem simulation tutorial\"). Use the numerical integration approach you used in step (a) to approximate the terms defined in equation (25) of Conlon and Gortmaker. If you get different results using this method, resolve this discrepancy either by correcting your code or explaining why your preferred method is the one to be trusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eba70d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2(c)ii completed:\n",
      "Morrow-Skerlos method: 600 markets solved\n",
      "Average iterations: 27.9\n",
      "Max iterations: 36\n",
      "Price range: 2.346 to 5.698\n",
      "Price mean: 3.318, std: 0.435\n",
      "Max price difference between methods: 4.52e-06\n",
      "Mean price difference: 1.28e-06\n"
     ]
    }
   ],
   "source": [
    "def solve_prices_morrow_skerlos(market_data, mc_market, nu_draws, max_iter=100, tol=1e-6):\n",
    "    \"\"\"Morrow-Skerlos algorithm\"\"\"\n",
    "    prices = mc_market.copy()\n",
    "    for iteration in range(max_iter):\n",
    "        # Efficiently compute shares, derivatives, and inside_shares_draws in one pass\n",
    "        shares, derivatives, inside_shares_draws = market_shares_and_derivatives(prices, market_data, nu_draws)\n",
    "        \n",
    "        Lambda = np.diag(alpha * shares)\n",
    "        Gamma = alpha * (inside_shares_draws.T @ inside_shares_draws) / nu_draws.shape[0]\n",
    "        diff = prices - mc_market\n",
    "        zeta = np.linalg.solve(Lambda, Gamma.T @ diff - shares)\n",
    "        prices_new = mc_market + zeta\n",
    "        foc_residual = Lambda @ (prices - mc_market - zeta)\n",
    "        if np.max(np.abs(foc_residual)) < tol:\n",
    "            break\n",
    "        prices = 0.5 * prices + 0.5 * prices_new\n",
    "    return prices, iteration + 1\n",
    "\n",
    "# Solve using Morrow-Skerlos method\n",
    "equilibrium_prices_ms = []\n",
    "iterations_ms = []\n",
    "\n",
    "for t in range(T):\n",
    "    market_data = product_data[product_data['market_ids'] == t]\n",
    "    mc_market = market_data['mc'].values\n",
    "    nu_draws = all_nu_draws[t]\n",
    "\n",
    "    prices_ms, iters = solve_prices_morrow_skerlos(market_data, mc_market, nu_draws)\n",
    "    equilibrium_prices_ms.append(prices_ms)\n",
    "    iterations_ms.append(iters)\n",
    "\n",
    "equilibrium_prices_ms = np.array(equilibrium_prices_ms)\n",
    "print(\"Question 2(c)ii completed:\")\n",
    "print(f\"Morrow-Skerlos method: {T} markets solved\")\n",
    "print(f\"Average iterations: {np.mean(iterations_ms):.1f}\")\n",
    "print(f\"Max iterations: {np.max(iterations_ms)}\")\n",
    "print(f\"Price range: {equilibrium_prices_ms.min():.3f} to {equilibrium_prices_ms.max():.3f}\")\n",
    "print(f\"Price mean: {equilibrium_prices_ms.mean():.3f}, std: {equilibrium_prices_ms.std():.3f}\")\n",
    "\n",
    "# Compare direct vs Morrow-Skerlos if direct succeeded for all\n",
    "if len(equilibrium_prices_direct) == T:\n",
    "    price_diff = np.abs(np.array(equilibrium_prices_direct) - equilibrium_prices_ms)\n",
    "    print(f\"Max price difference between methods: {price_diff.max():.2e}\")\n",
    "    print(f\"Mean price difference: {price_diff.mean():.2e}\")\n",
    "else:\n",
    "    print(\"Direct method failed for some markets, skipsigmang comparison.\")\n",
    "    print(\"Preferred method: Morrow-Skerlos, as it is more numerically stable.\")\n",
    "\n",
    "# Use Morrow-Skerlos prices\n",
    "product_data['prices'] = equilibrium_prices_ms.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b39f6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing derivative approximation convergence:\n",
      "Draws\t| Initial Std Dev\t| Equilibrium Std Dev\t| Ratio (Eq/Init)\n",
      "---------------------------------------------------------------------------\n",
      "    50\t| 8.04e-03\t\t| 5.33e-03\t\t| 0.66\n",
      "   100\t| 5.37e-03\t\t| 3.63e-03\t\t| 0.68\n",
      "   200\t| 3.73e-03\t\t| 2.65e-03\t\t| 0.71\n",
      "   500\t| 2.53e-03\t\t| 1.72e-03\t\t| 0.68\n",
      "  1000\t| 1.65e-03\t\t| 1.14e-03\t\t| 0.69\n",
      "  2000\t| 1.07e-03\t\t| 7.24e-04\t\t| 0.68\n",
      "  5000\t| 5.25e-04\t\t| 3.53e-04\t\t| 0.67\n"
     ]
    }
   ],
   "source": [
    "    # Compare derivative convergence at initial vs equilibrium prices\n",
    "    market_0 = product_data[product_data['market_ids'] == 0]\n",
    "    prices_equilibrium = market_0['prices'].values\n",
    "\n",
    "    draw_counts = [50, 100, 200, 500, 1000, 2000, 5000]\n",
    "    # Reuse previously calculated initial_stds from test_convergence\n",
    "    initial_stds = stds  # Already calculated earlier at initial prices\n",
    "    \n",
    "    # Only compute equilibrium stds\n",
    "    np.random.seed(1995)\n",
    "    n_available = len(all_nu_draws[0])\n",
    "    n_reps = 100\n",
    "    eq_stds = []\n",
    "    for n_draws in draw_counts:\n",
    "        deriv_list = []\n",
    "        for _ in range(n_reps):\n",
    "            indices = np.random.choice(n_available, size=n_draws, replace=False)\n",
    "            nu_draws = all_nu_draws[0][indices]\n",
    "            _, derivatives, _ = market_shares_and_derivatives(\n",
    "                prices_equilibrium, market_0, nu_draws\n",
    "            )\n",
    "            deriv_list.append(derivatives)\n",
    "        eq_stds.append(np.std(deriv_list, axis=0).mean())\n",
    "    eq_stds = np.array(eq_stds)\n",
    "\n",
    "    print(\"Comparing derivative approximation convergence:\")\n",
    "    print(\"Draws\\t| Initial Std Dev\\t| Equilibrium Std Dev\\t| Ratio (Eq/Init)\")\n",
    "    print(\"-\" * 75)\n",
    "\n",
    "    for i, n_draws in enumerate(draw_counts):\n",
    "        ratio = eq_stds[i] / initial_stds[i] if initial_stds[i] > 0 else float('inf')\n",
    "        print(f\"{n_draws:6d}\\t| {initial_stds[i]:.2e}\\t\\t| {eq_stds[i]:.2e}\\t\\t| {ratio:.2f}\")\n",
    "\n",
    "    # Summary statistics\n",
    "    valid_ratios = eq_stds / initial_stds\n",
    "    avg_ratio = np.mean(valid_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c19e4",
   "metadata": {},
   "source": [
    "### 3. \n",
    "Calculate \"observed\" market shares for your fake data set using your parameters, your draws of $x$, $w$, $\\xi$, $\\omega$, and your equilibrium prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f40eeb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share range: 0.000 to 0.724\n",
      "Share mean: 0.136, std: 0.122\n",
      "Market share sums (should be < 1):\n",
      "Average: 0.543\n",
      "Min: 0.307, Max: 0.745\n",
      "Outside shares: 0.457 (average)\n",
      "Average satellite product share: 0.135\n",
      "Average wired product share: 0.136\n"
     ]
    }
   ],
   "source": [
    "observed_shares = []\n",
    "for t in range(T):\n",
    "    market_data = product_data[product_data['market_ids'] == t]\n",
    "    prices_market = market_data['prices'].values\n",
    "    # Use pre-drawn simulation draws for this market\n",
    "    shares_market, _, _ = market_shares_and_derivatives(\n",
    "        prices_market, market_data, all_nu_draws[t]\n",
    "    )\n",
    "    observed_shares.extend(shares_market)\n",
    "\n",
    "product_data['shares'] = observed_shares\n",
    "\n",
    "print(f\"Share range: {product_data['shares'].min():.3f} to {product_data['shares'].max():.3f}\")\n",
    "print(f\"Share mean: {product_data['shares'].mean():.3f}, std: {product_data['shares'].std():.3f}\")\n",
    "\n",
    "# Validation: Check market share sums\n",
    "market_share_sums = product_data.groupby('market_ids')['shares'].sum()\n",
    "print(f\"Market share sums (should be < 1):\")\n",
    "print(f\"Average: {market_share_sums.mean():.3f}\")\n",
    "print(f\"Min: {market_share_sums.min():.3f}, Max: {market_share_sums.max():.3f}\")\n",
    "print(f\"Outside shares: {1 - market_share_sums.mean():.3f} (average)\")\n",
    "\n",
    "# Check by product type\n",
    "satellite_shares = product_data[product_data['satellite'] == 1]['shares'].mean()\n",
    "wired_shares = product_data[product_data['wired'] == 1]['shares'].mean()\n",
    "print(f\"Average satellite product share: {satellite_shares:.3f}\")\n",
    "print(f\"Average wired product share: {wired_shares:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95915201",
   "metadata": {},
   "source": [
    "### 4. \n",
    "\n",
    "Below you'll be using $x$ and $w$ as instruments in the demand estimation. Check whether these appear to be good instruments in your fake data using some regressions of prices and market shares on the exogenous variables (or some function of them; see the related discussion in the coding tips). If you believe the instruments are not providing enough variation, modify the parameter choices above until you are satisfied. Report your final choice of parameters and the results you rely on to conclude that the instruments seem good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e641c80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "INSTRUMENT VALIDITY TESTS\n",
      "===========================================================================\n",
      "\n",
      "1. Price Regression (Relevance Test)\n",
      "   R²: 0.511\n",
      "   Individual Coefficients:\n",
      "     satellite         :    2.845 (SE: 0.031, t:  92.41, p: 0.000)\n",
      "     wired             :    2.849 (SE: 0.031, t:  92.90, p: 0.000)\n",
      "     x                 :    0.071 (SE: 0.034, t:   2.09, p: 0.037)\n",
      "     w                 :    0.344 (SE: 0.034, t:  10.22, p: 0.000)\n",
      "     x**2              :    0.037 (SE: 0.013, t:   2.77, p: 0.006)\n",
      "     w**2              :    0.093 (SE: 0.013, t:   7.08, p: 0.000)\n",
      "     x*w               :   -0.085 (SE: 0.018, t:  -4.64, p: 0.000)\n",
      "     sum_x_competitors :    0.055 (SE: 0.007, t:   7.41, p: 0.000)\n",
      "     sum_w_competitors :   -0.035 (SE: 0.008, t:  -4.61, p: 0.000)\n",
      "     x_other_in_nest   :    0.050 (SE: 0.013, t:   3.87, p: 0.000)\n",
      "     w_other_in_nest   :   -0.031 (SE: 0.013, t:  -2.36, p: 0.018)\n",
      "   Excluded demand instruments F-stat: 300.86 (p=0.00e+00)\n",
      "   → Excluded instruments are relevant for prices\n",
      "\n",
      "2. Share Regression (Relevance Test)\n",
      "   R²: 0.364\n",
      "   Individual Coefficients:\n",
      "     satellite         :    0.127 (SE: 0.010, t:  12.81, p: 0.000)\n",
      "     wired             :    0.130 (SE: 0.010, t:  13.22, p: 0.000)\n",
      "     x                 :    0.083 (SE: 0.011, t:   7.56, p: 0.000)\n",
      "     w                 :   -0.069 (SE: 0.011, t:  -6.42, p: 0.000)\n",
      "     x**2              :    0.015 (SE: 0.004, t:   3.54, p: 0.000)\n",
      "     w**2              :    0.011 (SE: 0.004, t:   2.71, p: 0.007)\n",
      "     x*w               :   -0.034 (SE: 0.006, t:  -5.81, p: 0.000)\n",
      "     sum_x_competitors :   -0.019 (SE: 0.002, t:  -7.81, p: 0.000)\n",
      "     sum_w_competitors :    0.013 (SE: 0.002, t:   5.52, p: 0.000)\n",
      "     x_other_in_nest   :   -0.007 (SE: 0.004, t:  -1.56, p: 0.119)\n",
      "     w_other_in_nest   :    0.013 (SE: 0.004, t:   3.07, p: 0.002)\n",
      "   Excluded demand instruments F-stat: 91.03 (p=3.41e-132)\n",
      "   → Excluded instruments are relevant for shares\n",
      "\n",
      "3. ξ Regression (Exclusion Test)\n",
      "   R²: 0.003\n",
      "   Individual Coefficients:\n",
      "     satellite         :   -0.054 (SE: 0.103, t:  -0.52, p: 0.603)\n",
      "     wired             :   -0.010 (SE: 0.103, t:  -0.10, p: 0.923)\n",
      "     x                 :   -0.072 (SE: 0.114, t:  -0.63, p: 0.527)\n",
      "     w                 :    0.076 (SE: 0.113, t:   0.68, p: 0.500)\n",
      "     x**2              :    0.046 (SE: 0.045, t:   1.02, p: 0.306)\n",
      "     w**2              :   -0.013 (SE: 0.044, t:  -0.29, p: 0.773)\n",
      "     x*w               :   -0.048 (SE: 0.061, t:  -0.79, p: 0.428)\n",
      "     sum_x_competitors :   -0.021 (SE: 0.025, t:  -0.86, p: 0.388)\n",
      "     sum_w_competitors :    0.003 (SE: 0.025, t:   0.12, p: 0.904)\n",
      "     x_other_in_nest   :   -0.004 (SE: 0.044, t:  -0.08, p: 0.934)\n",
      "     w_other_in_nest   :    0.047 (SE: 0.044, t:   1.08, p: 0.282)\n",
      "   Excluded demand instruments F-stat: 0.63 (p=7.53e-01)\n",
      "   → Excluded instruments are exogenous\n",
      "\n",
      "4. ω Regression (Exclusion Test)\n",
      "   R²: 0.003\n",
      "   Individual Coefficients:\n",
      "     satellite         :    0.100 (SE: 0.102, t:   0.98, p: 0.330)\n",
      "     wired             :    0.101 (SE: 0.102, t:   0.99, p: 0.321)\n",
      "     x                 :   -0.040 (SE: 0.113, t:  -0.35, p: 0.726)\n",
      "     w                 :   -0.029 (SE: 0.112, t:  -0.26, p: 0.798)\n",
      "     x**2              :    0.009 (SE: 0.045, t:   0.21, p: 0.836)\n",
      "     w**2              :    0.007 (SE: 0.044, t:   0.15, p: 0.878)\n",
      "     x*w               :   -0.041 (SE: 0.060, t:  -0.68, p: 0.496)\n",
      "     sum_x_competitors :   -0.031 (SE: 0.025, t:  -1.26, p: 0.207)\n",
      "     sum_w_competitors :   -0.002 (SE: 0.025, t:  -0.07, p: 0.941)\n",
      "     x_other_in_nest   :    0.057 (SE: 0.043, t:   1.31, p: 0.189)\n",
      "     w_other_in_nest   :   -0.012 (SE: 0.043, t:  -0.29, p: 0.776)\n",
      "   Excluded demand instruments F-stat: 0.58 (p=7.99e-01)\n",
      "   → Excluded instruments are exogenous\n",
      "\n",
      "===========================================================================\n",
      "FINAL PARAMETER CHOICE:\n",
      "===========================================================================\n",
      "Demand: α = -2, β^(1) = 1, β_i^(2) ~ N(4, 1²), β_i^(3) ~ N(4, 1²)\n",
      "Supply: γ^(0) = 0.5, γ^(1) = 0.25\n",
      "These parameters generate data with valid instruments and are retained as final.\n"
     ]
    }
   ],
   "source": [
    "# Create quadratic and interaction columns first\n",
    "product_data['x**2'] = product_data['x'] ** 2\n",
    "product_data['w**2'] = product_data['w'] ** 2\n",
    "product_data['x*w'] = product_data['x'] * product_data['w']\n",
    "\n",
    "# sum over competing goods in market t\n",
    "product_data['sum_x_competitors'] = (\n",
    "    product_data.groupby('market_ids')['x'].transform('sum') - \n",
    "    product_data['x']\n",
    ")\n",
    "product_data['sum_w_competitors'] = (\n",
    "    product_data.groupby('market_ids')['w'].transform('sum') - \n",
    "    product_data['w']\n",
    ")\n",
    "\n",
    "# index of the other good in the same nest\n",
    "product_data['x_other_in_nest'] = (\n",
    "    product_data.groupby(['market_ids', 'satellite'])['x'].transform('sum') - \n",
    "    product_data['x']\n",
    ")\n",
    "product_data['w_other_in_nest'] = (\n",
    "    product_data.groupby(['market_ids', 'satellite'])['w'].transform('sum') - \n",
    "    product_data['w']\n",
    ")\n",
    "\n",
    "# Use satellite and wired dummies instead of constant\n",
    "Z = product_data[[\n",
    "    'satellite', 'wired', 'x', 'w', 'x**2', 'w**2', 'x*w', \n",
    "    'sum_x_competitors', 'sum_w_competitors', 'x_other_in_nest', 'w_other_in_nest'\n",
    "]]\n",
    "\n",
    "# Regression 1: Prices on extended instruments (Relevance check)\n",
    "price_model = sm.OLS(product_data['prices'], Z).fit()\n",
    "\n",
    "# Regression 2: Market shares on extended instruments\n",
    "share_model = sm.OLS(product_data['shares'], Z).fit()\n",
    "\n",
    "# Regression 3: Demand unobservable ξ on instruments (Exclusion check)\n",
    "xi_model = sm.OLS(product_data['xi'], Z).fit()\n",
    "\n",
    "# Regression 4: Cost unobservable ω on instruments (Exclusion check)\n",
    "omega_model = sm.OLS(product_data['omega'], Z).fit()\n",
    "\n",
    "# Test joint significance of excluded instruments\n",
    "print(\"=\"*75)\n",
    "print(\"INSTRUMENT VALIDITY TESTS\")\n",
    "print(\"=\"*75)\n",
    "excluded_vars = ['w', 'x**2', 'w**2', 'x*w', \n",
    "                 'sum_x_competitors', 'sum_w_competitors', \n",
    "                 'x_other_in_nest', 'w_other_in_nest']\n",
    "\n",
    "# Create hypothesis string using actual variable names\n",
    "hypothesis = ', '.join([f'{var}=0' for var in excluded_vars])\n",
    "\n",
    "# F-test for excluded instruments in price regression\n",
    "price_f_test = price_model.f_test(hypothesis)\n",
    "print(f\"\\n1. Price Regression (Relevance Test)\")\n",
    "print(f\"   R²: {price_model.rsquared:.3f}\")\n",
    "print(f\"   Individual Coefficients:\")\n",
    "for i, var in enumerate(Z.columns):\n",
    "    print(f\"     {var:18s}: {price_model.params.iloc[i]:8.3f} (SE: {price_model.bse.iloc[i]:.3f}, t: {price_model.tvalues.iloc[i]:6.2f}, p: {price_model.pvalues.iloc[i]:.3f})\")\n",
    "print(f\"   Excluded demand instruments F-stat: {price_f_test.fvalue:.2f} (p={price_f_test.pvalue:.2e})\")\n",
    "print(f\"   → Excluded instruments are {'relevant' if price_f_test.pvalue < 0.01 else 'weak'} for prices\")\n",
    "\n",
    "# F-test for excluded instruments in share regression\n",
    "share_f_test = share_model.f_test(hypothesis)\n",
    "print(f\"\\n2. Share Regression (Relevance Test)\")\n",
    "print(f\"   R²: {share_model.rsquared:.3f}\")\n",
    "print(f\"   Individual Coefficients:\")\n",
    "for i, var in enumerate(Z.columns):\n",
    "    print(f\"     {var:18s}: {share_model.params.iloc[i]:8.3f} (SE: {share_model.bse.iloc[i]:.3f}, t: {share_model.tvalues.iloc[i]:6.2f}, p: {share_model.pvalues.iloc[i]:.3f})\")\n",
    "print(f\"   Excluded demand instruments F-stat: {share_f_test.fvalue:.2f} (p={share_f_test.pvalue:.2e})\")\n",
    "print(f\"   → Excluded instruments are {'relevant' if share_f_test.pvalue < 0.01 else 'weak'} for shares\")\n",
    "\n",
    "# F-test for excluded instruments in xi regression (should be insignificant)\n",
    "xi_f_test = xi_model.f_test(hypothesis)\n",
    "print(f\"\\n3. ξ Regression (Exclusion Test)\")\n",
    "print(f\"   R²: {xi_model.rsquared:.3f}\")\n",
    "print(f\"   Individual Coefficients:\")\n",
    "for i, var in enumerate(Z.columns):\n",
    "    print(f\"     {var:18s}: {xi_model.params.iloc[i]:8.3f} (SE: {xi_model.bse.iloc[i]:.3f}, t: {xi_model.tvalues.iloc[i]:6.2f}, p: {xi_model.pvalues.iloc[i]:.3f})\")\n",
    "print(f\"   Excluded demand instruments F-stat: {xi_f_test.fvalue:.2f} (p={xi_f_test.pvalue:.2e})\")\n",
    "print(f\"   → Excluded instruments are {'exogenous' if xi_f_test.pvalue >= 0.01 else 'endogenous'}\")\n",
    "\n",
    "# F-test for excluded instruments in omega regression (should be insignificant)\n",
    "omega_f_test = omega_model.f_test(hypothesis)\n",
    "print(f\"\\n4. ω Regression (Exclusion Test)\")\n",
    "print(f\"   R²: {omega_model.rsquared:.3f}\")\n",
    "print(f\"   Individual Coefficients:\")\n",
    "for i, var in enumerate(Z.columns):\n",
    "    print(f\"     {var:18s}: {omega_model.params.iloc[i]:8.3f} (SE: {omega_model.bse.iloc[i]:.3f}, t: {omega_model.tvalues.iloc[i]:6.2f}, p: {omega_model.pvalues.iloc[i]:.3f})\")\n",
    "print(f\"   Excluded demand instruments F-stat: {omega_f_test.fvalue:.2f} (p={omega_f_test.pvalue:.2e})\")\n",
    "print(f\"   → Excluded instruments are {'exogenous' if omega_f_test.pvalue >= 0.01 else 'endogenous'}\")\n",
    "\n",
    "# Assess instrument validity\n",
    "weak_instruments = (\n",
    "    (price_model.f_pvalue >= 0.01 and share_model.f_pvalue >= 0.01) or \n",
    "    (price_model.rsquared < 0.05 and share_model.rsquared < 0.05)\n",
    ")\n",
    "excluded_instruments = (\n",
    "    xi_model.f_pvalue < 0.01 or omega_model.f_pvalue < 0.01\n",
    ")\n",
    "print()\n",
    "print(\"=\"*75)\n",
    "print(\"FINAL PARAMETER CHOICE:\")\n",
    "print(\"=\"*75)\n",
    "if weak_instruments or excluded_instruments:\n",
    "    print(\"Parameters need adjustment - instruments are weak or invalid.\")\n",
    "else:\n",
    "    print(f\"Demand: α = {alpha}, β^(1) = {beta1}, β_i^(2) ~ N({beta2}, {sigma_satellite}²), β_i^(3) ~ N({beta3}, {sigma_wired}²)\")\n",
    "    print(f\"Supply: γ^(0) = {gamma0}, γ^(1) = {gamma1}\")\n",
    "    print(\"These parameters generate data with valid instruments and are retained as final.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00bc00c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   market_ids  firm_ids  product_ids      x      w  satellite  wired     xi  \\\n",
      "0           0         1            0  1.241  0.919          1      0 -0.629   \n",
      "1           0         2            1  1.471  2.068          1      0  1.005   \n",
      "2           0         3            2  2.101  0.009          0      1 -2.595   \n",
      "3           0         4            3  1.465  2.114          0      1 -0.403   \n",
      "4           1         1            0  0.818  1.106          1      0  0.846   \n",
      "5           1         2            1  1.057  0.265          1      0 -1.792   \n",
      "6           1         3            2  1.535  0.750          0      1  0.082   \n",
      "7           1         4            3  0.614  0.576          0      1 -0.624   \n",
      "\n",
      "   omega     mc  prices  shares   x**2       w**2    x*w  sum_x_competitors  \\\n",
      "0  0.676  2.258   3.466   0.052  1.539  8.452e-01  1.141              5.037   \n",
      "1 -1.620  2.258   3.467   0.333  2.163  4.278e+00  3.042              4.807   \n",
      "2  0.954  1.862   2.990   0.055  4.415  7.799e-05  0.019              4.176   \n",
      "3 -1.056  2.451   3.579   0.080  2.146  4.471e+00  3.097              4.812   \n",
      "4  0.646  2.357   3.583   0.131  0.669  1.224e+00  0.905              3.206   \n",
      "5  1.172  2.040   3.266   0.022  1.117  7.032e-02  0.280              2.967   \n",
      "6 -1.506  1.647   2.957   0.357  2.356  5.623e-01  1.151              2.489   \n",
      "7 -0.245  1.847   3.156   0.047  0.377  3.317e-01  0.354              3.410   \n",
      "\n",
      "   sum_w_competitors  x_other_in_nest  w_other_in_nest  \n",
      "0              4.192            1.471            2.068  \n",
      "1              3.043            1.241            0.919  \n",
      "2              5.102            1.465            2.114  \n",
      "3              2.997            2.101            0.009  \n",
      "4              1.591            1.057            0.265  \n",
      "5              2.432            0.818            1.106  \n",
      "6              1.948            0.614            0.576  \n",
      "7              2.122            1.535            0.750  \n"
     ]
    }
   ],
   "source": [
    "product_data.to_csv('blp.csv', index=False)\n",
    "print(product_data.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cc0d1c",
   "metadata": {},
   "source": [
    "## 4 Estimate Some Mis-specified Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df5711",
   "metadata": {},
   "source": [
    "### 5. Estimate the plain multinomial logit model of demand by OLS (ignoring the endogeneity of prices).\n",
    "\n",
    "For the plain multinomial logit model, the utility is:\n",
    "\n",
    "$$u_{ijt} = \\beta^{(1)} x_{jt} + \\beta^{(2)} satellite_{jt} + \\beta^{(3)} wired_{jt} + \\alpha p_{jt} + \\xi_{jt} + \\epsilon_{ijt}$$\n",
    "\n",
    "This implies the log-odds ratio:\n",
    "\n",
    "$$\\ln\\left(\\frac{s_{jt}}{s_{0t}}\\right) = \\delta_{jt} = \\beta^{(1)} x_{jt} + \\beta^{(2)} satellite_{jt} + \\beta^{(3)} wired_{jt} + \\alpha p_{jt} + \\xi_{jt}$$\n",
    "\n",
    "We can estimate this by OLS, regressing the logit-transformed shares on the observed product characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b593d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Regression: ln(s_jt/s_0t) ~ x + satellite + wired + prices (no intercept)\n",
      "----------------------------------------------------------------------\n",
      "prices      :   -1.247 (SE: 0.051, t: -24.40, p: 0.000)\n",
      "x           :    0.855 (SE: 0.032, t:  26.36, p: 0.000)\n",
      "satellite   :    1.758 (SE: 0.165, t:  10.67, p: 0.000)\n",
      "wired       :    1.790 (SE: 0.164, t:  10.89, p: 0.000)\n"
     ]
    }
   ],
   "source": [
    "# Compute outside shares for each market\n",
    "product_data['outside_share'] = 1 - product_data.groupby('market_ids')['shares'].transform('sum')\n",
    "\n",
    "# Compute logit delta: ln(s_jt / s_0t)\n",
    "product_data['logit_delta'] = np.log(product_data['shares'] / product_data['outside_share'])\n",
    "\n",
    "# OLS using matrix algebra (no intercept)\n",
    "y = product_data['logit_delta'].values\n",
    "X = product_data[['prices', 'x', 'satellite', 'wired' ]].values\n",
    "\n",
    "# Compute OLS estimates: beta_hat = (X^T X)^(-1) X^T y\n",
    "beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "# Compute residuals and HC0 robust standard errors\n",
    "y_hat = X @ beta_hat\n",
    "residuals = y - y_hat\n",
    "n, k = X.shape\n",
    "\n",
    "# HC0 robust covariance matrix\n",
    "V = X.T @ np.diag(residuals**2) @ X\n",
    "cov_matrix_ols = np.linalg.inv(X.T @ X) @ V @ np.linalg.inv(X.T @ X)\n",
    "se_ols = np.sqrt(np.diag(cov_matrix_ols))\n",
    "\n",
    "# t-statistics and p-values\n",
    "t_stats = beta_hat / se_ols\n",
    "p_values = 2 * (1 - stats.norm.cdf(np.abs(t_stats)))\n",
    "\n",
    "print(\"OLS Regression: ln(s_jt/s_0t) ~ x + satellite + wired + prices (no intercept)\")\n",
    "print(\"-\" * 70)\n",
    "param_names = ['prices', 'x', 'satellite', 'wired']\n",
    "for i, param in enumerate(param_names):\n",
    "    print(f\"{param:12s}: {beta_hat[i]:8.3f} (SE: {se_ols[i]:.3f}, t: {t_stats[i]:6.2f}, p: {p_values[i]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afc88f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "==========================\n",
      " T    N     F    K1    MD \n",
      "---  ----  ---  ----  ----\n",
      "600  2400   4    4     4  \n",
      "==========================\n",
      "\n",
      "Formulations:\n",
      "=========================================================\n",
      "     Column Indices:          0      1       2        3  \n",
      "--------------------------  ------  ---  ---------  -----\n",
      "X1: Linear Characteristics  prices   x   satellite  wired\n",
      "=========================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dimensions:\n",
       "==========================\n",
       " T    N     F    K1    MD \n",
       "---  ----  ---  ----  ----\n",
       "600  2400   4    4     4  \n",
       "==========================\n",
       "\n",
       "Formulations:\n",
       "=========================================================\n",
       "     Column Indices:          0      1       2        3  \n",
       "--------------------------  ------  ---  ---------  -----\n",
       "X1: Linear Characteristics  prices   x   satellite  wired\n",
       "========================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_data['demand_instruments0'] = product_data['prices']\n",
    "ols_problem = pyblp.Problem(pyblp.Formulation('0 + prices + x + satellite + wired '), product_data)\n",
    "ols_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19dfdfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the problem ...\n",
      "Estimating standard errors ...\n",
      "Computed results after 00:00:00.\n",
      "\n",
      "Problem Results Summary:\n",
      "=============================================================\n",
      "GMM   Objective  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Shares   Condition Number  Condition Number \n",
      "----  ---------  -------  ----------------  -----------------\n",
      " 1    +1.29E-23     0        +1.53E+03          +1.94E+03    \n",
      "=============================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "========================\n",
      "Computation   Objective \n",
      "   Time      Evaluations\n",
      "-----------  -----------\n",
      " 00:00:00         1     \n",
      "========================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "==================================================\n",
      "  prices          x        satellite      wired   \n",
      "-----------  -----------  -----------  -----------\n",
      " -1.25E+00    +8.55E-01    +1.76E+00    +1.79E+00 \n",
      "(+5.11E-02)  (+3.24E-02)  (+1.65E-01)  (+1.64E-01)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Problem Results Summary:\n",
       "=============================================================\n",
       "GMM   Objective  Clipped  Weighting Matrix  Covariance Matrix\n",
       "Step    Value    Shares   Condition Number  Condition Number \n",
       "----  ---------  -------  ----------------  -----------------\n",
       " 1    +1.29E-23     0        +1.53E+03          +1.94E+03    \n",
       "=============================================================\n",
       "\n",
       "Cumulative Statistics:\n",
       "========================\n",
       "Computation   Objective \n",
       "   Time      Evaluations\n",
       "-----------  -----------\n",
       " 00:00:00         1     \n",
       "========================\n",
       "\n",
       "Beta Estimates (Robust SEs in Parentheses):\n",
       "==================================================\n",
       "  prices          x        satellite      wired   \n",
       "-----------  -----------  -----------  -----------\n",
       " -1.25E+00    +8.55E-01    +1.76E+00    +1.79E+00 \n",
       "(+5.11E-02)  (+3.24E-02)  (+1.65E-01)  (+1.64E-01)\n",
       "=================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_results = ols_problem.solve(method='1s')\n",
    "ols_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc6a2bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "('Estimates', 'Manual OLS')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('Estimates', 'PyBLP')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SEs', 'Manual OLS')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SEs', 'PyBLP')",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "17701a40-ecd4-43ef-bcbc-f26c7e66c690",
       "rows": [
        [
         "prices",
         "-1.2469292859721202",
         "-1.2469292859719705",
         "0.05110467529156648",
         "0.051104675291566926"
        ],
        [
         "x",
         "0.8546955133953722",
         "0.8546955133954175",
         "0.03243009285435498",
         "0.03243009285435494"
        ],
        [
         "satellite",
         "1.7582319376489783",
         "1.7582319376484663",
         "0.16483079228307596",
         "0.16483079228307385"
        ],
        [
         "wired",
         "1.7903366640065264",
         "1.7903366640059812",
         "0.16434060844976647",
         "0.16434060844976364"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Estimates</th>\n",
       "      <th colspan=\"2\" halign=\"left\">SEs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Manual OLS</th>\n",
       "      <th>PyBLP</th>\n",
       "      <th>Manual OLS</th>\n",
       "      <th>PyBLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prices</th>\n",
       "      <td>-1.247</td>\n",
       "      <td>-1.247</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>satellite</th>\n",
       "      <td>1.758</td>\n",
       "      <td>1.758</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wired</th>\n",
       "      <td>1.790</td>\n",
       "      <td>1.790</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Estimates               SEs       \n",
       "          Manual OLS  PyBLP Manual OLS  PyBLP\n",
       "prices        -1.247 -1.247      0.051  0.051\n",
       "x              0.855  0.855      0.032  0.032\n",
       "satellite      1.758  1.758      0.165  0.165\n",
       "wired          1.790  1.790      0.164  0.164"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(index=ols_results.beta_labels, data={\n",
    "    (\"Estimates\", \"Manual OLS\"): beta_hat,\n",
    "    (\"Estimates\", \"PyBLP\"): ols_results.beta.flat,\n",
    "    (\"SEs\", \"Manual OLS\"): se_ols,\n",
    "    (\"SEs\", \"PyBLP\"): ols_results.beta_se.flat,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b407c29",
   "metadata": {},
   "source": [
    "### 6. \n",
    "Re-estimate the multinomial logit model of demand by two-stage\n",
    "least squares, instrumenting for prices with the exogenous demand shifters $%\n",
    "x $ and excluded cost shifters w. Discuss how the results differ from those\n",
    "obtained by OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec453deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Stage Diagnostics:\n",
      "  R² = 0.5067\n",
      "  F-statistic (excluded instruments) = 394.82 (p = 0.0000)\n",
      "\n",
      "2SLS IV Regression: ln(s_jt/s_0t) ~ x + satellite + wired + prices_hat (no intercept)\n",
      "First stage instruments: x, w, x², w², x*w, sum_x_competitors, sum_w_competitors\n",
      "--------------------------------------------------------------------------------\n",
      "prices      :   -1.939 (SE: 0.064, t: -30.50, p: 0.000)\n",
      "x           :    0.923 (SE: 0.035, t:  26.15, p: 0.000)\n",
      "satellite   :    3.996 (SE: 0.208, t:  19.21, p: 0.000)\n",
      "wired       :    4.037 (SE: 0.209, t:  19.34, p: 0.000)\n"
     ]
    }
   ],
   "source": [
    "# First stage: \n",
    "Z = product_data[['satellite', 'wired', 'x', 'w', 'x**2', 'w**2', 'x*w', 'sum_x_competitors', 'sum_w_competitors']].values  \n",
    "\n",
    "# First stage OLS:\n",
    "sigma_hat = np.linalg.inv(Z.T @ Z) @ Z.T @ product_data['prices'].values\n",
    "prices_hat = Z @ sigma_hat\n",
    "\n",
    "# First stage diagnostics\n",
    "first_stage_residuals = product_data['prices'].values - prices_hat\n",
    "SST = np.sum((product_data['prices'].values - product_data['prices'].mean())**2)\n",
    "SSR = np.sum(first_stage_residuals**2)\n",
    "R2_first_stage = 1 - SSR/SST\n",
    "\n",
    "# F-statistic for excluded instruments (w, x², w², x*w, sum_x_competitors, sum_w_competitors)\n",
    "# Restricted model: prices ~ satellite + wired + x\n",
    "Z_restricted = product_data[['satellite', 'wired', 'x']].values\n",
    "sigma_restricted = np.linalg.inv(Z_restricted.T @ Z_restricted) @ Z_restricted.T @ product_data['prices'].values\n",
    "prices_restricted = Z_restricted @ sigma_restricted\n",
    "SSR_restricted = np.sum((product_data['prices'].values - prices_restricted)**2)\n",
    "\n",
    "# F-test: F = [(SSR_r - SSR_ur)/q] / [SSR_ur/(n-k)]\n",
    "n = len(product_data)\n",
    "k = Z.shape[1]  # number of parameters in unrestricted model\n",
    "q = 6  # number of excluded instruments\n",
    "F_stat = ((SSR_restricted - SSR) / q) / (SSR / (n - k))\n",
    "p_value_F = 1 - stats.f.cdf(F_stat, q, n - k)\n",
    "\n",
    "print(f\"First Stage Diagnostics:\")\n",
    "print(f\"  R² = {R2_first_stage:.4f}\")\n",
    "print(f\"  F-statistic (excluded instruments) = {F_stat:.2f} (p = {p_value_F:.4f})\")\n",
    "print()\n",
    "\n",
    "# Second stage: Regress logit_delta on x + satellite + wired + predicted_prices\n",
    "y = product_data['logit_delta'].values\n",
    "X_hat = np.column_stack([\n",
    "    prices_hat,  # Use predicted prices from first stage\n",
    "    product_data['x'].values,\n",
    "    product_data['satellite'].values,\n",
    "    product_data['wired'].values\n",
    "])\n",
    "\n",
    "# 2SLS estimates: beta_hat_iv = (X_hat^T X_hat)^(-1) X_hat^T y\n",
    "beta_hat_iv = np.linalg.inv(X_hat.T @ X_hat) @ X_hat.T @ y\n",
    "\n",
    "# Compute 2SLS standard errors (HC0 robust)\n",
    "# Need to use original regressors X, not fitted X_hat\n",
    "X = np.column_stack([\n",
    "    product_data['prices'].values,  # Use actual prices for residuals and variance\n",
    "    product_data['x'].values,\n",
    "    product_data['satellite'].values,\n",
    "    product_data['wired'].values\n",
    "])\n",
    "\n",
    "residuals_iv = y - X @ beta_hat_iv\n",
    "\n",
    "# HC0 robust covariance for 2SLS: (X'Z(Z'Z)^{-1}Z'X)^{-1} X'Z(Z'Z)^{-1} Ω (Z'Z)^{-1}Z'X (X'Z(Z'Z)^{-1}Z'X)^{-1}\n",
    "# where Ω = diag(residuals²)\n",
    "P_Z = Z @ np.linalg.inv(Z.T @ Z) @ Z.T  # Projection matrix\n",
    "Omega = np.diag(residuals_iv**2)\n",
    "\n",
    "# Simplified: (X'P_Z X)^{-1} X'P_Z Ω P_Z X (X'P_Z X)^{-1}\n",
    "XPZ = X.T @ P_Z\n",
    "bread = np.linalg.inv(XPZ @ X)\n",
    "meat = XPZ @ Omega @ P_Z @ X\n",
    "cov_matrix_iv = bread @ meat @ bread\n",
    "se_iv = np.sqrt(np.diag(cov_matrix_iv)) \n",
    "t_stats_iv = beta_hat_iv / se_iv\n",
    "p_values_iv = 2 * (1 - stats.norm.cdf(np.abs(t_stats_iv)))\n",
    "\n",
    "print(\"2SLS IV Regression: ln(s_jt/s_0t) ~ x + satellite + wired + prices_hat (no intercept)\")\n",
    "print(\"First stage instruments: x, w, x², w², x*w, sum_x_competitors, sum_w_competitors\")\n",
    "print(\"-\" * 80)\n",
    "param_names = ['prices', 'x', 'satellite', 'wired']\n",
    "for i, param in enumerate(param_names):\n",
    "    print(f\"{param:12s}: {beta_hat_iv[i]:8.3f} (SE: {se_iv[i]:.3f}, t: {t_stats_iv[i]:6.2f}, p: {p_values_iv[i]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "904b4814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "==========================\n",
      " T    N     F    K1    MD \n",
      "---  ----  ---  ----  ----\n",
      "600  2400   4    4     9  \n",
      "==========================\n",
      "\n",
      "Formulations:\n",
      "=========================================================\n",
      "     Column Indices:          0      1       2        3  \n",
      "--------------------------  ------  ---  ---------  -----\n",
      "X1: Linear Characteristics  prices   x   satellite  wired\n",
      "=========================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dimensions:\n",
       "==========================\n",
       " T    N     F    K1    MD \n",
       "---  ----  ---  ----  ----\n",
       "600  2400   4    4     9  \n",
       "==========================\n",
       "\n",
       "Formulations:\n",
       "=========================================================\n",
       "     Column Indices:          0      1       2        3  \n",
       "--------------------------  ------  ---  ---------  -----\n",
       "X1: Linear Characteristics  prices   x   satellite  wired\n",
       "========================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add demand instruments for PyBLP\n",
    "product_data['demand_instruments0'] = product_data['w']\n",
    "product_data['demand_instruments1'] = product_data['x**2']\n",
    "product_data['demand_instruments2'] = product_data['w**2']\n",
    "product_data['demand_instruments3'] = product_data['x*w']\n",
    "product_data['demand_instruments4'] = product_data['sum_x_competitors']\n",
    "product_data['demand_instruments5'] = product_data['sum_w_competitors']\n",
    "\n",
    "iv_problem = pyblp.Problem(pyblp.Formulation('0 + prices + x + satellite + wired'), product_data)\n",
    "iv_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63d2e250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the problem ...\n",
      "Estimating standard errors ...\n",
      "Computed results after 00:00:00.\n",
      "\n",
      "Problem Results Summary:\n",
      "=============================================================\n",
      "GMM   Objective  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Shares   Condition Number  Condition Number \n",
      "----  ---------  -------  ----------------  -----------------\n",
      " 1    +4.04E+00     0        +1.26E+03          +2.79E+03    \n",
      "=============================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "========================\n",
      "Computation   Objective \n",
      "   Time      Evaluations\n",
      "-----------  -----------\n",
      " 00:00:00         1     \n",
      "========================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "==================================================\n",
      "  prices          x        satellite      wired   \n",
      "-----------  -----------  -----------  -----------\n",
      " -1.94E+00    +9.23E-01    +4.00E+00    +4.04E+00 \n",
      "(+6.36E-02)  (+3.53E-02)  (+2.08E-01)  (+2.09E-01)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Problem Results Summary:\n",
       "=============================================================\n",
       "GMM   Objective  Clipped  Weighting Matrix  Covariance Matrix\n",
       "Step    Value    Shares   Condition Number  Condition Number \n",
       "----  ---------  -------  ----------------  -----------------\n",
       " 1    +4.04E+00     0        +1.26E+03          +2.79E+03    \n",
       "=============================================================\n",
       "\n",
       "Cumulative Statistics:\n",
       "========================\n",
       "Computation   Objective \n",
       "   Time      Evaluations\n",
       "-----------  -----------\n",
       " 00:00:00         1     \n",
       "========================\n",
       "\n",
       "Beta Estimates (Robust SEs in Parentheses):\n",
       "==================================================\n",
       "  prices          x        satellite      wired   \n",
       "-----------  -----------  -----------  -----------\n",
       " -1.94E+00    +9.23E-01    +4.00E+00    +4.04E+00 \n",
       "(+6.36E-02)  (+3.53E-02)  (+2.08E-01)  (+2.09E-01)\n",
       "=================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_results = iv_problem.solve(method='1s')\n",
    "iv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d140c557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "('Estimates', 'Manual IV')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('Estimates', 'PyBLP IV')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SEs', 'Manual IV')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SEs', 'PyBLP IV')",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ff0f48fe-fe1c-4302-b4d9-491ba09443a6",
       "rows": [
        [
         "prices",
         "-1.9389301648893227",
         "-1.9389301648894677",
         "0.06356740349215473",
         "0.06356740349217077"
        ],
        [
         "x",
         "0.9231395885739994",
         "0.9231395885740113",
         "0.035300734739323616",
         "0.03530073473932449"
        ],
        [
         "satellite",
         "3.9961805068724976",
         "3.9961805068729195",
         "0.2080252928068301",
         "0.2080252928068782"
        ],
        [
         "wired",
         "4.036867191020655",
         "4.036867191021066",
         "0.2087005654173812",
         "0.20870056541742849"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Estimates</th>\n",
       "      <th colspan=\"2\" halign=\"left\">SEs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Manual IV</th>\n",
       "      <th>PyBLP IV</th>\n",
       "      <th>Manual IV</th>\n",
       "      <th>PyBLP IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prices</th>\n",
       "      <td>-1.939</td>\n",
       "      <td>-1.939</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>satellite</th>\n",
       "      <td>3.996</td>\n",
       "      <td>3.996</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wired</th>\n",
       "      <td>4.037</td>\n",
       "      <td>4.037</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Estimates                SEs         \n",
       "          Manual IV PyBLP IV Manual IV PyBLP IV\n",
       "prices       -1.939   -1.939     0.064    0.064\n",
       "x             0.923    0.923     0.035    0.035\n",
       "satellite     3.996    3.996     0.208    0.208\n",
       "wired         4.037    4.037     0.209    0.209"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(index=iv_results.beta_labels, data={\n",
    "    (\"Estimates\", \"Manual IV\"): beta_hat_iv,\n",
    "    (\"Estimates\", \"PyBLP IV\"): iv_results.beta.flat,\n",
    "    (\"SEs\", \"Manual IV\"): se_iv,\n",
    "    (\"SEs\", \"PyBLP IV\"): iv_results.beta_se.flat\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b33a30",
   "metadata": {},
   "source": [
    "### 7. Nested Logit Model Estimation\n",
    "\n",
    "Now estimate a nested logit model by two-stage least squares, treating \"satellite\" and \"wired\" as the two nests for the inside goods. You will probably want to review the discussion of the nested logit in Berry (1994). Note that Berry focuses on the special case in which all the \"nesting parameters\" are the same; you should allow a different nesting parameter for each nest.\n",
    "\n",
    "\n",
    "\n",
    "In Berry’s notation, this means letting the parameter become g(j) , where g (j) indicates the group (satellite\n",
    "or wired) to which each inside good j belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9d0579e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2SLS IV Regression: ln(s_jt/s_0t) ~ prices + x + satellite + wired + ln_within_share_sat + ln_within_share_wired (no intercept)\n",
      "First stage instruments: x, satellite, wired, w, x**2, w**2, x*w, sum_x_competitors, sum_w_competitors, x_other_in_nest, w_other_in_nest\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "prices              :   -1.607 (SE: 0.098, t: -16.46, p: 0.000)\n",
      "x                   :    0.803 (SE: 0.041, t:  19.47, p: 0.000)\n",
      "satellite           :    3.099 (SE: 0.606, t:   5.12, p: 0.000)\n",
      "wired               :    3.367 (SE: 0.487, t:   6.92, p: 0.000)\n",
      "ln_within_share_sat :    0.101 (SE: 0.451, t:   0.22, p: 0.823)\n",
      "ln_within_share_wired:    0.324 (SE: 0.468, t:   0.69, p: 0.488)\n"
     ]
    }
   ],
   "source": [
    "# Compute ln_within_share\n",
    "product_data[\"group_share\"] = product_data.groupby([\"market_ids\", \"satellite\"])[\"shares\"].transform(\"sum\")\n",
    "product_data[\"ln_within_share\"] = np.log(product_data[\"shares\"] / product_data[\"group_share\"])\n",
    "\n",
    "# Create nest-specific ln_within_share\n",
    "product_data[\"ln_within_share_sat\"] = product_data[\"ln_within_share\"] * product_data[\"satellite\"]\n",
    "product_data[\"ln_within_share_wired\"] = product_data[\"ln_within_share\"] * product_data[\"wired\"]\n",
    "\n",
    "# Define variables\n",
    "exog_vars = [\"x\", \"satellite\", \"wired\"]\n",
    "endog_vars = [\"prices\", \"ln_within_share_sat\", \"ln_within_share_wired\"]\n",
    "instr_vars = [\"w\", \"x**2\", \"w**2\", \"x*w\", \"sum_x_competitors\", \"sum_w_competitors\", \"x_other_in_nest\", \"w_other_in_nest\"]\n",
    "Z_vars = exog_vars + instr_vars\n",
    "\n",
    "# First stage: Z = exog + instr\n",
    "Z = product_data[Z_vars].values\n",
    "\n",
    "# First stage OLS for each endog\n",
    "n_endog = len(endog_vars)\n",
    "sigma_hat = np.zeros((Z.shape[1], n_endog))\n",
    "endog_hat = np.zeros((len(product_data), n_endog))\n",
    "for i, var in enumerate(endog_vars):\n",
    "    y_endog = product_data[var].values\n",
    "    sigma = np.linalg.inv(Z.T @ Z) @ Z.T @ y_endog\n",
    "    sigma_hat[:, i] = sigma\n",
    "    endog_hat[:, i] = Z @ sigma\n",
    "\n",
    "# Second stage: Regress logit_delta on exog + predicted_endog, reordered to match PyBLP\n",
    "y = product_data[\"logit_delta\"].values\n",
    "X_hat = np.column_stack([\n",
    "    endog_hat[:, 0],  # prices_hat\n",
    "    product_data[\"x\"].values,\n",
    "    product_data[\"satellite\"].values,\n",
    "    product_data[\"wired\"].values,\n",
    "    endog_hat[:, 1],  # ln_within_share_sat_hat\n",
    "    endog_hat[:, 2]   # ln_within_share_wired_hat\n",
    "])\n",
    "\n",
    "# 2SLS estimates\n",
    "beta_hat_iv_nested = np.linalg.inv(X_hat.T @ X_hat) @ X_hat.T @ y\n",
    "\n",
    "# Compute robust standard errors (HC0) - CORRECTED for 2SLS\n",
    "# Need to use original regressors X, not fitted X_hat\n",
    "X = np.column_stack([\n",
    "    product_data[\"prices\"].values,\n",
    "    product_data[\"x\"].values,\n",
    "    product_data[\"satellite\"].values,\n",
    "    product_data[\"wired\"].values,\n",
    "    product_data[\"ln_within_share_sat\"].values,\n",
    "    product_data[\"ln_within_share_wired\"].values\n",
    "])\n",
    "residuals_iv = y - X @ beta_hat_iv_nested\n",
    "P_Z = Z @ np.linalg.inv(Z.T @ Z) @ Z.T\n",
    "Omega = np.diag(residuals_iv**2)\n",
    "XPZ = X.T @ P_Z\n",
    "bread = np.linalg.inv(XPZ @ X)\n",
    "meat = XPZ @ Omega @ P_Z @ X\n",
    "cov_matrix_iv = bread @ meat @ bread\n",
    "se_iv_nested = np.sqrt(np.diag(cov_matrix_iv))\n",
    "t_stats_iv = beta_hat_iv_nested / se_iv_nested\n",
    "p_values_iv = 2 * (1 - stats.norm.cdf(np.abs(t_stats_iv)))\n",
    "\n",
    "print(\"2SLS IV Regression: ln(s_jt/s_0t) ~ prices + x + satellite + wired + ln_within_share_sat + ln_within_share_wired (no intercept)\")\n",
    "print(\"First stage instruments: \" + \", \".join(Z_vars))\n",
    "print(\"-\" * 120)\n",
    "param_names = [\"prices\", \"x\", \"satellite\", \"wired\", \"ln_within_share_sat\", \"ln_within_share_wired\"]\n",
    "for i, param in enumerate(param_names):\n",
    "    print(f\"{param:20s}: {beta_hat_iv_nested[i]:8.3f} (SE: {se_iv_nested[i]:.3f}, t: {t_stats_iv[i]:6.2f}, p: {p_values_iv[i]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6db266c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for nested logit\n",
    "# Note: nesting_ids needed for PyBLP, but use satellite/wired for groupby where possible\n",
    "product_data['nesting_ids'] = product_data['satellite'].map({1: 'satellite', 0: 'wired'})\n",
    "product_data['demand_instruments6'] = product_data['x_other_in_nest']\n",
    "product_data['demand_instruments7'] = product_data['w_other_in_nest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "656ee267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "===============================\n",
      " T    N     F    K1    MD    H \n",
      "---  ----  ---  ----  ----  ---\n",
      "600  2400   4    4     11    2 \n",
      "===============================\n",
      "\n",
      "Formulations:\n",
      "=========================================================\n",
      "     Column Indices:          0      1       2        3  \n",
      "--------------------------  ------  ---  ---------  -----\n",
      "X1: Linear Characteristics  prices   x   satellite  wired\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "# Nested logit formulation\n",
    "nl_problem = pyblp.Problem(pyblp.Formulation('0 + prices + x + satellite + wired'), product_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98759dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the problem ...\n",
      "\n",
      "Rho Initial Values:\n",
      "====================\n",
      "satellite    wired  \n",
      "---------  ---------\n",
      "+7.00E-01  +7.00E-01\n",
      "====================\n",
      "\n",
      "Rho Lower Bounds:\n",
      "====================\n",
      "satellite    wired  \n",
      "---------  ---------\n",
      "+0.00E+00  +0.00E+00\n",
      "====================\n",
      "\n",
      "Rho Upper Bounds:\n",
      "====================\n",
      "satellite    wired  \n",
      "---------  ---------\n",
      "+9.90E-01  +9.90E-01\n",
      "====================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Objective   Objective     Projected                        \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares     Value    Improvement  Gradient Norm         Theta        \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  ---------  -----------  -------------  --------------------\n",
      " 1     00:00:00         0             1            0            0          0     +7.73E+01                 +1.57E+02    +7.00E-01, +7.00E-01\n",
      " 1     00:00:00         0             2            0            0          0     +1.58E+01   +6.14E+01     +6.70E+01    +0.00E+00, +0.00E+00\n",
      " 1     00:00:00         1             3            0            0          0     +1.89E+00   +1.39E+01     +3.55E-01    +2.09E-01, +2.12E-01\n",
      " 1     00:00:00         2             4            0            0          0     +1.89E+00   +7.95E-04     +3.53E-01    +2.08E-01, +2.13E-01\n",
      " 1     00:00:00         2             5            0            0          0     +1.89E+00   +3.10E-03     +3.46E-01    +2.04E-01, +2.17E-01\n",
      " 1     00:00:00         2             6            0            0          0     +1.88E+00   +1.11E-02     +3.19E-01    +1.86E-01, +2.36E-01\n",
      " 1     00:00:00         3             7            0            0          0     +1.85E+00   +2.42E-02     +1.10E-04    +1.01E-01, +3.24E-01\n",
      " 1     00:00:00         4             8            0            0          0     +1.85E+00   +3.67E-11     +7.66E-09    +1.01E-01, +3.24E-01\n",
      "\n",
      "Optimization completed after 00:00:02.\n",
      "Computing the Hessian and estimating standard errors ...\n",
      "Computed results after 00:00:01.\n",
      "\n",
      "Problem Results Summary:\n",
      "==============================================================================================================\n",
      "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares   Condition Number  Condition Number \n",
      "----  ---------  -------------  ---------------  ---------------  -------  ----------------  -----------------\n",
      " 1    +1.85E+00    +7.66E-09       +3.21E+00        +3.15E+02        0        +1.36E+03          +4.06E+04    \n",
      "==============================================================================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "=================================================\n",
      "Computation  Optimizer  Optimization   Objective \n",
      "   Time      Converged   Iterations   Evaluations\n",
      "-----------  ---------  ------------  -----------\n",
      " 00:00:02       Yes          5             9     \n",
      "=================================================\n",
      "\n",
      "Rho Estimates (Robust SEs in Parentheses):\n",
      "========================\n",
      " satellite      wired   \n",
      "-----------  -----------\n",
      " +1.01E-01    +3.24E-01 \n",
      "(+4.51E-01)  (+4.68E-01)\n",
      "========================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "==================================================\n",
      "  prices          x        satellite      wired   \n",
      "-----------  -----------  -----------  -----------\n",
      " -1.61E+00    +8.03E-01    +3.10E+00    +3.37E+00 \n",
      "(+9.76E-02)  (+4.12E-02)  (+6.06E-01)  (+4.87E-01)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Problem Results Summary:\n",
       "==============================================================================================================\n",
       "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Weighting Matrix  Covariance Matrix\n",
       "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares   Condition Number  Condition Number \n",
       "----  ---------  -------------  ---------------  ---------------  -------  ----------------  -----------------\n",
       " 1    +1.85E+00    +7.66E-09       +3.21E+00        +3.15E+02        0        +1.36E+03          +4.06E+04    \n",
       "==============================================================================================================\n",
       "\n",
       "Cumulative Statistics:\n",
       "=================================================\n",
       "Computation  Optimizer  Optimization   Objective \n",
       "   Time      Converged   Iterations   Evaluations\n",
       "-----------  ---------  ------------  -----------\n",
       " 00:00:02       Yes          5             9     \n",
       "=================================================\n",
       "\n",
       "Rho Estimates (Robust SEs in Parentheses):\n",
       "========================\n",
       " satellite      wired   \n",
       "-----------  -----------\n",
       " +1.01E-01    +3.24E-01 \n",
       "(+4.51E-01)  (+4.68E-01)\n",
       "========================\n",
       "\n",
       "Beta Estimates (Robust SEs in Parentheses):\n",
       "==================================================\n",
       "  prices          x        satellite      wired   \n",
       "-----------  -----------  -----------  -----------\n",
       " -1.61E+00    +8.03E-01    +3.10E+00    +3.37E+00 \n",
       "(+9.76E-02)  (+4.12E-02)  (+6.06E-01)  (+4.87E-01)\n",
       "=================================================="
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho_initial = [0.7, 0.7]  # Initial values for rho_sat and rho_wired\n",
    "nl_results = nl_problem.solve(rho=rho_initial, method='1s')\n",
    "nl_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fe60b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta Comparison for Nested Logit:\n",
      "              Estimates                        SEs             \n",
      "          Manual Nested PyBLP Nested Manual Nested PyBLP Nested\n",
      "prices           -1.607       -1.607         0.098        0.098\n",
      "x                 0.803        0.803         0.041        0.041\n",
      "satellite         3.099        3.099         0.606        0.606\n",
      "wired             3.367        3.367         0.487        0.487\n",
      "\n",
      "Rho Comparison for Nested Logit:\n",
      "              Estimates                        SEs             \n",
      "          Manual Nested PyBLP Nested Manual Nested PyBLP Nested\n",
      "satellite         0.101        0.101         0.451        0.451\n",
      "wired             0.324        0.324         0.468        0.468\n"
     ]
    }
   ],
   "source": [
    "# Compare manual nested logit estimates with PyBLP nested logit estimates for beta\n",
    "nested_beta_comparison = pd.DataFrame(index=nl_results.beta_labels, data={\n",
    "    (\"Estimates\", \"Manual Nested\"): beta_hat_iv_nested[:4],  # prices, x, satellite, wired\n",
    "    (\"Estimates\", \"PyBLP Nested\"): nl_results.beta.flat,\n",
    "    (\"SEs\", \"Manual Nested\"): se_iv_nested[:4],\n",
    "    (\"SEs\", \"PyBLP Nested\"): nl_results.beta_se.flat\n",
    "})\n",
    "\n",
    "print(\"Beta Comparison for Nested Logit:\")\n",
    "print(nested_beta_comparison)\n",
    "\n",
    "# Compare rho estimates\n",
    "nested_rho_comparison = pd.DataFrame(index=nl_results.rho_labels, data={\n",
    "    (\"Estimates\", \"Manual Nested\"): beta_hat_iv_nested[4:],  # rho_sat, rho_wired\n",
    "    (\"Estimates\", \"PyBLP Nested\"): nl_results.rho.flat,\n",
    "    (\"SEs\", \"Manual Nested\"): se_iv_nested[4:],\n",
    "    (\"SEs\", \"PyBLP Nested\"): nl_results.rho_se.flat\n",
    "})\n",
    "\n",
    "print(\"\\nRho Comparison for Nested Logit:\")\n",
    "print(nested_rho_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e598ac",
   "metadata": {},
   "source": [
    "### 8.\n",
    "Using the nested logit results, provide a table comparing the estimated own-price elasticities to the true own-price elasticities. The procedure you developed above for approximating derivatives cannot be used for your estimates based\n",
    "on the nested logit model. But because we have analytic expressions for market shares in the nested logit model,\n",
    "you could either differentiate these or use “finite difference” approximation of derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b6f9beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Nested Logit Elasticities (Analytical Derivatives)...\n",
      "Computing True RC Logit Elasticities (True Parameters on OBSERVED shares)...\n",
      "Computing True RC Logit Elasticities (True Parameters on OBSERVED shares)...\n",
      "\n",
      "======================================================================\n",
      "OWN-PRICE ELASTICITY COMPARISON\n",
      "======================================================================\n",
      "Nested Logit (Estimated) vs RC Logit (True params, observed shares)\n",
      "    Product  True (RC)  Estimated (NL)  Abs % Error\n",
      "Satellite 1     -5.480          -4.998        8.800\n",
      "Satellite 2     -5.315          -4.855        8.649\n",
      "    Wired 1     -5.377          -5.904        9.795\n",
      "    Wired 2     -5.458          -6.001        9.955\n",
      "\n",
      "Mean Absolute % Error: 9.30%\n",
      "\n",
      "Note: NL model misspecified (true DGP is RC), so errors expected\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "OWN-PRICE ELASTICITY COMPARISON\n",
      "======================================================================\n",
      "Nested Logit (Estimated) vs RC Logit (True params, observed shares)\n",
      "    Product  True (RC)  Estimated (NL)  Abs % Error\n",
      "Satellite 1     -5.480          -4.998        8.800\n",
      "Satellite 2     -5.315          -4.855        8.649\n",
      "    Wired 1     -5.377          -5.904        9.795\n",
      "    Wired 2     -5.458          -6.001        9.955\n",
      "\n",
      "Mean Absolute % Error: 9.30%\n",
      "\n",
      "Note: NL model misspecified (true DGP is RC), so errors expected\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract nested logit parameters\n",
    "alpha_nl, beta_x_nl, rho_sat_nl, rho_wired_nl = beta_hat_iv_nested[[0, 1, 4, 5]]\n",
    "\n",
    "def compute_nested_logit_elasticities_analytic(market_df, alpha, beta_x, rho_sat, rho_wired):\n",
    "    \"\"\"Compute elasticities using pyBLP's exact Jacobian formula for nested logit.\n",
    "    \n",
    "    Based on pyBLP's compute_capital_lamda_gamma:\n",
    "    - Lambda_jj = alpha * s_j / (1 - rho_j)\n",
    "    - Gamma_jk = alpha * s_j * s_k + rho/(1-rho) * membership_jk * alpha * s_j|g * s_k\n",
    "    - Jacobian[j,k] = Lambda_jj - Gamma_jk (if j==k), -Gamma_jk (if j!=k)\n",
    "    - Elasticity[j,k] = Jacobian[j,k] * price[k] / share[j]\n",
    "    \n",
    "    This matches pyBLP to within ~1% numerical precision.\n",
    "    \"\"\"\n",
    "    J = len(market_df)\n",
    "    prices = market_df['prices'].values\n",
    "    shares = market_df['shares'].values\n",
    "    satellite, wired = market_df['satellite'].values, market_df['wired'].values\n",
    "    \n",
    "    # Compute within-nest shares (conditionals in pyBLP terminology)\n",
    "    s_group = market_df.groupby('satellite')['shares'].transform('sum').values\n",
    "    conditionals = shares / s_group\n",
    "    \n",
    "    # Nesting parameter for each product\n",
    "    rho = np.where(satellite == 1, rho_sat, rho_wired)\n",
    "    \n",
    "    # Compute full elasticity matrix using pyBLP's formula\n",
    "    elasticities = np.zeros((J, J))\n",
    "    for j in range(J):\n",
    "        # Lambda diagonal element\n",
    "        lambda_jj = alpha * shares[j] / (1 - rho[j])\n",
    "        \n",
    "        for k in range(J):\n",
    "            # Gamma matrix element\n",
    "            same_nest = (satellite[j] == satellite[k]) and (wired[j] == wired[k])\n",
    "            gamma_jk = alpha * shares[j] * shares[k]\n",
    "            if same_nest:\n",
    "                gamma_jk += (rho[j] / (1 - rho[j])) * alpha * conditionals[j] * shares[k]\n",
    "            \n",
    "            # Jacobian = Lambda - Gamma (on diagonal), -Gamma (off-diagonal)\n",
    "            if j == k:\n",
    "                jac_jk = lambda_jj - gamma_jk\n",
    "            else:\n",
    "                jac_jk = -gamma_jk\n",
    "            \n",
    "            # Elasticity = Jacobian * price / share\n",
    "            elasticities[j, k] = jac_jk * prices[k] / shares[j]\n",
    "    \n",
    "    return elasticities\n",
    "\n",
    "def compute_rc_elasticities_observed_shares(market_df, nu_draws, alpha, beta_x, beta_sat, beta_wired, sigma_sat, sigma_wired):\n",
    "    \"\"\"Compute elasticities from RC logit using OBSERVED shares (not recomputed from xi).\n",
    "    \n",
    "    This matches pyBLP's approach:\n",
    "    1. Start with observed shares\n",
    "    2. Back out mean utilities (delta) that rationalize these shares via contraction mapping\n",
    "    3. Compute individual choice probabilities using delta + random coefficients\n",
    "    4. Compute elasticities via analytical derivatives\n",
    "    \n",
    "    Key difference from old method:\n",
    "    - OLD: Uses TRUE xi to compute shares, then elasticities (wrong for comparison!)\n",
    "    - NEW: Uses OBSERVED shares, backs out delta, then computes elasticities (correct!)\n",
    "    \"\"\"\n",
    "    J = len(market_df)\n",
    "    prices = market_df['prices'].values\n",
    "    observed_shares = market_df['shares'].values\n",
    "    x, satellite, wired = market_df['x'].values, market_df['satellite'].values, market_df['wired'].values\n",
    "    \n",
    "    # Compute random coefficient deviations (the part that varies across individuals)\n",
    "    # Delta will absorb everything else: beta_x*x + beta_sat*satellite + beta_wired*wired + alpha*prices + xi\n",
    "    rc_deviation = sigma_sat*nu_draws[:,0:1]*satellite + sigma_wired*nu_draws[:,1:2]*wired\n",
    "    \n",
    "    # Back out mean utilities (delta) via contraction mapping\n",
    "    # Goal: Find delta such that observed_shares = E[exp(delta + rc_deviation) / (1 + sum exp(delta + rc_deviation))]\n",
    "    delta = np.log(observed_shares)  # Initial guess\n",
    "    \n",
    "    for iteration in range(1000):\n",
    "        # Compute individual choice probabilities\n",
    "        utilities = delta[np.newaxis, :] + rc_deviation  # Shape: (n_draws, J)\n",
    "        exp_utils = np.exp(utilities)\n",
    "        denom = 1 + exp_utils.sum(axis=1, keepdims=True)\n",
    "        choice_probs = exp_utils / denom  # Shape: (n_draws, J)\n",
    "        \n",
    "        # Predicted shares\n",
    "        predicted_shares = choice_probs.mean(axis=0)\n",
    "        \n",
    "        # Contraction update: delta_new = delta + log(s_obs) - log(s_pred)\n",
    "        delta_new = delta + np.log(observed_shares) - np.log(predicted_shares)\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.max(np.abs(delta_new - delta)) < 1e-14:\n",
    "            delta = delta_new\n",
    "            break\n",
    "        delta = delta_new\n",
    "    \n",
    "    # Compute final choice probabilities with converged delta\n",
    "    utilities = delta[np.newaxis, :] + rc_deviation\n",
    "    exp_utils = np.exp(utilities)\n",
    "    choice_probs = exp_utils / (1 + exp_utils.sum(axis=1, keepdims=True))\n",
    "    \n",
    "    # Compute elasticities using analytical derivatives\n",
    "    elasticities = np.zeros((J, J))\n",
    "    for j in range(J):\n",
    "        for k in range(J):\n",
    "            if j == k:\n",
    "                # Own-price: E[s_ij * (1 - s_ij)]\n",
    "                deriv = alpha * np.mean(choice_probs[:, j] * (1 - choice_probs[:, j]))\n",
    "            else:\n",
    "                # Cross-price: -E[s_ij * s_ik]\n",
    "                deriv = -alpha * np.mean(choice_probs[:, j] * choice_probs[:, k])\n",
    "            \n",
    "            if observed_shares[j] > 1e-10:\n",
    "                elasticities[j, k] = (prices[k] / observed_shares[j]) * deriv\n",
    "    \n",
    "    return elasticities\n",
    "\n",
    "# ============================================================================\n",
    "# Compute elasticities for Q8 comparison\n",
    "# ============================================================================\n",
    "\n",
    "# Compute Nested Logit elasticities (analytical derivatives)\n",
    "# Compute Nested Logit elasticities (analytical derivatives)\n",
    "print(\"Computing Nested Logit Elasticities (Analytical Derivatives)...\")\n",
    "elasticity_matrices_analytic = [compute_nested_logit_elasticities_analytic(\n",
    "    product_data[product_data['market_ids'] == t], alpha_nl, beta_x_nl, rho_sat_nl, rho_wired_nl\n",
    ") for t in range(T)]\n",
    "\n",
    "print(\"Computing True RC Logit Elasticities (True Parameters on OBSERVED shares)...\")\n",
    "# Use the new function that works with observed shares for fair comparison\n",
    "true_elasticity_matrices = [compute_rc_elasticities_observed_shares(\n",
    "    product_data[product_data['market_ids'] == t], all_nu_draws[t], -2.0, 1.0, 4.0, 4.0, 1.0, 1.0\n",
    ") for t in range(T)]\n",
    "\n",
    "avg_elasticity_matrix_nl = np.mean(elasticity_matrices_analytic, axis=0)\n",
    "avg_elasticity_matrix_true = np.mean(true_elasticity_matrices, axis=0)\n",
    "\n",
    "# Comparison table\n",
    "print(\"\\n\" + \"=\"*70 + \"\\nOWN-PRICE ELASTICITY COMPARISON\\n\" + \"=\"*70)\n",
    "print(\"Nested Logit (Estimated) vs RC Logit (True params, observed shares)\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Product': ['Satellite 1', 'Satellite 2', 'Wired 1', 'Wired 2'],\n",
    "    'True (RC)': np.diag(avg_elasticity_matrix_true),\n",
    "    'Estimated (NL)': np.diag(avg_elasticity_matrix_nl),\n",
    "    'Abs % Error': np.abs(100 * (np.diag(avg_elasticity_matrix_nl) - np.diag(avg_elasticity_matrix_true)) / np.diag(avg_elasticity_matrix_true))\n",
    "})\n",
    "print(comparison_df.to_string(index=False, float_format=lambda x: f'{x:8.3f}'))\n",
    "print(f\"\\nMean Absolute % Error: {comparison_df['Abs % Error'].mean():.2f}%\")\n",
    "print(\"\\nNote: NL model misspecified (true DGP is RC), so errors expected\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Store elasticities in product_data\n",
    "product_data['true_elasticity_rc'] = [true_elasticity_matrices[t][j, j] for t in range(T) for j in range(J)]\n",
    "product_data['estimated_elasticity_nl'] = [elasticity_matrices_analytic[t][j, j] for t in range(T) for j in range(J)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47b846f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing elasticities with respect to prices ...\n",
      "Finished after 00:00:00.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-4.99800789, -4.85483762, -5.90389083, -6.00138066])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticities_nl = nl_results.compute_elasticities()\n",
    "avg_elasticities_nl = elasticities_nl.reshape((T, J, J)).mean(axis=0)\n",
    "own_elasticities_nl = np.diag(avg_elasticities_nl)\n",
    "own_elasticities_nl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa6d2b",
   "metadata": {},
   "source": [
    "Provide two additional tables showing the true\n",
    "matrix of diversion ratios and the diversion ratios implied by your estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3b71944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Diversion Ratios...\n",
      "Computing TRUE RC diversion ratios (true params, observed shares)...\n",
      "\n",
      "======================================================================\n",
      "DIVERSION RATIO MATRICES\n",
      "======================================================================\n",
      "\n",
      "True Diversion Ratios (RC Logit with TRUE params on OBSERVED shares):\n",
      "Diagonal = diversion to outside option D_j0\n",
      "          Sat 1   Sat 2  Wired 1  Wired 2\n",
      "Sat 1    0.5248  0.2239   0.1303   0.1211\n",
      "Sat 2    0.2137  0.5316   0.1314   0.1233\n",
      "Wired 1  0.1237  0.1300   0.5324   0.2139\n",
      "Wired 2  0.1221  0.1292   0.2256   0.5231\n",
      "\n",
      "\n",
      "Estimated Diversion Ratios (from Nested Logit - PyBLP Method):\n",
      "Diagonal = diversion to outside option D_j0\n",
      "          Sat 1   Sat 2  Wired 1  Wired 2\n",
      "Sat 1    0.5083  0.1995   0.1515   0.1407\n",
      "Sat 2    0.1902  0.5141   0.1528   0.1430\n",
      "Wired 1  0.1239  0.1291   0.4445   0.3025\n",
      "Wired 2  0.1213  0.1295   0.3143   0.4349\n",
      "\n",
      "======================================================================\n",
      "Note: D_jk = -(∂s_k/∂p_j) / (∂s_j/∂p_j)\n",
      "Off-diagonal: share of j's lost customers who switch to product k\n",
      "Diagonal: share of j's lost customers who leave the market (outside)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "DIVERSION RATIO MATRICES\n",
      "======================================================================\n",
      "\n",
      "True Diversion Ratios (RC Logit with TRUE params on OBSERVED shares):\n",
      "Diagonal = diversion to outside option D_j0\n",
      "          Sat 1   Sat 2  Wired 1  Wired 2\n",
      "Sat 1    0.5248  0.2239   0.1303   0.1211\n",
      "Sat 2    0.2137  0.5316   0.1314   0.1233\n",
      "Wired 1  0.1237  0.1300   0.5324   0.2139\n",
      "Wired 2  0.1221  0.1292   0.2256   0.5231\n",
      "\n",
      "\n",
      "Estimated Diversion Ratios (from Nested Logit - PyBLP Method):\n",
      "Diagonal = diversion to outside option D_j0\n",
      "          Sat 1   Sat 2  Wired 1  Wired 2\n",
      "Sat 1    0.5083  0.1995   0.1515   0.1407\n",
      "Sat 2    0.1902  0.5141   0.1528   0.1430\n",
      "Wired 1  0.1239  0.1291   0.4445   0.3025\n",
      "Wired 2  0.1213  0.1295   0.3143   0.4349\n",
      "\n",
      "======================================================================\n",
      "Note: D_jk = -(∂s_k/∂p_j) / (∂s_j/∂p_j)\n",
      "Off-diagonal: share of j's lost customers who switch to product k\n",
      "Diagonal: share of j's lost customers who leave the market (outside)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DIVERSION RATIOS\n",
    "# ============================================================================\n",
    "# Using PyBLP's derivative-based method for both RC and NL models\n",
    "# Convention: Diagonal shows diversion to outside option D_j0 instead of D_jj=-1\n",
    "\n",
    "print(\"Computing Diversion Ratios...\")\n",
    "\n",
    "# Unified function using PyBLP's derivative-based approach\n",
    "def compute_diversion_ratios_pyblp(elasticity_matrices, product_data, T, J):\n",
    "    \"\"\"\n",
    "    Compute diversion ratios using pyBLP's derivative-based method.\n",
    "    \n",
    "    This method:\n",
    "    1. Converts elasticities to Jacobian (derivatives)\n",
    "    2. Replaces diagonal with outside option derivative using adding-up constraint\n",
    "    3. Computes diversion ratios as D_jk = -(∂s_k/∂p_j) / (∂s_j/∂p_j)\n",
    "    \n",
    "    Works for any model (RC, NL, etc.) - just supply the elasticity matrices.\n",
    "    \"\"\"\n",
    "    diversion_matrices = []\n",
    "    \n",
    "    for t in range(T):\n",
    "        elast_matrix = elasticity_matrices[t]\n",
    "        market_data_t = product_data[product_data['market_ids'] == t]\n",
    "        shares = market_data_t['shares'].values\n",
    "        prices = market_data_t['prices'].values\n",
    "        \n",
    "        # Convert elasticities to Jacobian (derivatives): ∂s_j/∂p_k = (s_j/p_k) * ε_jk\n",
    "        jacobian = np.zeros((J, J))\n",
    "        for j in range(J):\n",
    "            for k in range(J):\n",
    "                jacobian[j, k] = (shares[j] / prices[k]) * elast_matrix[j, k]\n",
    "        \n",
    "        # PyBLP's method: Replace diagonal with outside option derivative\n",
    "        # ∂s_0/∂p_j = -Σ_k ∂s_k/∂p_j (by adding-up constraint)\n",
    "        jacobian_diag = np.diag(jacobian).copy()\n",
    "        np.fill_diagonal(jacobian, -jacobian.sum(axis=1))\n",
    "        \n",
    "        # Compute diversion ratios: D_jk = -Jacobian[j,k] / Jacobian[j,j]\n",
    "        diversion = -jacobian / jacobian_diag[:, None]\n",
    "        \n",
    "        diversion_matrices.append(diversion)\n",
    "    \n",
    "    return diversion_matrices\n",
    "\n",
    "# --- TRUE DIVERSION RATIOS (from RC model with true parameters on OBSERVED shares) ---\n",
    "# Note: We recompute true elasticities here to ensure we use observed shares\n",
    "print(\"Computing TRUE RC diversion ratios (true params, observed shares)...\")\n",
    "true_elasticity_matrices_for_div = [compute_rc_elasticities_observed_shares(\n",
    "    product_data[product_data['market_ids'] == t], all_nu_draws[t], -2.0, 1.0, 4.0, 4.0, 1.0, 1.0\n",
    ") for t in range(T)]\n",
    "\n",
    "true_diversion_matrices = compute_diversion_ratios_pyblp(\n",
    "    true_elasticity_matrices_for_div, product_data, T, J\n",
    ")\n",
    "true_avg_diversion = np.mean(true_diversion_matrices, axis=0)\n",
    "\n",
    "# --- ESTIMATED DIVERSION RATIOS (from Nested Logit) ---\n",
    "estimated_diversion_matrices = compute_diversion_ratios_pyblp(\n",
    "    elasticity_matrices_analytic, product_data, T, J\n",
    ")\n",
    "estimated_avg_diversion = np.mean(estimated_diversion_matrices, axis=0)\n",
    "\n",
    "# --- DISPLAY RESULTS ---\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DIVERSION RATIO MATRICES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "product_labels = ['Sat 1', 'Sat 2', 'Wired 1', 'Wired 2']\n",
    "\n",
    "print(\"\\nTrue Diversion Ratios (RC Logit with TRUE params on OBSERVED shares):\")\n",
    "print(\"Diagonal = diversion to outside option D_j0\")\n",
    "true_df = pd.DataFrame(true_avg_diversion, index=product_labels, columns=product_labels)\n",
    "print(true_df.to_string(float_format=lambda x: f'{x:7.4f}'))\n",
    "\n",
    "print(\"\\n\\nEstimated Diversion Ratios (from Nested Logit - PyBLP Method):\")\n",
    "print(\"Diagonal = diversion to outside option D_j0\")\n",
    "est_df = pd.DataFrame(estimated_avg_diversion, index=product_labels, columns=product_labels)\n",
    "print(est_df.to_string(float_format=lambda x: f'{x:7.4f}'))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Note: D_jk = -(∂s_k/∂p_j) / (∂s_j/∂p_j)\")\n",
    "print(\"Off-diagonal: share of j's lost customers who switch to product k\")\n",
    "print(\"Diagonal: share of j's lost customers who leave the market (outside)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940ab563",
   "metadata": {},
   "source": [
    "## 5 Estimate the Correctly Specified Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19841e0a",
   "metadata": {},
   "source": [
    "Use the pyBLP software to estimate the correctly specified model. Allow pyBLP to construct\n",
    "approximations to the optimal instruments, using the exogenous demand shifters and exogenous\n",
    "cost shifters. For your own benefit, you may want to see what happens without the approximation of the optimal instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e160701",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data.drop(columns=['nesting_ids'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c983afe3",
   "metadata": {},
   "source": [
    "### 9. \n",
    "Report a table with the estimates of the demand parameters and standard errors. Do\n",
    "this twice: once when you estimate demand alone, then again when you estimate jointly\n",
    "with supply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b54f68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "=======================================\n",
      " T    N     F     I     K1    K2    MD \n",
      "---  ----  ---  -----  ----  ----  ----\n",
      "600  2400   4   60000   4     2     11 \n",
      "=======================================\n",
      "\n",
      "Formulations:\n",
      "=================================================================\n",
      "       Column Indices:             0        1        2        3  \n",
      "-----------------------------  ---------  -----  ---------  -----\n",
      " X1: Linear Characteristics     prices      x    satellite  wired\n",
      "X2: Nonlinear Characteristics  satellite  wired                  \n",
      "=================================================================\n",
      "Solving the problem ...\n",
      "\n",
      "Nonlinear Coefficient Initial Values:\n",
      "===============================\n",
      " Sigma:    satellite    wired  \n",
      "---------  ---------  ---------\n",
      "satellite  +1.00E+00           \n",
      "  wired    +0.00E+00  +1.00E+00\n",
      "===============================\n",
      "\n",
      "Nonlinear Coefficient Lower Bounds:\n",
      "===============================\n",
      " Sigma:    satellite    wired  \n",
      "---------  ---------  ---------\n",
      "satellite  +0.00E+00           \n",
      "  wired    +0.00E+00  +0.00E+00\n",
      "===============================\n",
      "\n",
      "Nonlinear Coefficient Upper Bounds:\n",
      "===============================\n",
      " Sigma:    satellite    wired  \n",
      "---------  ---------  ---------\n",
      "satellite    +INF              \n",
      "  wired    +0.00E+00    +INF   \n",
      "===============================\n",
      "\n",
      "Updating starting values for the weighting matrix and delta ...\n",
      "Computed results after 00:00:00.\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Objective   Objective     Projected                        \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares     Value    Improvement  Gradient Norm         Theta        \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  ---------  -----------  -------------  --------------------\n",
      " 1     00:00:00         0             1            0           600         0     +5.28E+00                 +3.13E+00    +1.00E+00, +1.00E+00\n",
      " 1     00:00:00         0             2          4030         12317        0     +1.65E+01                 +2.25E+01    +1.63E+00, +1.78E+00\n",
      " 1     00:00:00         0             3          3297         10055        0     +4.92E+00   +3.53E-01     +6.80E-01    +1.09E+00, +1.12E+00\n",
      " 1     00:00:00         1             4          3344         10285        0     +4.91E+00   +1.38E-02     +3.61E-01    +1.10E+00, +1.15E+00\n",
      " 1     00:00:00         2             5          3405         10433        0     +4.90E+00   +9.26E-03     +4.66E-01    +1.08E+00, +1.17E+00\n",
      " 1     00:00:00         3             6          3435         10576        0     +4.87E+00   +3.31E-02     +6.64E-01    +9.66E-01, +1.30E+00\n",
      " 1     00:00:00         4             7          3440         10607        0     +4.85E+00   +1.60E-02     +4.23E-01    +9.15E-01, +1.32E+00\n",
      " 1     00:00:00         5             8          3430         10546        0     +4.84E+00   +1.16E-02     +6.40E-02    +8.45E-01, +1.35E+00\n",
      " 1     00:00:00         6             9          3434         10584        0     +4.84E+00   +9.46E-04     +4.66E-02    +8.10E-01, +1.37E+00\n",
      " 1     00:00:00         7            10          3435         10565        0     +4.84E+00   +6.93E-05     +7.18E-03    +8.06E-01, +1.37E+00\n",
      " 1     00:00:00         8            11          3437         10570        0     +4.84E+00   +1.53E-06     +1.13E-05    +8.06E-01, +1.37E+00\n",
      " 1     00:00:01         9            12          3435         10574        0     +4.84E+00   +4.24E-11     +4.01E-07    +8.06E-01, +1.37E+00\n",
      " 1     00:00:01         10           13          3438         10572        0     +4.84E+00   +5.51E-14     +4.91E-10    +8.06E-01, +1.37E+00\n",
      "\n",
      "Optimization completed after 00:00:06.\n",
      "Computing the Hessian and updating the weighting matrix ...\n",
      "Computed results after 00:00:02.\n",
      "\n",
      "Problem Results Summary:\n",
      "==============================================================================================================\n",
      "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares   Condition Number  Condition Number \n",
      "----  ---------  -------------  ---------------  ---------------  -------  ----------------  -----------------\n",
      " 1    +4.84E+00    +4.91E-10       +9.58E-01        +2.59E+01        0        +1.59E+03          +3.62E+05    \n",
      "==============================================================================================================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Objective   Objective     Projected                        \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares     Value    Improvement  Gradient Norm         Theta        \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  ---------  -----------  -------------  --------------------\n",
      " 2     00:00:00         0             1            0           600         0     +4.75E+00                 +1.70E-02    +8.06E-01, +1.37E+00\n",
      " 2     00:00:00         0             2          3095         9503         0     +4.76E+00                 +4.15E-01    +7.94E-01, +1.36E+00\n",
      " 2     00:00:00         0             3          2767         8544         0     +4.75E+00   +8.45E-06     +6.36E-04    +8.06E-01, +1.37E+00\n",
      " 2     00:00:00         1             4          2770         8566         0     +4.75E+00   +2.32E-08     +6.12E-04    +8.05E-01, +1.37E+00\n",
      " 2     00:00:00         1             5          2777         8608         0     +4.75E+00   +8.39E-08     +5.17E-04    +8.05E-01, +1.37E+00\n",
      " 2     00:00:00         2             6          2786         8601         0     +4.75E+00   +2.09E-07     +3.15E-06    +8.05E-01, +1.37E+00\n",
      " 2     00:00:00         3             7          2788         8594         0     +4.75E+00   +3.24E-13     +2.84E-09    +8.05E-01, +1.37E+00\n",
      "\n",
      "Optimization completed after 00:00:02.\n",
      "Computing the Hessian and estimating standard errors ...\n",
      "Computed results after 00:00:03.\n",
      "\n",
      "Problem Results Summary:\n",
      "==============================================================================================================\n",
      "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares   Condition Number  Condition Number \n",
      "----  ---------  -------------  ---------------  ---------------  -------  ----------------  -----------------\n",
      " 2    +4.75E+00    +2.84E-09       +9.35E-01        +2.51E+01        0        +1.59E+03          +3.62E+05    \n",
      "==============================================================================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "===========================================================================\n",
      "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
      "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
      "-----------  ---------  ------------  -----------  -----------  -----------\n",
      " 00:00:13       Yes          15           23          68408       211548   \n",
      "===========================================================================\n",
      "\n",
      "Nonlinear Coefficient Estimates (Robust SEs in Parentheses):\n",
      "===================================\n",
      " Sigma:     satellite      wired   \n",
      "---------  -----------  -----------\n",
      "satellite   +8.05E-01              \n",
      "           (+2.85E+00)             \n",
      "                                   \n",
      "  wired     +0.00E+00    +1.37E+00 \n",
      "                        (+1.84E+00)\n",
      "===================================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "==================================================\n",
      "  prices          x        satellite      wired   \n",
      "-----------  -----------  -----------  -----------\n",
      " -2.03E+00    +9.98E-01    +4.13E+00    +3.95E+00 \n",
      "(+7.67E-02)  (+4.76E-02)  (+9.93E-01)  (+7.52E-01)\n",
      "==================================================\n",
      "Computing optimal instruments for theta ...\n",
      "Computed optimal instruments after 00:00:01.\n",
      "\n",
      "Optimal Instrument Results Summary:\n",
      "=======================\n",
      "Computation  Error Term\n",
      "   Time        Draws   \n",
      "-----------  ----------\n",
      " 00:00:01        1     \n",
      "=======================\n",
      "Re-creating the problem ...\n",
      "Re-created the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "=======================================\n",
      " T    N     F     I     K1    K2    MD \n",
      "---  ----  ---  -----  ----  ----  ----\n",
      "600  2400   4   60000   4     2     6  \n",
      "=======================================\n",
      "\n",
      "Formulations:\n",
      "=================================================================\n",
      "       Column Indices:             0        1        2        3  \n",
      "-----------------------------  ---------  -----  ---------  -----\n",
      " X1: Linear Characteristics     prices      x    satellite  wired\n",
      "X2: Nonlinear Characteristics  satellite  wired                  \n",
      "=================================================================\n",
      "Solving the problem ...\n",
      "\n",
      "Nonlinear Coefficient Initial Values:\n",
      "===============================\n",
      " Sigma:    satellite    wired  \n",
      "---------  ---------  ---------\n",
      "satellite  +1.00E+00           \n",
      "  wired    +0.00E+00  +1.00E+00\n",
      "===============================\n",
      "\n",
      "Nonlinear Coefficient Lower Bounds:\n",
      "===============================\n",
      " Sigma:    satellite    wired  \n",
      "---------  ---------  ---------\n",
      "satellite  +0.00E+00           \n",
      "  wired    +0.00E+00  +0.00E+00\n",
      "===============================\n",
      "\n",
      "Nonlinear Coefficient Upper Bounds:\n",
      "===============================\n",
      " Sigma:    satellite    wired  \n",
      "---------  ---------  ---------\n",
      "satellite    +INF              \n",
      "  wired    +0.00E+00    +INF   \n",
      "===============================\n",
      "\n",
      "Updating starting values for the weighting matrix and delta ...\n",
      "Computed results after 00:00:04.\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Objective   Objective     Projected                        \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares     Value    Improvement  Gradient Norm         Theta        \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  ---------  -----------  -------------  --------------------\n",
      " 1     00:00:01         0             1            0           600         0     +2.16E+00                 +1.11E+01    +1.00E+00, +1.00E+00\n",
      " 1     00:00:01         0             2          3913         11962        0     +1.17E+01                 +3.81E+01    +2.00E+00, +9.11E-01\n",
      " 1     00:00:00         0             3          3445         10596        0     +4.79E-02   +2.11E+00     +1.68E+00    +1.30E+00, +9.73E-01\n",
      " 1     00:00:01         1             4          3560         10883        0     +4.61E-03   +4.33E-02     +6.22E-01    +1.36E+00, +1.00E+00\n",
      " 1     00:00:01         2             5          3549         10853        0     +1.90E-05   +4.60E-03     +3.42E-02    +1.35E+00, +1.00E+00\n",
      " 1     00:00:00         3             6          3550         10859        0     +5.60E-07   +1.84E-05     +5.74E-03    +1.35E+00, +1.00E+00\n",
      " 1     00:00:00         4             7          3545         10847        0     +1.39E-12   +5.60E-07     +8.19E-06    +1.35E+00, +1.00E+00\n",
      " 1     00:00:00         5             8          3550         10853        0     +5.78E-17   +1.39E-12     +6.98E-08    +1.35E+00, +1.00E+00\n",
      " 1     00:00:00         6             9          3546         10841        0     +3.40E-22   +5.78E-17     +8.88E-11    +1.35E+00, +1.00E+00\n",
      "\n",
      "Optimization completed after 00:00:05.\n",
      "Computing the Hessian and updating the weighting matrix ...\n",
      "Computed results after 00:00:02.\n",
      "\n",
      "Problem Results Summary:\n",
      "==============================================================================================================\n",
      "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares   Condition Number  Condition Number \n",
      "----  ---------  -------------  ---------------  ---------------  -------  ----------------  -----------------\n",
      " 1    +3.40E-22    +8.88E-11       +2.82E+01        +4.65E+01        0        +3.39E+03          +2.76E+03    \n",
      "==============================================================================================================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Objective   Objective     Projected                        \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares     Value    Improvement  Gradient Norm         Theta        \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  ---------  -----------  -------------  --------------------\n",
      " 2     00:00:00         0             1            0           600         0     +6.73E-22                 +2.58E-11    +1.35E+00, +1.00E+00\n",
      "\n",
      "Optimization completed after 00:00:00.\n",
      "Computing the Hessian and estimating standard errors ...\n",
      "Computed results after 00:00:01.\n",
      "\n",
      "Problem Results Summary:\n",
      "==============================================================================================================\n",
      "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares   Condition Number  Condition Number \n",
      "----  ---------  -------------  ---------------  ---------------  -------  ----------------  -----------------\n",
      " 2    +6.73E-22    +2.58E-11       +2.79E+01        +4.45E+01        0        +3.43E+03          +2.76E+03    \n",
      "==============================================================================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "===========================================================================\n",
      "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
      "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
      "-----------  ---------  ------------  -----------  -----------  -----------\n",
      " 00:00:13       Yes          7            13          35843       111417   \n",
      "===========================================================================\n",
      "\n",
      "Nonlinear Coefficient Estimates (Robust SEs in Parentheses):\n",
      "===================================\n",
      " Sigma:     satellite      wired   \n",
      "---------  -----------  -----------\n",
      "satellite   +1.35E+00              \n",
      "           (+2.27E-01)             \n",
      "                                   \n",
      "  wired     +0.00E+00    +1.00E+00 \n",
      "                        (+2.55E-01)\n",
      "===================================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "==================================================\n",
      "  prices          x        satellite      wired   \n",
      "-----------  -----------  -----------  -----------\n",
      " -2.03E+00    +1.01E+00    +3.91E+00    +4.09E+00 \n",
      "(+6.75E-02)  (+4.47E-02)  (+2.29E-01)  (+2.22E-01)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Problem Results Summary:\n",
       "==============================================================================================================\n",
       "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Weighting Matrix  Covariance Matrix\n",
       "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares   Condition Number  Condition Number \n",
       "----  ---------  -------------  ---------------  ---------------  -------  ----------------  -----------------\n",
       " 2    +6.73E-22    +2.58E-11       +2.79E+01        +4.45E+01        0        +3.43E+03          +2.76E+03    \n",
       "==============================================================================================================\n",
       "\n",
       "Cumulative Statistics:\n",
       "===========================================================================\n",
       "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
       "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
       "-----------  ---------  ------------  -----------  -----------  -----------\n",
       " 00:00:13       Yes          7            13          35843       111417   \n",
       "===========================================================================\n",
       "\n",
       "Nonlinear Coefficient Estimates (Robust SEs in Parentheses):\n",
       "===================================\n",
       " Sigma:     satellite      wired   \n",
       "---------  -----------  -----------\n",
       "satellite   +1.35E+00              \n",
       "           (+2.27E-01)             \n",
       "                                   \n",
       "  wired     +0.00E+00    +1.00E+00 \n",
       "                        (+2.55E-01)\n",
       "===================================\n",
       "\n",
       "Beta Estimates (Robust SEs in Parentheses):\n",
       "==================================================\n",
       "  prices          x        satellite      wired   \n",
       "-----------  -----------  -----------  -----------\n",
       " -2.03E+00    +1.01E+00    +3.91E+00    +4.09E+00 \n",
       "(+6.75E-02)  (+4.47E-02)  (+2.29E-01)  (+2.22E-01)\n",
       "=================================================="
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_formulation = pyblp.Formulation('0 + prices + x + satellite + wired')\n",
    "X2_formulation = pyblp.Formulation('0 + satellite + wired')\n",
    "product_formulations1 = (X1_formulation, X2_formulation)\n",
    "product_data['demand_instruments0'] = product_data['w']\n",
    "product_data['demand_instruments1'] = product_data['x**2']\n",
    "product_data['demand_instruments2'] = product_data['w**2']\n",
    "product_data['demand_instruments3'] = product_data['x*w']\n",
    "product_data['demand_instruments4'] = product_data['sum_x_competitors']\n",
    "product_data['demand_instruments5'] = product_data['sum_w_competitors']\n",
    "product_data['demand_instruments6'] = product_data['x_other_in_nest']\n",
    "product_data['demand_instruments7'] = product_data['w_other_in_nest']\n",
    "integration = pyblp.Integration('product', 10)\n",
    "problem1 = pyblp.Problem(product_formulations1, product_data, integration=integration)\n",
    "results1 = problem1.solve(sigma=np.eye(2), initial_update=True)\n",
    "optimal_iv1 = results1.compute_optimal_instruments(seed=1995)\n",
    "optimal_problem1 = optimal_iv1.to_problem()\n",
    "optimal_iv_results1 = optimal_problem1.solve(sigma=np.eye(2), initial_update=True)\n",
    "optimal_iv_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d591ff63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "===================================================\n",
      " T    N     F     I     K1    K2    K3    MD    MS \n",
      "---  ----  ---  -----  ----  ----  ----  ----  ----\n",
      "600  2400   4   60000   4     2     2     6     2  \n",
      "===================================================\n",
      "\n",
      "Formulations:\n",
      "=================================================================\n",
      "       Column Indices:             0        1        2        3  \n",
      "-----------------------------  ---------  -----  ---------  -----\n",
      " X1: Linear Characteristics     prices      x    satellite  wired\n",
      "X2: Nonlinear Characteristics  satellite  wired                  \n",
      "X3: Log Cost Characteristics       1        w                    \n",
      "=================================================================\n",
      "Solving the problem ...\n",
      "\n",
      "Nonlinear Coefficient Initial Values:\n",
      "===============================\n",
      " Sigma:    satellite    wired  \n",
      "---------  ---------  ---------\n",
      "satellite  +1.00E+00           \n",
      "  wired    +0.00E+00  +1.00E+00\n",
      "===============================\n",
      "\n",
      "Beta Initial Values:\n",
      "==========================================\n",
      " prices        x      satellite    wired  \n",
      "---------  ---------  ---------  ---------\n",
      "-2.03E+00  +1.01E+00  +3.91E+00  +4.09E+00\n",
      "==========================================\n",
      "\n",
      "Nonlinear Coefficient Lower Bounds:\n",
      "===============================\n",
      " Sigma:    satellite    wired  \n",
      "---------  ---------  ---------\n",
      "satellite  +0.00E+00           \n",
      "  wired    +0.00E+00  +0.00E+00\n",
      "===============================\n",
      "\n",
      "Beta Lower Bounds:\n",
      "==========================================\n",
      " prices        x      satellite    wired  \n",
      "---------  ---------  ---------  ---------\n",
      "  -INF       -INF       -INF       -INF   \n",
      "==========================================\n",
      "\n",
      "Nonlinear Coefficient Upper Bounds:\n",
      "===============================\n",
      " Sigma:    satellite    wired  \n",
      "---------  ---------  ---------\n",
      "satellite    +INF              \n",
      "  wired    +0.00E+00    +INF   \n",
      "===============================\n",
      "\n",
      "Beta Upper Bounds:\n",
      "==========================================\n",
      " prices        x      satellite    wired  \n",
      "---------  ---------  ---------  ---------\n",
      "  +INF       +INF       +INF       +INF   \n",
      "==========================================\n",
      "\n",
      "Updating starting values for the weighting matrix and delta ...\n",
      "Computed results after 00:00:01.\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Clipped  Objective   Objective     Projected                                                                    \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares    Costs     Value    Improvement  Gradient Norm                               Theta                              \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  -------  ---------  -----------  -------------  ----------------------------------------------------------------\n",
      " 1     00:00:01         0             1            0           600         0        0     +2.34E+01                 +9.86E+02    +1.00E+00, +1.00E+00, -2.03E+00, +1.01E+00, +3.91E+00, +4.09E+00\n",
      " 1     00:00:01         0             2          3162         9684         0        1     +2.57E+04                 +5.12E+04    +1.11E+00, +9.99E-01, -1.10E+00, +1.18E+00, +4.20E+00, +4.08E+00\n",
      " 1     00:00:01         0             3          2774         8635         0        0     +1.30E+01   +1.04E+01     +1.62E+02    +1.00E+00, +1.00E+00, -2.01E+00, +1.01E+00, +3.92E+00, +4.09E+00\n",
      " 1     00:00:01         1             4          2964         9132         0        0     +1.19E+01   +1.08E+00     +1.54E+02    +1.00E+00, +9.99E-01, -2.01E+00, +1.01E+00, +3.92E+00, +4.09E+00\n",
      " 1     00:00:01         1             5          3248         10028        0        0     +8.13E+00   +3.78E+00     +1.22E+02    +1.01E+00, +9.95E-01, -2.01E+00, +1.01E+00, +3.93E+00, +4.08E+00\n",
      " 1     00:00:01         2             6          3373         10415        0        0     +1.62E+00   +6.51E+00     +8.74E+00    +1.03E+00, +9.79E-01, -2.01E+00, +9.92E-01, +3.98E+00, +4.03E+00\n",
      " 1     00:00:01         3             7          3314         10264        0        0     +1.58E+00   +4.22E-02     +8.52E+00    +1.04E+00, +9.79E-01, -2.01E+00, +9.90E-01, +3.97E+00, +4.04E+00\n",
      " 1     00:00:01         4             8          3200         9926         0        0     +1.32E+00   +2.56E-01     +1.31E+01    +1.07E+00, +9.76E-01, -2.01E+00, +9.81E-01, +3.96E+00, +4.04E+00\n",
      " 1     00:00:01         5             9          3282         10047        0        0     +1.00E+00   +3.20E-01     +2.21E+01    +1.12E+00, +9.70E-01, -2.01E+00, +9.77E-01, +3.95E+00, +4.05E+00\n",
      " 1     00:00:01         6            10          3341         10261        0        0     +3.95E-01   +6.08E-01     +2.22E+01    +1.26E+00, +9.55E-01, -2.01E+00, +9.83E-01, +3.91E+00, +4.07E+00\n",
      " 1     00:00:01         7            11          3451         10623        0        0     +1.15E-01   +2.79E-01     +1.17E+01    +1.32E+00, +9.50E-01, -2.02E+00, +9.96E-01, +3.89E+00, +4.08E+00\n",
      " 1     00:00:04         8            12          3459         10634        0        0     +4.51E-02   +7.03E-02     +6.59E+00    +1.33E+00, +9.50E-01, -2.02E+00, +1.01E+00, +3.89E+00, +4.08E+00\n",
      " 1     00:00:01         9            13          3457         10640        0        0     +4.34E-02   +1.71E-03     +9.55E-01    +1.33E+00, +9.51E-01, -2.02E+00, +1.01E+00, +3.89E+00, +4.08E+00\n",
      " 1     00:00:01         10           14          3453         10641        0        0     +4.28E-02   +6.07E-04     +1.87E+00    +1.33E+00, +9.51E-01, -2.02E+00, +1.01E+00, +3.89E+00, +4.08E+00\n",
      " 1     00:00:01         11           15          3454         10636        0        0     +4.19E-02   +9.17E-04     +1.49E+00    +1.32E+00, +9.52E-01, -2.02E+00, +1.01E+00, +3.89E+00, +4.08E+00\n",
      " 1     00:00:01         12           16          3451         10618        0        0     +4.18E-02   +8.25E-05     +2.05E+01    +1.32E+00, +9.56E-01, -2.02E+00, +1.01E+00, +3.89E+00, +4.07E+00\n",
      " 1     00:00:01         12           17          3450         10625        0        0     +4.04E-02   +1.38E-03     +1.07E+01    +1.32E+00, +9.54E-01, -2.02E+00, +1.01E+00, +3.89E+00, +4.07E+00\n",
      " 1     00:00:01         13           18          3462         10648        0        0     +3.72E-02   +3.27E-03     +8.26E+00    +1.32E+00, +9.56E-01, -2.02E+00, +1.01E+00, +3.89E+00, +4.07E+00\n",
      " 1     00:00:01         14           19          3498         10740        0        0     +1.93E-02   +1.78E-02     +3.45E+00    +1.33E+00, +9.72E-01, -2.02E+00, +1.01E+00, +3.88E+00, +4.06E+00\n",
      " 1     00:00:01         15           20          3515         10797        0        0     +7.31E-03   +1.20E-02     +5.09E+00    +1.33E+00, +9.86E-01, -2.02E+00, +1.01E+00, +3.87E+00, +4.05E+00\n",
      " 1     00:00:01         16           21          3530         10828        0        0     +1.89E-03   +5.42E-03     +2.96E+00    +1.34E+00, +9.94E-01, -2.02E+00, +1.01E+00, +3.86E+00, +4.04E+00\n",
      " 1     00:00:01         17           22          3528         10811        0        0     +1.27E-03   +6.18E-04     +6.84E-01    +1.34E+00, +9.93E-01, -2.02E+00, +1.01E+00, +3.86E+00, +4.04E+00\n",
      " 1     00:00:01         18           23          3529         10826        0        0     +1.23E-03   +4.15E-05     +1.79E-01    +1.34E+00, +9.93E-01, -2.02E+00, +1.01E+00, +3.86E+00, +4.04E+00\n",
      " 1     00:00:01         19           24          3532         10831        0        0     +1.22E-03   +8.74E-06     +1.89E-01    +1.34E+00, +9.92E-01, -2.02E+00, +1.01E+00, +3.86E+00, +4.04E+00\n",
      " 1     00:00:01         20           25          3531         10810        0        0     +1.17E-03   +4.53E-05     +5.85E-01    +1.34E+00, +9.92E-01, -2.02E+00, +1.01E+00, +3.86E+00, +4.04E+00\n",
      " 1     00:00:01         21           26          3529         10806        0        0     +1.08E-03   +9.18E-05     +1.09E+00    +1.34E+00, +9.91E-01, -2.02E+00, +1.01E+00, +3.86E+00, +4.04E+00\n",
      " 1     00:00:01         22           27          3526         10800        0        0     +8.62E-04   +2.21E-04     +1.70E+00    +1.34E+00, +9.89E-01, -2.02E+00, +1.01E+00, +3.86E+00, +4.04E+00\n",
      " 1     00:00:01         23           28          3520         10788        0        0     +5.12E-04   +3.50E-04     +2.49E+00    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.86E+00, +4.04E+00\n",
      " 1     00:00:01         24           29          3505         10760        0        0     +3.28E-03                 +1.41E+01    +1.33E+00, +9.82E-01, -2.01E+00, +1.01E+00, +3.86E+00, +4.04E+00\n",
      " 1     00:00:01         24           30          3523         10798        0        0     +4.57E-04   +5.52E-05     +5.66E-01    +1.33E+00, +9.86E-01, -2.01E+00, +1.01E+00, +3.86E+00, +4.04E+00\n",
      " 1     00:00:01         25           31          3525         10818        0        0     +1.44E-04   +3.13E-04     +9.01E-01    +1.33E+00, +9.86E-01, -2.01E+00, +1.01E+00, +3.86E+00, +4.04E+00\n",
      " 1     00:00:01         26           32          3520         10786        0        0     +2.30E-05   +1.21E-04     +6.33E-01    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         27           33          3525         10807        0        0     +6.46E-06   +1.66E-05     +1.31E-01    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         28           34          3524         10791        0        0     +2.92E-06   +3.54E-06     +6.47E-02    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         29           35          3523         10808        0        0     +1.25E-06   +1.67E-06     +4.91E-02    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         30           36          3521         10799        0        0     +9.60E-07   +2.89E-07     +5.08E-02    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         31           37          3525         10809        0        0     +1.33E-07   +8.27E-07     +2.73E-02    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         32           38          3525         10801        0        0     +1.51E-07                 +3.38E-02    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         32           39          3527         10817        0        0     +1.59E-08   +1.17E-07     +4.70E-03    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         33           40          3524         10804        0        0     +7.93E-10   +1.52E-08     +1.41E-03    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         34           41          3524         10800        0        0     +2.82E-12   +7.90E-10     +1.71E-04    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         35           42          3524         10806        0        0     +3.74E-12                 +5.23E-04    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         35           43          3521         10802        0        0     +1.64E-12   +1.19E-12     +1.26E-04    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         36           44          3522         10808        0        0     +1.03E-13   +1.53E-12     +1.01E-05    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         37           45          3525         10811        0        0     +3.58E-15   +9.94E-14     +4.61E-06    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         38           46          3523         10801        0        0     +2.77E-15   +8.10E-16     +4.96E-06    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         39           47          3522         10801        0        0     +1.60E-18   +2.77E-15     +4.59E-08    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         40           48          3520         10802        0        0     +2.97E-20   +1.57E-18     +7.11E-09    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      "\n",
      "Optimization completed after 00:00:46.\n",
      "Computing the Hessian and updating the weighting matrix ...\n",
      "Computed results after 00:00:11.\n",
      "\n",
      "Problem Results Summary:\n",
      "=======================================================================================================================\n",
      "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares    Costs   Condition Number  Condition Number \n",
      "----  ---------  -------------  ---------------  ---------------  -------  -------  ----------------  -----------------\n",
      " 1    +2.97E-20    +7.11E-09       +1.81E+01        +5.65E+04        0        0        +6.78E+02          +2.85E+04    \n",
      "=======================================================================================================================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Clipped  Objective   Objective     Projected                                                                    \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares    Costs     Value    Improvement  Gradient Norm                               Theta                              \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  -------  ---------  -----------  -------------  ----------------------------------------------------------------\n",
      " 2     00:00:01         0             1            0           600         0        0     +2.96E-20                 +7.40E-09    +1.34E+00, +9.87E-01, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      "\n",
      "Optimization completed after 00:00:01.\n",
      "Computing the Hessian and estimating standard errors ...\n",
      "Computed results after 00:00:07.\n",
      "\n",
      "Problem Results Summary:\n",
      "=======================================================================================================================\n",
      "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares    Costs   Condition Number  Condition Number \n",
      "----  ---------  -------------  ---------------  ---------------  -------  -------  ----------------  -----------------\n",
      " 2    +2.96E-20    +7.40E-09       +1.81E+01        +5.57E+04        0        0        +6.65E+02          +2.85E+04    \n",
      "=======================================================================================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "===========================================================================\n",
      "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
      "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
      "-----------  ---------  ------------  -----------  -----------  -----------\n",
      " 00:01:05       Yes          41           52         169140       521207   \n",
      "===========================================================================\n",
      "\n",
      "Nonlinear Coefficient Estimates (Robust SEs in Parentheses):\n",
      "===================================\n",
      " Sigma:     satellite      wired   \n",
      "---------  -----------  -----------\n",
      "satellite   +1.34E+00              \n",
      "           (+2.27E-01)             \n",
      "                                   \n",
      "  wired     +0.00E+00    +9.87E-01 \n",
      "                        (+2.57E-01)\n",
      "===================================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "==================================================\n",
      "  prices          x        satellite      wired   \n",
      "-----------  -----------  -----------  -----------\n",
      " -2.01E+00    +1.01E+00    +3.85E+00    +4.04E+00 \n",
      "(+7.17E-02)  (+4.49E-02)  (+2.41E-01)  (+2.34E-01)\n",
      "==================================================\n",
      "\n",
      "Gamma Estimates (Robust SEs in Parentheses):\n",
      "========================\n",
      "     1            w     \n",
      "-----------  -----------\n",
      " +7.96E-01    +2.04E-01 \n",
      "(+1.51E-02)  (+6.90E-03)\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "X3_formulation = pyblp.Formulation('1 + w')\n",
    "product_formulations2 = (X1_formulation, X2_formulation, X3_formulation)\n",
    "columns_to_drop = [col for col in product_data.columns if 'instruments' in col]\n",
    "product_data = product_data.drop(columns=columns_to_drop)\n",
    "product_data['demand_instruments0'] = optimal_iv1.demand_instruments[:, 0]\n",
    "product_data['demand_instruments1'] = optimal_iv1.demand_instruments[:, 1]\n",
    "product_data['demand_instruments2'] = product_data['w'] \n",
    "problem2 = pyblp.Problem(product_formulations2, product_data, costs_type='log', integration=integration)\n",
    "results2 = problem2.solve(sigma=np.eye(2), costs_bounds=(0.001, None), beta=optimal_iv_results1.beta, initial_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4404dc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing optimal instruments for theta ...\n",
      "Computed optimal instruments after 00:00:01.\n",
      "\n",
      "Optimal Instrument Results Summary:\n",
      "=================================================\n",
      "Computation  Error Term  Fixed Point  Contraction\n",
      "   Time        Draws     Iterations   Evaluations\n",
      "-----------  ----------  -----------  -----------\n",
      " 00:00:01        1          8462         8462    \n",
      "=================================================\n",
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "===================================================\n",
      " T    N     F     I     K1    K2    K3    MD    MS \n",
      "---  ----  ---  -----  ----  ----  ----  ----  ----\n",
      "600  2400   4   60000   4     2     2     6     2  \n",
      "===================================================\n",
      "\n",
      "Formulations:\n",
      "=================================================================\n",
      "       Column Indices:             0        1        2        3  \n",
      "-----------------------------  ---------  -----  ---------  -----\n",
      " X1: Linear Characteristics     prices      x    satellite  wired\n",
      "X2: Nonlinear Characteristics  satellite  wired                  \n",
      "X3: Log Cost Characteristics       1        w                    \n",
      "=================================================================\n",
      "Solving the problem ...\n",
      "\n",
      "Nonlinear Coefficient Initial Values:\n",
      "===============================\n",
      " Sigma:    satellite    wired  \n",
      "---------  ---------  ---------\n",
      "satellite  +1.00E+00           \n",
      "  wired    +0.00E+00  +1.00E+00\n",
      "===============================\n",
      "\n",
      "Beta Initial Values:\n",
      "==========================================\n",
      " prices        x      satellite    wired  \n",
      "---------  ---------  ---------  ---------\n",
      "-2.01E+00  +1.01E+00  +3.85E+00  +4.04E+00\n",
      "==========================================\n",
      "\n",
      "Nonlinear Coefficient Lower Bounds:\n",
      "===============================\n",
      " Sigma:    satellite    wired  \n",
      "---------  ---------  ---------\n",
      "satellite  +0.00E+00           \n",
      "  wired    +0.00E+00  +0.00E+00\n",
      "===============================\n",
      "\n",
      "Beta Lower Bounds:\n",
      "==========================================\n",
      " prices        x      satellite    wired  \n",
      "---------  ---------  ---------  ---------\n",
      "  -INF       -INF       -INF       -INF   \n",
      "==========================================\n",
      "\n",
      "Nonlinear Coefficient Upper Bounds:\n",
      "===============================\n",
      " Sigma:    satellite    wired  \n",
      "---------  ---------  ---------\n",
      "satellite    +INF              \n",
      "  wired    +0.00E+00    +INF   \n",
      "===============================\n",
      "\n",
      "Beta Upper Bounds:\n",
      "==========================================\n",
      " prices        x      satellite    wired  \n",
      "---------  ---------  ---------  ---------\n",
      "  +INF       +INF       +INF       +INF   \n",
      "==========================================\n",
      "\n",
      "Updating starting values for the weighting matrix and delta ...\n",
      "Computed results after 00:00:01.\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Clipped  Objective   Objective     Projected                                                                    \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares    Costs     Value    Improvement  Gradient Norm                               Theta                              \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  -------  ---------  -----------  -------------  ----------------------------------------------------------------\n",
      " 1     00:00:01         0             1            0           600         0        0     +2.20E+01                 +9.04E+02    +1.00E+00, +1.00E+00, -2.01E+00, +1.01E+00, +3.85E+00, +4.04E+00\n",
      " 1     00:00:01         0             2          3170         9702         0        2     +2.57E+04                 +5.14E+04    +1.12E+00, +9.99E-01, -1.08E+00, +1.18E+00, +4.16E+00, +4.01E+00\n",
      " 1     00:00:01         0             3          2771         8625         0        0     +1.31E+01   +8.88E+00     +1.62E+02    +1.00E+00, +1.00E+00, -2.00E+00, +1.01E+00, +3.86E+00, +4.04E+00\n",
      " 1     00:00:01         1             4          2952         9096         0        0     +1.20E+01   +1.07E+00     +1.53E+02    +1.00E+00, +9.99E-01, -2.00E+00, +1.01E+00, +3.86E+00, +4.03E+00\n",
      " 1     00:00:01         1             5          3223         9921         0        0     +8.31E+00   +3.73E+00     +1.21E+02    +1.01E+00, +9.95E-01, -2.00E+00, +1.01E+00, +3.87E+00, +4.02E+00\n",
      " 1     00:00:01         2             6          3291         10179        0        0     +1.99E+00   +6.32E+00     +9.26E+00    +1.03E+00, +9.81E-01, -1.99E+00, +9.91E-01, +3.92E+00, +3.98E+00\n",
      " 1     00:00:01         3             7          3248         10055        0        0     +1.94E+00   +4.32E-02     +9.05E+00    +1.04E+00, +9.82E-01, -1.99E+00, +9.89E-01, +3.92E+00, +3.98E+00\n",
      " 1     00:00:01         4             8          3138         9633         0        0     +1.55E+00   +3.87E-01     +1.74E+01    +1.09E+00, +9.96E-01, -2.00E+00, +9.79E-01, +3.92E+00, +3.99E+00\n",
      " 1     00:00:01         5             9          3269         10011        0        0     +1.10E+00   +4.60E-01     +2.68E+01    +1.16E+00, +1.02E+00, -2.00E+00, +9.78E-01, +3.91E+00, +4.01E+00\n",
      " 1     00:00:01         6            10          3596         11024        0        0     +3.51E-01   +7.44E-01     +2.29E+01    +1.32E+00, +1.06E+00, -2.02E+00, +9.93E-01, +3.90E+00, +4.05E+00\n",
      " 1     00:00:01         7            11          3665         11201        0        0     +8.26E-02   +2.68E-01     +9.72E+00    +1.36E+00, +1.07E+00, -2.03E+00, +1.01E+00, +3.90E+00, +4.06E+00\n",
      " 1     00:00:01         8            12          3658         11190        0        0     +4.22E-02   +4.04E-02     +3.95E+00    +1.36E+00, +1.07E+00, -2.03E+00, +1.01E+00, +3.89E+00, +4.06E+00\n",
      " 1     00:00:01         9            13          3658         11191        0        0     +4.08E-02   +1.40E-03     +9.22E-01    +1.37E+00, +1.07E+00, -2.03E+00, +1.02E+00, +3.89E+00, +4.06E+00\n",
      " 1     00:00:01         10           14          3668         11213        0        0     +3.87E-02   +2.13E-03     +4.21E+00    +1.36E+00, +1.08E+00, -2.03E+00, +1.02E+00, +3.89E+00, +4.05E+00\n",
      " 1     00:00:01         11           15          3666         11193        0        0     +3.54E-02   +3.30E-03     +2.52E+00    +1.36E+00, +1.08E+00, -2.03E+00, +1.02E+00, +3.89E+00, +4.05E+00\n",
      " 1     00:00:01         12           16          3646         11153        0        0     +4.06E-02                 +4.32E+01    +1.36E+00, +1.09E+00, -2.03E+00, +1.02E+00, +3.89E+00, +4.04E+00\n",
      " 1     00:00:01         12           17          3668         11217        0        0     +3.18E-02   +3.58E-03     +1.78E+01    +1.36E+00, +1.08E+00, -2.03E+00, +1.02E+00, +3.89E+00, +4.05E+00\n",
      " 1     00:00:01         13           18          3659         11199        0        0     +2.42E-02   +7.57E-03     +1.24E+01    +1.36E+00, +1.09E+00, -2.03E+00, +1.02E+00, +3.89E+00, +4.04E+00\n",
      " 1     00:00:01         14           19          3689         11275        0        0     +6.32E-03   +1.79E-02     +2.63E+00    +1.37E+00, +1.11E+00, -2.03E+00, +1.02E+00, +3.88E+00, +4.02E+00\n",
      " 1     00:00:01         15           20          3686         11263        0        0     +2.93E-03   +3.40E-03     +1.85E+00    +1.37E+00, +1.12E+00, -2.02E+00, +1.02E+00, +3.87E+00, +4.02E+00\n",
      " 1     00:00:01         16           21          3685         11272        0        0     +2.39E-03   +5.31E-04     +5.67E-01    +1.37E+00, +1.12E+00, -2.02E+00, +1.02E+00, +3.87E+00, +4.02E+00\n",
      " 1     00:00:01         17           22          3689         11283        0        0     +2.34E-03   +5.03E-05     +2.42E-01    +1.37E+00, +1.12E+00, -2.02E+00, +1.02E+00, +3.87E+00, +4.02E+00\n",
      " 1     00:00:01         18           23          3692         11292        0        0     +2.29E-03   +5.34E-05     +5.84E-01    +1.37E+00, +1.12E+00, -2.02E+00, +1.02E+00, +3.87E+00, +4.02E+00\n",
      " 1     00:00:01         19           24          3690         11287        0        0     +2.18E-03   +1.09E-04     +1.32E+00    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.87E+00, +4.02E+00\n",
      " 1     00:00:01         20           25          3690         11280        0        0     +1.92E-03   +2.67E-04     +2.42E+00    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.87E+00, +4.02E+00\n",
      " 1     00:00:01         21           26          3695         11296        0        0     +1.41E-03   +5.08E-04     +3.47E+00    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.87E+00, +4.02E+00\n",
      " 1     00:00:01         22           27          3682         11266        0        0     +6.96E-04   +7.11E-04     +3.47E+00    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.87E+00, +4.02E+00\n",
      " 1     00:00:01         23           28          3615         11057        0        0     +4.85E-01                 +1.86E+02    +1.37E+00, +1.04E+00, -2.03E+00, +1.01E+00, +3.89E+00, +4.07E+00\n",
      " 1     00:00:01         23           29          3678         11264        0        0     +6.93E-04   +3.11E-06     +2.99E+00    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.87E+00, +4.02E+00\n",
      " 1     00:00:01         24           30          3680         11256        0        0     +1.92E-04   +5.01E-04     +1.56E+00    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         25           31          3681         11272        0        0     +5.63E-05   +1.35E-04     +2.83E-01    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         26           32          3688         11275        0        0     +4.09E-05   +1.54E-05     +1.68E-01    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         27           33          3688         11279        0        0     +3.80E-05   +2.85E-06     +2.31E-01    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         28           34          3686         11281        0        0     +2.94E-05   +8.58E-06     +2.60E-01    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         29           35          3688         11284        0        0     +1.06E-05   +1.88E-05     +2.35E-01    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         30           36          3686         11284        0        0     +6.18E-06   +4.47E-06     +3.39E-01    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         31           37          3687         11280        0        0     +2.06E-06   +4.12E-06     +5.75E-02    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         32           38          3690         11285        0        0     +1.08E-07   +1.96E-06     +5.36E-03    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         33           39          3686         11263        0        0     +8.53E-09   +9.95E-08     +1.22E-02    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         34           40          3687         11274        0        0     +1.61E-07                 +1.04E-01    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         34           41          3688         11278        0        0     +7.73E-09   +8.06E-10     +1.84E-02    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         35           42          3688         11278        0        0     +8.69E-10   +6.86E-09     +4.90E-03    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:02         36           43          3687         11279        0        0     +3.79E-11   +8.31E-10     +2.20E-04    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         37           44          3688         11283        0        0     +1.77E-12   +3.61E-11     +1.73E-04    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         38           45          3687         11275        0        0     +4.79E-12                 +9.96E-05    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         38           46          3688         11275        0        0     +9.21E-13   +8.48E-13     +8.58E-05    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         39           47          3690         11276        0        0     +7.99E-15   +9.13E-13     +1.59E-06    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         40           48          3688         11282        0        0     +5.60E-17   +7.94E-15     +1.09E-06    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         41           49          3686         11289        0        0     +2.54E-18   +5.34E-17     +2.05E-07    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      " 1     00:00:01         42           50          3686         11278        0        0     +6.30E-19   +1.91E-18     +7.54E-08    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Clipped  Objective   Objective     Projected                                                                    \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares    Costs     Value    Improvement  Gradient Norm                               Theta                              \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  -------  ---------  -----------  -------------  ----------------------------------------------------------------\n",
      " 1     00:00:01         43           51          3688         11279        0        0     +1.59E-21   +6.29E-19     +4.13E-09    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      "\n",
      "Optimization completed after 00:00:48.\n",
      "Computing the Hessian and updating the weighting matrix ...\n",
      "Computed results after 00:00:13.\n",
      "\n",
      "Problem Results Summary:\n",
      "=======================================================================================================================\n",
      "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares    Costs   Condition Number  Condition Number \n",
      "----  ---------  -------------  ---------------  ---------------  -------  -------  ----------------  -----------------\n",
      " 1    +1.59E-21    +4.13E-09       +1.83E+01        +5.69E+04        0        0        +3.83E+03          +2.79E+04    \n",
      "=======================================================================================================================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Clipped  Objective   Objective     Projected                                                                    \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares    Costs     Value    Improvement  Gradient Norm                               Theta                              \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  -------  ---------  -----------  -------------  ----------------------------------------------------------------\n",
      " 2     00:00:01         0             1            0           600         0        0     +1.52E-21                 +3.71E-09    +1.37E+00, +1.11E+00, -2.02E+00, +1.02E+00, +3.86E+00, +4.02E+00\n",
      "\n",
      "Optimization completed after 00:00:01.\n",
      "Computing the Hessian and estimating standard errors ...\n",
      "Computed results after 00:00:08.\n",
      "\n",
      "Problem Results Summary:\n",
      "=======================================================================================================================\n",
      "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares    Costs   Condition Number  Condition Number \n",
      "----  ---------  -------------  ---------------  ---------------  -------  -------  ----------------  -----------------\n",
      " 2    +1.52E-21    +3.71E-09       +1.82E+01        +5.51E+04        0        0        +3.84E+03          +2.79E+04    \n",
      "=======================================================================================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "===========================================================================\n",
      "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
      "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
      "-----------  ---------  ------------  -----------  -----------  -----------\n",
      " 00:01:10       Yes          44           55         186875       573904   \n",
      "===========================================================================\n",
      "\n",
      "Nonlinear Coefficient Estimates (Robust SEs in Parentheses):\n",
      "===================================\n",
      " Sigma:     satellite      wired   \n",
      "---------  -----------  -----------\n",
      "satellite   +1.37E+00              \n",
      "           (+2.31E-01)             \n",
      "                                   \n",
      "  wired     +0.00E+00    +1.11E+00 \n",
      "                        (+2.53E-01)\n",
      "===================================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "==================================================\n",
      "  prices          x        satellite      wired   \n",
      "-----------  -----------  -----------  -----------\n",
      " -2.02E+00    +1.02E+00    +3.86E+00    +4.02E+00 \n",
      "(+6.86E-02)  (+4.50E-02)  (+2.36E-01)  (+2.33E-01)\n",
      "==================================================\n",
      "\n",
      "Gamma Estimates (Robust SEs in Parentheses):\n",
      "========================\n",
      "     1            w     \n",
      "-----------  -----------\n",
      " +7.93E-01    +2.05E-01 \n",
      "(+1.56E-02)  (+7.15E-03)\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "# Re-estimate with optimal instruments\n",
    "columns_to_drop = [col for col in product_data.columns \n",
    "                   if 'instruments' in col]\n",
    "product_data = product_data.drop(columns=columns_to_drop)\n",
    "optimal_iv2 = results2.compute_optimal_instruments(seed=1995)\n",
    "for i in range(optimal_iv2.demand_instruments.shape[1]-3):\n",
    "    product_data[f'demand_instruments{i}'] = optimal_iv2.demand_instruments[:, i]\n",
    "problem3 = pyblp.Problem(product_formulations2, product_data, \n",
    "                         costs_type='log', integration=integration)\n",
    "optimal_iv_results2 = problem3.solve(sigma=np.eye(2), \n",
    "                                      beta=results2.beta, \n",
    "                                      costs_bounds=(0.001, None), \n",
    "                                      initial_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06d4c927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta Comparison:\n",
      "          Estimates                 SEs            \n",
      "            PyBLP D PyBLP D & S PyBLP D PyBLP D & S\n",
      "prices       -2.033      -2.022   0.068       0.069\n",
      "x             1.011       1.017   0.045       0.045\n",
      "satellite     3.910       3.864   0.229       0.236\n",
      "wired         4.093       4.015   0.222       0.233\n",
      "\n",
      "Sigma Comparison:\n",
      "          Estimates                 SEs            \n",
      "            PyBLP D PyBLP D & S PyBLP D PyBLP D & S\n",
      "satellite     1.349       1.371   0.227       0.231\n",
      "wired         1.002       1.111   0.255       0.253\n",
      "\n",
      "\n",
      "Gamma Estimates (only from joint D & S estimation):\n",
      "    Estimates         SEs\n",
      "  PyBLP D & S PyBLP D & S\n",
      "1       0.793       0.016\n",
      "w       0.205       0.007\n"
     ]
    }
   ],
   "source": [
    "# Compare individual and joint PyBLP estimates for beta\n",
    "pyblp_beta_comparison = pd.DataFrame(index=optimal_iv_results1.beta_labels, data={\n",
    "    (\"Estimates\", \"PyBLP D\"): optimal_iv_results1.beta.flat,  # prices, x, satellite, wired\n",
    "    (\"Estimates\", \"PyBLP D & S\"): optimal_iv_results2.beta.flat,\n",
    "    (\"SEs\", \"PyBLP D\"): optimal_iv_results1.beta_se.flat,\n",
    "    (\"SEs\", \"PyBLP D & S\"): optimal_iv_results2.beta_se.flat\n",
    "})\n",
    "print(\"Beta Comparison:\")\n",
    "print(pyblp_beta_comparison)\n",
    "# Compare sigma estimates\n",
    "pyblp_sigma_comparison = pd.DataFrame(index=optimal_iv_results1.sigma_labels, data={\n",
    "    (\"Estimates\", \"PyBLP D\"): optimal_iv_results1.sigma.diagonal(),\n",
    "    (\"Estimates\", \"PyBLP D & S\"): optimal_iv_results2.sigma.diagonal(),\n",
    "    (\"SEs\", \"PyBLP D\"): optimal_iv_results1.sigma_se.diagonal(),\n",
    "    (\"SEs\", \"PyBLP D & S\"): optimal_iv_results2.sigma_se.diagonal()\n",
    "})\n",
    "print(\"\\nSigma Comparison:\")\n",
    "print(pyblp_sigma_comparison)\n",
    "\n",
    "# Compare gamma estimates (only available in joint estimation)\n",
    "print(\"\\n\\nGamma Estimates (only from joint D & S estimation):\")\n",
    "pyblp_gamma_comparison = pd.DataFrame(index=optimal_iv_results2.gamma_labels, data={\n",
    "    (\"Estimates\", \"PyBLP D & S\"): optimal_iv_results2.gamma.flat,\n",
    "    (\"SEs\", \"PyBLP D & S\"): optimal_iv_results2.gamma_se.flat,\n",
    "})\n",
    "print(pyblp_gamma_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8228d9",
   "metadata": {},
   "source": [
    "### 10. \n",
    "Using your preferred estimates from the prior step (explain your preference), provide\n",
    "a table comparing the estimated own-price elasticities to the true own-price elasticities.\n",
    "Provide two additional tables showing the true matrix of diversion ratios and the diversion\n",
    "ratios implied by your estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "#VSC-7655b5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TRUE elasticities from Q8 (true params, observed shares)...\n",
      "  (Already computed 600 markets)\n",
      "Computing ESTIMATED elasticities (estimated params, observed shares)...\n",
      "Computing elasticities with respect to prices ...\n",
      "Finished after 00:00:00.\n",
      "\n",
      "Parameter Comparison:\n",
      "True α = -2.0, Estimated α = -2.022\n",
      "True σ_sat = 1.0, Estimated σ_sat = 1.371\n",
      "True σ_wired = 1.0, Estimated σ_wired = 1.111\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TABLE 1: OWN-PRICE ELASTICITY COMPARISON\n",
      "True = RC logit with TRUE params (-2, 1, 4, 4, 1, 1) on OBSERVED shares\n",
      "Estimated = RC logit with ESTIMATED params from pyBLP on OBSERVED shares\n",
      "================================================================================\n",
      "Product  True Elasticity  Estimated Elasticity  Difference   % Error\n",
      "  Sat 1          -5.4803               -5.3538      0.1265    2.3082\n",
      "  Sat 2          -5.3145               -5.1751      0.1394    2.6235\n",
      "Wired 1          -5.3772               -5.3618      0.0154    0.2863\n",
      "Wired 2          -5.4581               -5.4444      0.0137    0.2506\n",
      "\n",
      "Mean Absolute % Error: 1.37%\n",
      "\n",
      "Interpretation: Estimated |elasticities| are LOWER than true (flatter demand)\n",
      "  • Estimated σ > true σ → More heterogeneity → Products become less substitutable\n",
      "  • When consumers have diverse tastes (high σ), price changes affect fewer people\n",
      "  • Result: Demand is LESS elastic (lower |ε|) with higher σ\n",
      "  • This is OPPOSITE to homogeneous preferences where everyone reacts similarly\n",
      "================================================================================\n",
      "\n",
      "Using TRUE diversion ratios from Q8 (true params, observed shares)...\n",
      "  (Already computed 600 markets)\n",
      "Computing diversion ratios with respect to prices ...\n",
      "Finished after 00:00:00.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TABLE 2: TRUE DIVERSION RATIOS\n",
      "(from RC Logit with TRUE params: σ_sat=1.0, σ_wired=1.0, on OBSERVED shares)\n",
      "================================================================================\n",
      "Diagonal = diversion to outside option D_j0\n",
      "          Sat 1   Sat 2  Wired 1  Wired 2\n",
      "Sat 1    0.5248  0.2239   0.1303   0.1211\n",
      "Sat 2    0.2137  0.5316   0.1314   0.1233\n",
      "Wired 1  0.1237  0.1300   0.5324   0.2139\n",
      "Wired 2  0.1221  0.1292   0.2256   0.5231\n",
      "\n",
      "================================================================================\n",
      "TABLE 3: ESTIMATED DIVERSION RATIOS\n",
      "(from RC Logit with ESTIMATED params: σ_sat=1.371, σ_wired=1.111)\n",
      "================================================================================\n",
      "Diagonal = diversion to outside option D_j0\n",
      "          Sat 1   Sat 2  Wired 1  Wired 2\n",
      "Sat 1    0.4985  0.2652   0.1225   0.1138\n",
      "Sat 2    0.2532  0.5065   0.1241   0.1162\n",
      "Wired 1  0.1124  0.1181   0.5403   0.2291\n",
      "Wired 2  0.1109  0.1174   0.2410   0.5308\n",
      "\n",
      "================================================================================\n",
      "INTERPRETATION & KEY FINDING\n",
      "================================================================================\n",
      "D_jk = -(∂s_k/∂p_j) / (∂s_j/∂p_j) = -(s_k/s_j) * (ε_kj/ε_jj)\n",
      "  • Off-diagonal: Fraction of j's lost customers who switch to product k\n",
      "  • Diagonal: Fraction of j's lost customers who choose outside option\n",
      "\n",
      "SURPRISING FINDING: Diversion ratios relatively similar despite σ differences!\n",
      "  • True model (σ=1.0):  52.5% to outside\n",
      "  • Est. model (σ_sat=1.37, σ_wired=1.11):  49.9% to outside\n",
      "\n",
      "Example: When Sat 1 price ↑ 1%, where do lost customers go?\n",
      "  TRUE model:  52.5% to outside, 22.4% to Sat 2\n",
      "  EST. model:  49.9% to outside, 26.5% to Sat 2\n",
      "\n",
      "WHY are diversions similar despite different elasticities?\n",
      "  • Diversion D_jk = -(s_k/s_j) * (ε_kj/ε_jj) is a RATIO of elasticities\n",
      "  • Higher σ makes ALL elasticities flatter (lower |ε|)\n",
      "  • Since BOTH numerator (ε_kj) and denominator (ε_jj) decrease proportionally,\n",
      "    their RATIO stays relatively constant!\n",
      "  • This is why σ estimation errors affect elasticities more than diversions\n",
      "================================================================================\n",
      "Finished after 00:00:00.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TABLE 2: TRUE DIVERSION RATIOS\n",
      "(from RC Logit with TRUE params: σ_sat=1.0, σ_wired=1.0, on OBSERVED shares)\n",
      "================================================================================\n",
      "Diagonal = diversion to outside option D_j0\n",
      "          Sat 1   Sat 2  Wired 1  Wired 2\n",
      "Sat 1    0.5248  0.2239   0.1303   0.1211\n",
      "Sat 2    0.2137  0.5316   0.1314   0.1233\n",
      "Wired 1  0.1237  0.1300   0.5324   0.2139\n",
      "Wired 2  0.1221  0.1292   0.2256   0.5231\n",
      "\n",
      "================================================================================\n",
      "TABLE 3: ESTIMATED DIVERSION RATIOS\n",
      "(from RC Logit with ESTIMATED params: σ_sat=1.371, σ_wired=1.111)\n",
      "================================================================================\n",
      "Diagonal = diversion to outside option D_j0\n",
      "          Sat 1   Sat 2  Wired 1  Wired 2\n",
      "Sat 1    0.4985  0.2652   0.1225   0.1138\n",
      "Sat 2    0.2532  0.5065   0.1241   0.1162\n",
      "Wired 1  0.1124  0.1181   0.5403   0.2291\n",
      "Wired 2  0.1109  0.1174   0.2410   0.5308\n",
      "\n",
      "================================================================================\n",
      "INTERPRETATION & KEY FINDING\n",
      "================================================================================\n",
      "D_jk = -(∂s_k/∂p_j) / (∂s_j/∂p_j) = -(s_k/s_j) * (ε_kj/ε_jj)\n",
      "  • Off-diagonal: Fraction of j's lost customers who switch to product k\n",
      "  • Diagonal: Fraction of j's lost customers who choose outside option\n",
      "\n",
      "SURPRISING FINDING: Diversion ratios relatively similar despite σ differences!\n",
      "  • True model (σ=1.0):  52.5% to outside\n",
      "  • Est. model (σ_sat=1.37, σ_wired=1.11):  49.9% to outside\n",
      "\n",
      "Example: When Sat 1 price ↑ 1%, where do lost customers go?\n",
      "  TRUE model:  52.5% to outside, 22.4% to Sat 2\n",
      "  EST. model:  49.9% to outside, 26.5% to Sat 2\n",
      "\n",
      "WHY are diversions similar despite different elasticities?\n",
      "  • Diversion D_jk = -(s_k/s_j) * (ε_kj/ε_jj) is a RATIO of elasticities\n",
      "  • Higher σ makes ALL elasticities flatter (lower |ε|)\n",
      "  • Since BOTH numerator (ε_kj) and denominator (ε_jj) decrease proportionally,\n",
      "    their RATIO stays relatively constant!\n",
      "  • This is why σ estimation errors affect elasticities more than diversions\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Q9: Compare TRUE vs ESTIMATED Random Coefficients Elasticities/Diversions\n",
    "# ============================================================================\n",
    "# Reuse TRUE elasticities computed in Q8 to avoid redundancy\n",
    "print(\"Using TRUE elasticities from Q8 (true params, observed shares)...\")\n",
    "print(f\"  (Already computed {len(true_elasticity_matrices_for_div)} markets)\")\n",
    "true_elasticity_matrices_obs = true_elasticity_matrices_for_div  # Reuse from Q8\n",
    "avg_elasticity_matrix_true_rc = np.mean(true_elasticity_matrices_obs, axis=0)\n",
    "own_elasticities_rc_true = np.diag(avg_elasticity_matrix_true_rc)\n",
    "\n",
    "# Compute ESTIMATED elasticities using pyBLP's ESTIMATED parameters\n",
    "print(\"Computing ESTIMATED elasticities (estimated params, observed shares)...\")\n",
    "elasticities_rc_est2 = optimal_iv_results2.compute_elasticities()\n",
    "avg_elasticities_rc_est2 = elasticities_rc_est2.reshape((T, J, J)).mean(axis=0)\n",
    "own_elasticities_rc_est2 = np.diag(avg_elasticities_rc_est2)\n",
    "\n",
    "# Show parameter differences\n",
    "print(\"Parameter Comparison:\")\n",
    "print(f\"True α = -2.0, Estimated α = {optimal_iv_results2.beta[0,0]:.3f}\")\n",
    "print(f\"True σ_sat = 1.0, Estimated σ_sat = {optimal_iv_results2.sigma[0,0]:.3f}\")\n",
    "print(f\"True σ_wired = 1.0, Estimated σ_wired = {optimal_iv_results2.sigma[1,1]:.3f}\")\n",
    "print()\n",
    "\n",
    "# Create comparison table\n",
    "product_labels = ['Sat 1', 'Sat 2', 'Wired 1', 'Wired 2']\n",
    "elasticity_comparison_rc = pd.DataFrame({\n",
    "    'Product': product_labels,\n",
    "    'True Elasticity': own_elasticities_rc_true,\n",
    "    'Estimated Elasticity': own_elasticities_rc_est2,\n",
    "    'Difference': own_elasticities_rc_est2 - own_elasticities_rc_true,\n",
    "    '% Error': np.abs((own_elasticities_rc_est2 - own_elasticities_rc_true) / own_elasticities_rc_true * 100)\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TABLE 1: OWN-PRICE ELASTICITY COMPARISON\")\n",
    "print(\"True = RC logit with TRUE params (-2, 1, 4, 4, 1, 1) on OBSERVED shares\")\n",
    "print(\"Estimated = RC logit with ESTIMATED params from pyBLP on OBSERVED shares\")\n",
    "print(\"=\" * 80)\n",
    "print(elasticity_comparison_rc.to_string(index=False, float_format=lambda x: f'{x:9.4f}'))\n",
    "print(f\"\\nMean Absolute % Error: {elasticity_comparison_rc['% Error'].mean():.2f}%\")\n",
    "print()\n",
    "print(\"Interpretation: Estimated |elasticities| are LOWER than true (flatter demand)\")\n",
    "print(\"  • Estimated σ > true σ → More heterogeneity → Products become less substitutable\")\n",
    "print(\"  • When consumers have diverse tastes (high σ), price changes affect fewer people\")\n",
    "print(\"  • Result: Demand is LESS elastic (lower |ε|) with higher σ\")\n",
    "print(\"  • This is OPPOSITE to homogeneous preferences where everyone reacts similarly\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# --- DIVERSION RATIO COMPARISON ---\n",
    "# Reuse TRUE diversion ratios computed in Q8 to avoid redundancy\n",
    "print(\"\\nUsing TRUE diversion ratios from Q8 (true params, observed shares)...\")\n",
    "print(f\"  (Already computed {len(true_diversion_matrices)} markets)\")\n",
    "true_diversion_matrices_obs = true_diversion_matrices  # Reuse from Q8\n",
    "true_avg_diversion_rc = np.mean(true_diversion_matrices_obs, axis=0)\n",
    "\n",
    "# RC estimated diversion ratios from PREFERRED specification (D+S)\n",
    "diversion_rc_est2 = optimal_iv_results2.compute_diversion_ratios()\n",
    "avg_diversion_rc_est2 = diversion_rc_est2.reshape((T, J, J)).mean(axis=0)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TABLE 2: TRUE DIVERSION RATIOS\")\n",
    "print(\"(from RC Logit with TRUE params: σ_sat=1.0, σ_wired=1.0, on OBSERVED shares)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Diagonal = diversion to outside option D_j0\")\n",
    "true_div_df_rc = pd.DataFrame(true_avg_diversion_rc, index=product_labels, columns=product_labels)\n",
    "print(true_div_df_rc.to_string(float_format=lambda x: f'{x:7.4f}'))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TABLE 3: ESTIMATED DIVERSION RATIOS\")\n",
    "print(f\"(from RC Logit with ESTIMATED params: σ_sat={optimal_iv_results2.sigma[0,0]:.3f}, σ_wired={optimal_iv_results2.sigma[1,1]:.3f})\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Diagonal = diversion to outside option D_j0\")\n",
    "est_div_df_rc2 = pd.DataFrame(avg_diversion_rc_est2, index=product_labels, columns=product_labels)\n",
    "print(est_div_df_rc2.to_string(float_format=lambda x: f'{x:7.4f}'))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INTERPRETATION & KEY FINDING\")\n",
    "print(\"=\" * 80)\n",
    "print(\"D_jk = -(∂s_k/∂p_j) / (∂s_j/∂p_j) = -(s_k/s_j) * (ε_kj/ε_jj)\")\n",
    "print(\"  • Off-diagonal: Fraction of j's lost customers who switch to product k\")\n",
    "print(\"  • Diagonal: Fraction of j's lost customers who choose outside option\")\n",
    "print()\n",
    "print(\"SURPRISING FINDING: Diversion ratios relatively similar despite σ differences!\")\n",
    "print(f\"  • True model (σ=1.0):  {true_avg_diversion_rc[0,0]:.1%} to outside\")\n",
    "print(f\"  • Est. model (σ_sat={optimal_iv_results2.sigma[0,0]:.2f}, σ_wired={optimal_iv_results2.sigma[1,1]:.2f}):  {avg_diversion_rc_est2[0,0]:.1%} to outside\")\n",
    "print()\n",
    "print(\"Example: When Sat 1 price ↑ 1%, where do lost customers go?\")\n",
    "print(f\"  TRUE model:  {true_avg_diversion_rc[0,0]:.1%} to outside, {true_avg_diversion_rc[0,1]:.1%} to Sat 2\")\n",
    "print(f\"  EST. model:  {avg_diversion_rc_est2[0,0]:.1%} to outside, {avg_diversion_rc_est2[0,1]:.1%} to Sat 2\")\n",
    "print()\n",
    "print(\"WHY are diversions similar despite different elasticities?\")\n",
    "print(\"  • Diversion D_jk = -(s_k/s_j) * (ε_kj/ε_jj) is a RATIO of elasticities\")\n",
    "print(\"  • Higher σ makes ALL elasticities flatter (lower |ε|)\")\n",
    "print(\"  • Since BOTH numerator (ε_kj) and denominator (ε_jj) decrease proportionally,\")\n",
    "print(\"    their RATIO stays relatively constant!\")\n",
    "print(\"  • This is why σ estimation errors affect elasticities more than diversions\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873bc298",
   "metadata": {},
   "source": [
    "## 6 Merger Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b777443f",
   "metadata": {},
   "source": [
    "### 10.\n",
    "Suppose two of the four firms were to merge. Give a brief\n",
    "intuition for what theory tells us is likely to happen to the equilibrium\n",
    "prices of each good $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8761404a",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "When two firms merge, all prices increase. The mechanism: merged firms internalize competition between their own products.\n",
    "\n",
    "**Pre-merger FOC (firm $f$, product $j$):**\n",
    "$$p_j - mc_j = -\\frac{s_j}{\\partial s_j/\\partial p_j}$$\n",
    "\n",
    "**Post-merger FOC:**\n",
    "$$p_j - mc_j = -\\left[\\frac{\\partial s_j}{\\partial p_j}\\right]^{-1}\\left[s_j + \\sum_{k \\in \\mathcal{J}_f, k \\neq j} \\frac{\\partial s_k}{\\partial p_j}(p_k - mc_k)\\right]$$\n",
    "\n",
    "The additional term $\\sum_{k \\in \\mathcal{J}_f, k \\neq j} \\frac{\\partial s_k}{\\partial p_j}(p_k - mc_k)$ captures recaptured demand: customers who switch from $j$ to the merged firm's product $k$.\n",
    "\n",
    "**Price effects:**\n",
    "\n",
    "1. **Merging firms:** Large increases, proportional to diversion ratios\n",
    "   - Change in markup: $\\Delta \\text{Markup}_j \\approx \\sum_{k \\in \\mathcal{J}_f, k \\neq j} D_{jk}(p_k - mc_k)$\n",
    "   - Where $D_{jk} = -(\\partial s_k/\\partial p_j)/(\\partial s_j/\\partial p_j)$ = fraction of $j$'s lost customers switching to $k$\n",
    "\n",
    "2. **Non-merging firms:** Small increases from strategic complementarity\n",
    "   - Higher competitor prices → shift in residual demand → optimal to raise own prices\n",
    "   - Magnitude depends on cross-elasticities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef269d8",
   "metadata": {},
   "source": [
    "### 11.\n",
    "Suppose firms 1 and 2 are proposing to merge. Use the \\texttt{pyBLP}\n",
    "merger simulation procedure to provide a prediction of the post-merger\n",
    "equilibrium prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0eddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline marginal costs, markups, profits, and consumer surplus under the estimated demand+supply model\n",
    "costs = optimal_iv_results2.compute_costs()\n",
    "markups = optimal_iv_results2.compute_markups(costs=costs)\n",
    "profits = optimal_iv_results2.compute_profits(costs=costs)\n",
    "cs = optimal_iv_results2.compute_consumer_surpluses()\n",
    "\n",
    "# Get pre-merger prices (reshaped as T×J to get average per product)\n",
    "pre_merger_prices = product_data['prices'].values\n",
    "pre_merger_prices_avg = pre_merger_prices.reshape((T, J)).mean(axis=0)\n",
    "\n",
    "# Create merger firm IDs: merge firms 1 and 2 into firm 1\n",
    "# Firms 1 and 2 (satellite) → firm 1\n",
    "# Firms 3 and 4 (wired) remain unchanged\n",
    "merger_firm_ids = product_data['firm_ids'].copy()\n",
    "merger_firm_ids[merger_firm_ids == 2] = 1  # Firm 2 becomes firm 1\n",
    "\n",
    "# Compute post-merger equilibrium prices using pyBLP's compute_prices method\n",
    "# This solves the first-order conditions under the new ownership structure\n",
    "post_merger_prices = optimal_iv_results2.compute_prices(\n",
    "    firm_ids=merger_firm_ids,\n",
    "    iteration=pyblp.Iteration('simple', {'atol': 1e-12})\n",
    ")\n",
    "\n",
    "# Reshape to get average prices per product\n",
    "post_merger_prices_avg = post_merger_prices.reshape((T, J)).mean(axis=0)\n",
    "\n",
    "# Calculate price changes\n",
    "price_changes = post_merger_prices_avg - pre_merger_prices_avg\n",
    "pct_price_changes = (price_changes / pre_merger_prices_avg) * 100\n",
    "\n",
    "merger_results_df = pd.DataFrame({\n",
    "    'Product': product_labels,\n",
    "    'Type': ['Satellite', 'Satellite', 'Wired', 'Wired'],\n",
    "    'Firm (Pre)': [1, 2, 3, 4],\n",
    "    'Firm (Post)': [1, 1, 3, 4],\n",
    "    'Pre-Merger Price': pre_merger_prices_avg,\n",
    "    'Post-Merger Price': post_merger_prices_avg,\n",
    "    'Price Change ($)': price_changes,\n",
    "    'Price Change (%)': pct_price_changes\n",
    "})\n",
    "numeric_columns = ['Pre-Merger Price', 'Post-Merger Price', 'Price Change ($)', 'Price Change (%)']\n",
    "merger_results_df[numeric_columns] = merger_results_df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "# Diagnostics inspired by the post_estimation tutorial\n",
    "post_merger_shares = optimal_iv_results2.compute_shares(post_merger_prices)\n",
    "post_merger_markups = optimal_iv_results2.compute_markups(post_merger_prices, costs)\n",
    "post_merger_profits = optimal_iv_results2.compute_profits(post_merger_prices, post_merger_shares, costs)\n",
    "post_merger_cs = optimal_iv_results2.compute_consumer_surpluses(post_merger_prices)\n",
    "\n",
    "baseline_metrics = {\n",
    "    'Average Price ($)': pre_merger_prices_avg.mean(),\n",
    "    'Average Markup ($)': markups.reshape((T, J)).mean(),\n",
    "    'Total Profit ($)': profits.sum(),\n",
    "    'Average CS ($)': cs.mean(),\n",
    "}\n",
    "post_merger_metrics = {\n",
    "    'Average Price ($)': post_merger_prices_avg.mean(),\n",
    "    'Average Markup ($)': post_merger_markups.reshape((T, J)).mean(),\n",
    "    'Total Profit ($)': post_merger_profits.sum(),\n",
    "    'Average CS ($)': post_merger_cs.mean(),\n",
    "}\n",
    "metric_names = list(baseline_metrics.keys())\n",
    "merger_metric_summary = pd.DataFrame({\n",
    "    'Metric': metric_names,\n",
    "    'Pre-Merger': [baseline_metrics[m] for m in metric_names],\n",
    "    'Post-Merger': [post_merger_metrics[m] for m in metric_names]\n",
    "})\n",
    "merger_metric_summary['Change'] = (\n",
    "    merger_metric_summary['Post-Merger'] - merger_metric_summary['Pre-Merger']\n",
    ")\n",
    "merger_metric_summary = merger_metric_summary.astype({\n",
    "    'Pre-Merger': float,\n",
    "    'Post-Merger': float,\n",
    "    'Change': float\n",
    "})\n",
    "merger_metric_summary = merger_metric_summary.set_index('Metric')\n",
    "IPython.display.display(merger_results_df.style.format({\n",
    "    'Pre-Merger Price': '{:,.4f}'.format,\n",
    "    'Post-Merger Price': '{:,.4f}'.format,\n",
    "    'Price Change ($)': '{:,.4f}'.format,\n",
    "    'Price Change (%)': '{:,.2f}'.format,\n",
    "}))\n",
    "IPython.display.display(merger_metric_summary.style.format('{:,.3f}'))\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.bar(product_labels, pct_price_changes, color=['#4c72b0', '#4c72b0', '#dd8452', '#dd8452'])\n",
    "ax.axhline(0, color='black', linewidth=0.8)\n",
    "ax.set_ylabel('Price Change (%)')\n",
    "ax.set_title('Within-Nest Merger (Firms 1 & 2): Percent Price Changes')\n",
    "for idx, value in enumerate(pct_price_changes):\n",
    "    ax.text(idx, value + (0.1 if value >= 0 else -0.3), f'{value:.2f}%', ha='center', va='bottom' if value >= 0 else 'top', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33319f8",
   "metadata": {},
   "source": [
    "### 13. \n",
    "Now suppose instead that firms 1 and 3 are the ones to merge. Re-run the merger\n",
    "simulation. Provide a table comparing the (average across markets) predicted merger-\n",
    "induced price changes for this merger and that in part 11. Interpret the differences\n",
    "between the predictions for the two mergers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8bd1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# QUESTION 13: MERGER SIMULATION (Firms 1 and 3)\n",
    "# ========================================================================\n",
    "# Firm 1 is satellite provider, Firm 3 is wired provider (cross-nest merger)\n",
    "\n",
    "# Note: pre_merger_prices, post_merger_prices, and mean_pct_change_within \n",
    "# already computed in Question 11\n",
    "\n",
    "# Create merger firm IDs: merge firms 1 and 3 into firm 1\n",
    "# Firm 1 (satellite) + Firm 3 (wired) → firm 1\n",
    "# Firms 2 and 4 remain unchanged\n",
    "merger_firm_ids_cross = product_data['firm_ids'].copy()\n",
    "merger_firm_ids_cross[merger_firm_ids_cross == 3] = 1  # Firm 3 becomes firm 1\n",
    "\n",
    "# Compute post-merger equilibrium prices for cross-nest merger\n",
    "post_merger_prices_cross = optimal_iv_results2.compute_prices(\n",
    "    firm_ids=merger_firm_ids_cross,\n",
    "    iteration=pyblp.Iteration('simple', {'atol': 1e-12})\n",
    ")\n",
    "\n",
    "# Reshape and calculate changes\n",
    "post_merger_prices_cross_matrix = post_merger_prices_cross.reshape((T, J))\n",
    "post_merger_prices_cross_avg = post_merger_prices_cross_matrix.mean(axis=0)\n",
    "mean_pct_change_cross = ((post_merger_prices_cross_avg - pre_merger_prices_avg) / pre_merger_prices_avg * 100)\n",
    "\n",
    "merger_results_cross_df = pd.DataFrame({\n",
    "    'Product': product_labels,\n",
    "    'Type': ['Satellite', 'Satellite', 'Wired', 'Wired'],\n",
    "    'Firm (Pre)': [1, 2, 3, 4],\n",
    "    'Firm (Post)': [1, 2, 1, 4],\n",
    "    'Pre-Merger Price': pre_merger_prices_avg,\n",
    "    'Post-Merger Price': post_merger_prices_cross_avg,\n",
    "    'Price Change ($)': post_merger_prices_cross_avg - pre_merger_prices_avg,\n",
    "    'Price Change (%)': mean_pct_change_cross\n",
    "})\n",
    "numeric_columns_cross = ['Pre-Merger Price', 'Post-Merger Price', 'Price Change ($)', 'Price Change (%)']\n",
    "merger_results_cross_df[numeric_columns_cross] = merger_results_cross_df[numeric_columns_cross].apply(pd.to_numeric, errors='coerce')\n",
    "# Diagnostics parallel to the post_estimation tutorial\n",
    "post_merger_shares_cross = optimal_iv_results2.compute_shares(post_merger_prices_cross)\n",
    "post_merger_markups_cross = optimal_iv_results2.compute_markups(post_merger_prices_cross, costs)\n",
    "post_merger_profits_cross = optimal_iv_results2.compute_profits(\n",
    "    post_merger_prices_cross,\n",
    "    post_merger_shares_cross,\n",
    "    costs\n",
    ")\n",
    "post_merger_cs_cross = optimal_iv_results2.compute_consumer_surpluses(post_merger_prices_cross)\n",
    "\n",
    "cross_merger_metrics = {\n",
    "    'Average Price ($)': post_merger_prices_cross_avg.mean(),\n",
    "    'Average Markup ($)': post_merger_markups_cross.reshape((T, J)).mean(),\n",
    "    'Total Profit ($)': post_merger_profits_cross.sum(),\n",
    "    'Average CS ($)': post_merger_cs_cross.mean(),\n",
    "}\n",
    "cross_metric_summary = pd.DataFrame({\n",
    "    'Metric': metric_names,\n",
    "    'Within-Nest (1&2)': [post_merger_metrics[m] for m in metric_names],\n",
    "    'Cross-Nest (1&3)': [cross_merger_metrics[m] for m in metric_names]\n",
    "})\n",
    "cross_metric_summary['Difference (Cross - Within)'] = (\n",
    "    cross_metric_summary['Cross-Nest (1&3)'] - cross_metric_summary['Within-Nest (1&2)']\n",
    ")\n",
    "cross_metric_summary = cross_metric_summary.astype({\n",
    "    'Within-Nest (1&2)': float,\n",
    "    'Cross-Nest (1&3)': float,\n",
    "    'Difference (Cross - Within)': float,\n",
    "})\n",
    "cross_metric_summary = cross_metric_summary.set_index('Metric')\n",
    "\n",
    "IPython.display.display(merger_results_cross_df.style.format({\n",
    "    'Pre-Merger Price': '{:,.4f}'.format,\n",
    "    'Post-Merger Price': '{:,.4f}'.format,\n",
    "    'Price Change ($)': '{:,.4f}'.format,\n",
    "    'Price Change (%)': '{:,.2f}'.format,\n",
    "}))\n",
    "IPython.display.display(cross_metric_summary.style.format('{:,.3f}'))\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.bar(product_labels, mean_pct_change_cross, color=['#4c72b0', '#55a868', '#4c72b0', '#55a868'])\n",
    "ax.axhline(0, color='black', linewidth=0.8)\n",
    "ax.set_ylabel('Price Change (%)')\n",
    "ax.set_title('Cross-Nest Merger (Firms 1 & 3): Percent Price Changes')\n",
    "for idx, value in enumerate(mean_pct_change_cross):\n",
    "    ax.text(idx, value + (0.1 if value >= 0 else -0.3), f'{value:.2f}%', ha='center', va='bottom' if value >= 0 else 'top', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table: Within-nest vs Cross-nest mergers\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Product': product_labels,\n",
    "    'Within-Nest (%)': pct_price_changes,\n",
    "    'Cross-Nest (%)': mean_pct_change_cross,\n",
    "    'Difference (pp)': mean_pct_change_cross - pct_price_changes\n",
    "})\n",
    "comparison_df[['Within-Nest (%)', 'Cross-Nest (%)', 'Difference (pp)']] = comparison_df[['Within-Nest (%)', 'Cross-Nest (%)', 'Difference (pp)']].apply(pd.to_numeric, errors='coerce')\n",
    "IPython.display.display(comparison_df.style.format({\n",
    "    'Within-Nest (%)': '{:,.2f}'.format,\n",
    "    'Cross-Nest (%)': '{:,.2f}'.format,\n",
    "    'Difference (pp)': '{:,.2f}'.format,\n",
    "}))\n",
    "indices = np.arange(len(product_labels))\n",
    "width = 0.35\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.bar(indices - width / 2, pct_price_changes, width, label='Within-Nest (1&2)', color='#4c72b0')\n",
    "ax.bar(indices + width / 2, mean_pct_change_cross, width, label='Cross-Nest (1&3)', color='#55a868')\n",
    "ax.axhline(0, color='black', linewidth=0.8)\n",
    "ax.set_xticks(indices)\n",
    "ax.set_xticklabels(product_labels)\n",
    "ax.set_ylabel('Price Change (%)')\n",
    "ax.set_title('Percent Price Changes: Within-Nest vs Cross-Nest Mergers')\n",
    "ax.legend()\n",
    "for idx, value in enumerate(pct_price_changes):\n",
    "    ax.text(indices[idx] - width / 2, value + (0.1 if value >= 0 else -0.3), f'{value:.2f}%', ha='center', va='bottom' if value >= 0 else 'top', fontsize=8)\n",
    "for idx, value in enumerate(mean_pct_change_cross):\n",
    "    ax.text(indices[idx] + width / 2, value + (0.1 if value >= 0 else -0.3), f'{value:.2f}%', ha='center', va='bottom' if value >= 0 else 'top', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10724b2",
   "metadata": {},
   "source": [
    "### 14. \n",
    "Thus far you have assumed that there are no efficiencies resulting from the merger.\n",
    "Explain briefly why a merger-specific reduction in marginal cost could mean that a merger\n",
    "is welfare-enhancing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4cb18b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0edffe0",
   "metadata": {},
   "source": [
    "### 15.\n",
    "Consider the merger between firms 1 and 2, and suppose the firms\n",
    "demonstrate that by merging they would reduce marginal cost of each of their\n",
    "products by 15\\%. Furthermore, suppose that they demonstrate that this cost\n",
    "reduction could not be achieved without merging.    Using the \\texttt{pyBLP} software, re-run the merger simulation\n",
    "with the 15\\% cost saving. Show the predicted post-merger price changes (again,\n",
    "for each product, averaged across markets). What is the predicted impact of\n",
    "the merger on consumer welfare,\\footnote{%\n",
    "Note that because we have quasilinear preferences, consumer surplus is a\n",
    "valid measure of aggregate consumer welfare under the usual assumption of\n",
    "optimal redistribution.} assuming that the total measure of consumers $%\n",
    "M_{t} $ is the same in each market  $t$? Explain why this additional assumption\n",
    "(or data on the correct values of $M_{t}$) is needed here, whereas up to\n",
    "this point it was without loss to assume $M_{t}=1$. What is the predicted\n",
    "impact of the merger on total welfare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7003d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume same market size M_t for all markets (needed for welfare calculation)\n",
    "# We'll use M_t = 1000 consumers per market as a reasonable assumption\n",
    "M_t = 1000\n",
    "\n",
    "# Get estimated marginal costs from optimal_iv_results2\n",
    "marginal_costs = optimal_iv_results2.compute_costs()\n",
    "\n",
    "# Create a copy with 15% cost reduction for firms 1 and 2\n",
    "marginal_costs_efficiency = marginal_costs.copy()\n",
    "\n",
    "# Apply 15% reduction (multiply by 0.85) to firms 1 and 2 products\n",
    "# More efficient approach using boolean indexing\n",
    "products_1_2 = product_data['firm_ids'].isin([1, 2])\n",
    "marginal_costs_efficiency[products_1_2] *= 0.85\n",
    "\n",
    "# Use the same merger firm IDs as Question 11\n",
    "# (firm 2 becomes firm 1, already computed earlier as merger_firm_ids)\n",
    "\n",
    "# Compute post-merger prices WITH efficiency gains\n",
    "post_merger_prices_efficiency = optimal_iv_results2.compute_prices(\n",
    "    firm_ids=merger_firm_ids,  # Reuse from Q11\n",
    "    costs=marginal_costs_efficiency,\n",
    "    iteration=pyblp.Iteration('simple', {'atol': 1e-12})\n",
    ")\n",
    "\n",
    "# Reshape and calculate changes\n",
    "post_merger_prices_eff_matrix = post_merger_prices_efficiency.reshape((T, J))\n",
    "post_merger_prices_eff_avg = post_merger_prices_eff_matrix.mean(axis=0)\n",
    "\n",
    "# Calculate price changes relative to pre-merger baseline\n",
    "price_changes_eff = post_merger_prices_eff_avg - pre_merger_prices_avg\n",
    "pct_price_changes_eff = (price_changes_eff / pre_merger_prices_avg) * 100\n",
    "\n",
    "merger_efficiency_df = pd.DataFrame({\n",
    "    'Product': product_labels,\n",
    "    'Type': ['Satellite', 'Satellite', 'Wired', 'Wired'],\n",
    "    'Firm (Pre)': [1, 2, 3, 4],\n",
    "    'Firm (Post)': [1, 1, 3, 4],\n",
    "    'Pre-Merger Price': pre_merger_prices_avg,\n",
    "    'Post-Merger Price': post_merger_prices_eff_avg,\n",
    "    'Price Change ($)': price_changes_eff,\n",
    "    'Price Change (%)': pct_price_changes_eff\n",
    "})\n",
    "numeric_columns_eff = ['Pre-Merger Price', 'Post-Merger Price', 'Price Change ($)', 'Price Change (%)']\n",
    "merger_efficiency_df[numeric_columns_eff] = merger_efficiency_df[numeric_columns_eff].apply(pd.to_numeric, errors='coerce')\n",
    "comparison_eff_df = pd.DataFrame({\n",
    "    'Product': product_labels,\n",
    "    'No Efficiency (%)': pct_price_changes,  # From Q11\n",
    "    'With 15% Cost Cut (%)': pct_price_changes_eff,\n",
    "    'Difference (pp)': pct_price_changes_eff - pct_price_changes\n",
    "})\n",
    "comparison_eff_df[['No Efficiency (%)', 'With 15% Cost Cut (%)', 'Difference (pp)']] = comparison_eff_df[['No Efficiency (%)', 'With 15% Cost Cut (%)', 'Difference (pp)']].apply(pd.to_numeric, errors='coerce')\n",
    "IPython.display.display(merger_efficiency_df.style.format({\n",
    "    'Pre-Merger Price': '{:,.4f}'.format,\n",
    "    'Post-Merger Price': '{:,.4f}'.format,\n",
    "    'Price Change ($)': '{:,.4f}'.format,\n",
    "    'Price Change (%)': '{:,.2f}'.format,\n",
    "}))\n",
    "IPython.display.display(comparison_eff_df.style.format({\n",
    "    'No Efficiency (%)': '{:,.2f}'.format,\n",
    "    'With 15% Cost Cut (%)': '{:,.2f}'.format,\n",
    "    'Difference (pp)': '{:,.2f}'.format,\n",
    "}))\n",
    "# Diagnostics parallel to the post_estimation tutorial\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.bar(product_labels, pct_price_changes_eff, color=['#4c72b0', '#4c72b0', '#dd8452', '#dd8452'])\n",
    "ax.axhline(0, color='black', linewidth=0.8)\n",
    "ax.set_ylabel('Price Change (%)')\n",
    "ax.set_title('Within-Nest Merger with 15% Cost Reduction: Percent Price Changes')\n",
    "for idx, value in enumerate(pct_price_changes_eff):\n",
    "    ax.text(idx, value + (0.1 if value >= 0 else -0.3), f'{value:.2f}%', ha='center', va='bottom' if value >= 0 else 'top', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "post_merger_shares_eff = optimal_iv_results2.compute_shares(post_merger_prices_efficiency)\n",
    "post_merger_markups_eff = optimal_iv_results2.compute_markups(\n",
    "    post_merger_prices_efficiency,\n",
    "    marginal_costs_efficiency\n",
    ")\n",
    "post_merger_profits_eff = optimal_iv_results2.compute_profits(\n",
    "    post_merger_prices_efficiency,\n",
    "    post_merger_shares_eff,\n",
    "    marginal_costs_efficiency\n",
    ")\n",
    "post_merger_cs_eff = optimal_iv_results2.compute_consumer_surpluses(post_merger_prices_efficiency)\n",
    "\n",
    "efficiency_metrics = {\n",
    "    'Average Price ($)': post_merger_prices_eff_avg.mean(),\n",
    "    'Average Markup ($)': post_merger_markups_eff.reshape((T, J)).mean(),\n",
    "    'Total Profit ($)': post_merger_profits_eff.sum(),\n",
    "    'Average CS ($)': post_merger_cs_eff.mean(),\n",
    "}\n",
    "efficiency_metric_summary = pd.DataFrame({\n",
    "    'Metric': metric_names,\n",
    "    'No Efficiency (1&2)': [post_merger_metrics[m] for m in metric_names],\n",
    "    '15% Cost Cut (1&2)': [efficiency_metrics[m] for m in metric_names]\n",
    "})\n",
    "efficiency_metric_summary['Difference (Eff - No Eff)'] = (\n",
    "    efficiency_metric_summary['15% Cost Cut (1&2)'] - efficiency_metric_summary['No Efficiency (1&2)']\n",
    ")\n",
    "efficiency_metric_summary = efficiency_metric_summary.astype({\n",
    "    'No Efficiency (1&2)': float,\n",
    "    '15% Cost Cut (1&2)': float,\n",
    "    'Difference (Eff - No Eff)': float,\n",
    "})\n",
    "efficiency_metric_summary = efficiency_metric_summary.set_index('Metric')\n",
    "\n",
    "IPython.display.display(efficiency_metric_summary.style.format('{:,.3f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8db341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# WELFARE ANALYSIS\n",
    "# ========================================================================\n",
    "\n",
    "# Compute consumer surplus for different scenarios using PyBLP\n",
    "# Pre-merger consumer surplus (baseline)\n",
    "cs_pre = optimal_iv_results2.compute_consumer_surpluses()\n",
    "\n",
    "# Post-merger WITHOUT efficiencies (from Question 11)\n",
    "cs_post_no_eff = optimal_iv_results2.compute_consumer_surpluses(prices=post_merger_prices)\n",
    "\n",
    "# Post-merger WITH 15% cost reduction\n",
    "cs_post_with_eff = optimal_iv_results2.compute_consumer_surpluses(prices=post_merger_prices_efficiency)\n",
    "\n",
    "# Calculate changes in consumer surplus (per consumer, per market)\n",
    "delta_cs_no_eff = cs_post_no_eff - cs_pre\n",
    "delta_cs_with_eff = cs_post_with_eff - cs_pre\n",
    "\n",
    "# Aggregate across all markets and consumers\n",
    "# Total CS change = M_t * sum over all markets\n",
    "total_delta_cs_no_eff = M_t * delta_cs_no_eff.sum()\n",
    "total_delta_cs_with_eff = M_t * delta_cs_with_eff.sum()\n",
    "\n",
    "# Average per consumer across markets\n",
    "avg_delta_cs_no_eff = delta_cs_no_eff.mean()\n",
    "avg_delta_cs_with_eff = delta_cs_with_eff.mean()\n",
    "\n",
    "# Compute producer surplus changes\n",
    "# Producer surplus = (p - mc) × shares × M_t for each product\n",
    "# Pre-merger\n",
    "shares_pre = product_data['shares'].values.reshape((T, J))\n",
    "prices_pre_matrix = pre_merger_prices.reshape((T, J))\n",
    "mc_pre_matrix = marginal_costs.reshape((T, J))\n",
    "ps_pre = ((prices_pre_matrix - mc_pre_matrix) * shares_pre * M_t).sum()\n",
    "\n",
    "# Post-merger without efficiency\n",
    "shares_post_no_eff = optimal_iv_results2.compute_shares(prices=post_merger_prices)\n",
    "shares_post_no_eff_matrix = shares_post_no_eff.reshape((T, J))\n",
    "prices_post_no_eff_matrix = post_merger_prices.reshape((T, J))\n",
    "ps_post_no_eff = ((prices_post_no_eff_matrix - mc_pre_matrix) * shares_post_no_eff_matrix * M_t).sum()\n",
    "\n",
    "# Post-merger with 15% efficiency\n",
    "shares_post_eff = optimal_iv_results2.compute_shares(prices=post_merger_prices_efficiency)\n",
    "shares_post_eff_matrix = shares_post_eff.reshape((T, J))\n",
    "mc_eff_matrix = marginal_costs_efficiency.reshape((T, J))\n",
    "ps_post_eff = ((post_merger_prices_eff_matrix - mc_eff_matrix) * shares_post_eff_matrix * M_t).sum()\n",
    "\n",
    "# Changes in producer surplus\n",
    "delta_ps_no_eff = ps_post_no_eff - ps_pre\n",
    "delta_ps_with_eff = ps_post_eff - ps_pre\n",
    "\n",
    "# Total welfare changes\n",
    "delta_w_no_eff = total_delta_cs_no_eff + delta_ps_no_eff\n",
    "delta_w_with_eff = total_delta_cs_with_eff + delta_ps_with_eff\n",
    "\n",
    "welfare_summary = pd.DataFrame({\n",
    "    'Scenario': ['Without efficiency', 'With 15% cost cut'],\n",
    "    'ΔCS per consumer ($)': [avg_delta_cs_no_eff, avg_delta_cs_with_eff],\n",
    "    'ΔCS total ($)': [total_delta_cs_no_eff, total_delta_cs_with_eff],\n",
    "    'ΔPS ($)': [delta_ps_no_eff, delta_ps_with_eff],\n",
    "    'ΔW ($)': [delta_w_no_eff, delta_w_with_eff],\n",
    "})\n",
    "welfare_summary['Verdict'] = welfare_summary['ΔW ($)'].apply(lambda x: 'ENHANCING' if x >= 0 else 'REDUCING')\n",
    "numeric_columns_welfare = ['ΔCS per consumer ($)', 'ΔCS total ($)', 'ΔPS ($)', 'ΔW ($)']\n",
    "welfare_summary[numeric_columns_welfare] = welfare_summary[numeric_columns_welfare].apply(pd.to_numeric, errors='coerce')\n",
    "welfare_summary = welfare_summary.set_index('Scenario')\n",
    "IPython.display.display(welfare_summary.style.format({\n",
    "    'ΔCS per consumer ($)': '{:,.4f}'.format,\n",
    "    'ΔCS total ($)': '{:,.2f}'.format,\n",
    "    'ΔPS ($)': '{:,.2f}'.format,\n",
    "    'ΔW ($)': '{:,.2f}'.format,\n",
    "}))\n",
    "IPython.display.display(IPython.display.Markdown(f'*Totals assume M_t = {M_t:,} consumers per market across all {T} markets.*'))\n",
    "component_df = welfare_summary[['ΔCS total ($)', 'ΔPS ($)']]\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "component_df.plot(kind='bar', stacked=True, ax=ax, color=['#4c72b0', '#dd8452'])\n",
    "ax.set_ylabel('Dollars')\n",
    "ax.set_title('Total Surplus Changes by Scenario')\n",
    "ax.set_xticks(range(len(component_df.index)))\n",
    "ax.set_xticklabels(component_df.index, rotation=0)\n",
    "ax.axhline(0, color='black', linewidth=0.8)\n",
    "totals = component_df.sum(axis=1)\n",
    "for idx, total in enumerate(totals):\n",
    "    offset = 0.02 * total if total != 0 else 0.02\n",
    "    ax.text(idx, total + (offset if total >= 0 else -abs(offset)), f'{total:,.0f}', ha='center', va='bottom' if total >= 0 else 'top', fontsize=8)\n",
    "ax.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82576351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# Consolidated diagnostics across all merger scenarios\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "scenario_metric_table = pd.DataFrame({\n",
    "    'Metric': metric_names,\n",
    "    'Pre-Merger Baseline': [baseline_metrics[m] for m in metric_names],\n",
    "    'Merger 1&2 (No Eff)': [post_merger_metrics[m] for m in metric_names],\n",
    "    'Merger 1&3 (Cross)': [cross_merger_metrics[m] for m in metric_names],\n",
    "    'Merger 1&2 (15% Cost Cut)': [efficiency_metrics[m] for m in metric_names],\n",
    "})\n",
    "scenario_metric_table['Δ (1&2 - Pre)'] = scenario_metric_table['Merger 1&2 (No Eff)'] - scenario_metric_table['Pre-Merger Baseline']\n",
    "scenario_metric_table['Δ (1&3 - Pre)'] = scenario_metric_table['Merger 1&3 (Cross)'] - scenario_metric_table['Pre-Merger Baseline']\n",
    "scenario_metric_table['Δ (15% Cut - Pre)'] = scenario_metric_table['Merger 1&2 (15% Cost Cut)'] - scenario_metric_table['Pre-Merger Baseline']\n",
    "\n",
    "numeric_columns = scenario_metric_table.select_dtypes(include='number').columns\n",
    "scenario_metric_table[numeric_columns] = scenario_metric_table[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "format_dict = {col: '{:,.3f}'.format for col in numeric_columns}\n",
    "IPython.display.display(scenario_metric_table.style.format(format_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
