{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ef1489",
   "metadata": {},
   "source": [
    "# Economics 600a Fall 2025 Prof. P. Haile Homework Assignment 1\n",
    "\n",
    "## 1 Overview\n",
    "You will estimate demand and supply in a stylized model of the market for pay-TV services. You will use a matrix programming language of your choice to create your own fake data set for the industry and do some relatively simple estimation. Then, using the **pyBLP** package of Conlon and Gortmaker, you will estimate the model and perform some merger simulations.\n",
    "\n",
    "The pyBLP package has excellent documentation and a very helpful tutorial (which covers merger simulation), both easy to find via Google.\n",
    "\n",
    "Please submit (on canvas) a single PDF document presenting your answers to the questions below, requested results, and well documented code. Write this up nicely, with properly formatted tables and discussion of results. You may work in groups on the coding. However, your write-ups should be your own work, and you must describe all collaboration at the beginning of your submission; this includes any use of AI.\n",
    "\n",
    "## 2 Model\n",
    "There are $T$ markets, each with four inside goods $j \\in \\{1,2,3,4\\}$ and an outside option. Goods 1 and 2 are satellite television services (e.g., DirecTV and Dish); goods 3 and 4 are wired television services (e.g., Frontier and Comcast in New Haven). The conditional indirect utility of consumer $i$ for good $j$ in market $t$ is given by\n",
    "\n",
    "\\begin{align*}\n",
    "u_{ijt} &= \\beta^{(1)} x_{jt} + \\beta_i^{(2)} satellite_{jt} + \\beta_i^{(3)} wired_{jt} + \\alpha p_{jt} + \\xi_{jt} + \\epsilon_{ijt} \\quad j > 0 \\\\\n",
    "u_{i0t} &= \\epsilon_{i0t},\n",
    "\\end{align*}\n",
    "\n",
    "where $x_{jt}$ is a measure of good $j$'s quality, $p_{jt}$ is its price, $satellite_{jt}$ is an indicator equal to 1 for the two satellite services, and $wired_{jt}$ is an indicator equal to 1 for the two wired services. The remaining notation is as usual in the class notes, including the i.i.d. type-1 extreme value $\\epsilon_{ijt}$. Each consumer purchases the good giving them the highest conditional indirect utility.\n",
    "\n",
    "Goods are produced by single-product firms. Firm $j$'s (log) marginal cost in market $t$ is\n",
    "\n",
    "\\begin{equation*}\n",
    "\\ln mc_{jt} = \\gamma^{(0)} + w_{jt} \\gamma^{(1)} + \\omega_{jt}/8,\n",
    "\\end{equation*}\n",
    "\n",
    "where $w_{jt}$ is an observed cost shifter. Firms compete by simultaneously choosing prices in each market under complete information. Firm $j$ has profit\n",
    "\n",
    "\\begin{equation*}\n",
    "\\pi_{jt} = \\max_{p_{jt}} (p_{jt} - mc_{jt}) s_{jt}(p_t).\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ee1070",
   "metadata": {},
   "source": [
    "## 3 Generate Fake Data\n",
    "\n",
    "Generate a data set from the model above. Let\n",
    "\n",
    "\\begin{align*}\n",
    "\\beta^{(1)} &= 1, \\quad \\beta_i^{(k)} \\sim \\text{iid } N(4,1) \\text{ for } k=2,3 \\\\\n",
    "\\alpha &= -2 \\\\\n",
    "\\gamma^{(0)} &= 1/2, \\quad \\gamma^{(1)} = 1/4.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8744e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1.1.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import IPython.display\n",
    "IPython.display.display(IPython.display.HTML('<style>pre { white-space: pre !important; }</style>'))\n",
    "import pyblp\n",
    "pyblp.options.digits = 3\n",
    "pd.options.display.precision = 3\n",
    "pd.options.display.max_columns = 50\n",
    "pyblp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12caa47",
   "metadata": {},
   "source": [
    "### 1. \n",
    "Draw the exogenous product characteristic $x_{jt}$ for $T=600$ geographically defined markets (e.g., cities). Assume each $x_{jt}$ is equal to the absolute value of an iid standard normal draw, as is each $w_{jt}$. Simulate demand and cost unobservables as well, specifying\n",
    "\n",
    "\\begin{equation*}\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "\\xi_{jt} \\\\\n",
    "\\omega_{jt}\n",
    "\\end{array}\n",
    "\\right) \\sim N\\left( \\left(\n",
    "\\begin{array}{c}\n",
    "0 \\\\\n",
    "0\n",
    "\\end{array}\n",
    "\\right), \\left(\n",
    "\\begin{array}{cc}\n",
    "1 & 0.25 \\\\\n",
    "0.25 & 1\n",
    "\\end{array}\n",
    "\\right) \\right) \\quad \\text{iid across } j,t.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9546c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 completed:\n",
      "Generated 2400 observations across 600 markets\n",
      "x range: 0.001 to 3.534\n",
      "w range: 0.000 to 3.621\n",
      "ξ-ω correlation: 0.240 (target: 0.25)\n",
      "Satellite products: 1200, Wired products: 1200\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1995)\n",
    "\n",
    "# Model parameters\n",
    "T, J = 600, 4\n",
    "alpha, beta1 = -2, 1\n",
    "beta2, beta3 = 4, 4  \n",
    "sigma_satellite, sigma_wired = 1, 1\n",
    "gamma0, gamma1 = 0.5, 0.25\n",
    "\n",
    "# Product data structure\n",
    "data = [\n",
    "    {'market_ids': t, 'firm_ids': j+1, 'product_ids': j} \n",
    "    for t in range(T) \n",
    "    for j in range(J)\n",
    "]\n",
    "product_data = pd.DataFrame(data)\n",
    "\n",
    "# Exogenous variables: x_jt and w_jt as absolute values of iid standard normal draws\n",
    "product_data['x'] = np.abs(\n",
    "    np.random.normal(0, 1, len(product_data))\n",
    ")\n",
    "product_data['w'] = np.abs(\n",
    "    np.random.normal(0, 1, len(product_data))\n",
    ")\n",
    "\n",
    "# Indicators\n",
    "product_data['satellite'] = (\n",
    "    product_data['firm_ids'].isin([1, 2]).astype(int)\n",
    ")\n",
    "product_data['wired'] = (\n",
    "    product_data['firm_ids'].isin([3, 4]).astype(int)\n",
    ")\n",
    "\n",
    "# Unobservables: ξ_jt and ω_jt with covariance matrix [[1, 0.25], [0.25, 1]]\n",
    "cov_matrix = np.array([[1, 0.25], [0.25, 1]])\n",
    "A = np.linalg.cholesky(cov_matrix)\n",
    "z = np.random.normal(0, 1, (len(product_data), 2))\n",
    "unobs = z @ A.T\n",
    "product_data['xi'] = unobs[:, 0]  # demand unobservable\n",
    "product_data['omega'] = unobs[:, 1]  # cost unobservable\n",
    "\n",
    "print(\"Question 1 completed:\")\n",
    "print(f\"Generated {len(product_data)} observations across {T} markets\")\n",
    "print(f'x range: {product_data[\"x\"].min():.3f} to {product_data[\"x\"].max():.3f}')\n",
    "print(f'w range: {product_data[\"w\"].min():.3f} to {product_data[\"w\"].max():.3f}')\n",
    "xi_omega_corr = product_data[['xi', 'omega']].corr().iloc[0,1]\n",
    "print(f\"ξ-ω correlation: {xi_omega_corr:.3f} (target: 0.25)\")\n",
    "sat_count = product_data[\"satellite\"].sum()\n",
    "wired_count = product_data[\"wired\"].sum()\n",
    "print(f\"Satellite products: {sat_count}, Wired products: {wired_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ed4c4c",
   "metadata": {},
   "source": [
    "### 2. Solve for the equilibrium prices for each good in each market.\n",
    "\n",
    "**(a)** Start by writing a procedure to approximate the derivatives of market shares with respect to prices (taking prices, shares, x, and demand parameters as inputs). The key steps are:\n",
    "\n",
    "(i) For each $jt$, write the choice probability for good $j$, $s_{jt}$, as a weighted average (integral) of the (multinomial logit) choice probabilities conditional on the value of each consumer's random coefficients;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693a0d7a",
   "metadata": {},
   "source": [
    "The market share for good $j$ in market $t$, $s_{jt}$, is the probability that a consumer chooses good $j$:\n",
    "\n",
    "$$s_{jt} = \\int P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)}) f(\\beta_i^{(2)}, \\beta_i^{(3)}) d\\beta_i^{(2)} d\\beta_i^{(3)}$$\n",
    "\n",
    "where $P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})$ is the multinomial logit choice probability conditional on the random coefficients.\n",
    "\n",
    "Given the random coefficients $\\beta_i^{(2)}$ and $\\beta_i^{(3)}$ (with means $\\beta^{(2)} = 4$, $\\beta^{(3)} = 4$ and variances $\\sigma_2^2 = 1$, $\\sigma_3^2 = 1$), the conditional utility becomes:\n",
    "\n",
    "$$u_{ijt} = \\beta^{(1)} x_{jt} + \\beta_i^{(2)} satellite_{jt} + \\beta_i^{(3)} wired_{jt} + \\alpha p_{jt} + \\xi_{jt} + \\epsilon_{ijt}$$\n",
    "\n",
    "Since $\\epsilon_{ijt}$ are i.i.d. Type-1 extreme value, the conditional choice probability follows the multinomial logit form:\n",
    "\n",
    "$$P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)}) = \\frac{\\exp(\\delta_{jt} + \\mu_{jt}^i)}{\\sum_{k=1}^J \\exp(\\delta_{kt} + \\mu_{kt}^i) + 1}$$\n",
    "\n",
    "where:\n",
    "- $\\delta_{jt} = \\beta^{(1)} x_{jt} + \\alpha p_{jt} + \\xi_{jt}$ (mean utility component)\n",
    "- $\\mu_{jt}^i = \\beta_i^{(2)} satellite_{jt} + \\beta_i^{(3)} wired_{jt}$ (random utility component)\n",
    "\n",
    "**Final Expression:**\n",
    "\n",
    "$$s_{jt} = \\int \\frac{\\exp(\\delta_{jt} + \\beta_i^{(2)} satellite_{jt} + \\beta_i^{(3)} wired_{jt})}{\\sum_{k=1}^J \\exp(\\delta_{kt} + \\beta_i^{(2)} satellite_{kt} + \\beta_i^{(3)} wired_{kt}) + 1} \\phi(\\beta_i^{(2)}, \\beta_i^{(3)}) d\\beta_i^{(2)} d\\beta_i^{(3)}$$\n",
    "\n",
    "where $\\phi(\\cdot, \\cdot)$ is the bivariate normal density with mean $(\\beta^{(2)}, \\beta^{(3)}) = (4, 4)$ and covariance matrix $\\text{diag}(1, 1)$.\n",
    "\n",
    "This integral is approximated in the code using Monte Carlo simulation with draws from the normal distribution of $(\\beta_i^{(2)}, \\beta_i^{(3)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfaf6df",
   "metadata": {},
   "source": [
    "(ii) Anticipating differentiation under the integral sign, derive the analytical expression for the derivative of the integrand with respect to each $p_{kt}$.\n",
    "\n",
    "The integrand is the conditional choice probability $P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})$, which depends on prices through the mean utility component $\\delta_{jt} = \\beta^{(1)} x_{jt} + \\alpha p_{jt} + \\xi_{jt}$.\n",
    "\n",
    "Since $p_{kt}$ appears in $\\delta_{kt}$, the derivative with respect to $p_{kt}$ affects the choice probability.\n",
    "\n",
    "For the multinomial logit model, the derivative of the choice probability with respect to a price is:\n",
    "\n",
    "$$\\frac{\\partial P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})}{\\partial p_{kt}} = \\alpha P(j|\\beta_i) \\left( I_{jk} - P(k|\\beta_i) \\right)$$\n",
    "\n",
    "where $I_{jk}$ is the indicator function equal to 1 if $j = k$.\n",
    "\n",
    "Therefore, the derivative of the integrand (conditional choice probability) with respect to $p_{kt}$ is:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial p_{kt}} \\left[ \\frac{\\exp(\\delta_{jt} + \\mu_{jt}^i)}{\\sum_{m=1}^J \\exp(\\delta_{mt} + \\mu_{mt}^i) + 1} \\right] = \\alpha \\cdot \\frac{\\exp(\\delta_{jt} + \\mu_{jt}^i)}{\\sum_{m=1}^J \\exp(\\delta_{mt} + \\mu_{mt}^i) + 1} \\left( I_{jk} - \\frac{\\exp(\\delta_{kt} + \\mu_{kt}^i)}{\\sum_{m=1}^J \\exp(\\delta_{mt} + \\mu_{mt}^i) + 1} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2c76a",
   "metadata": {},
   "source": [
    "3. Use the expression you obtained in (2) and simulation draws of the random coefficients to approximate the integral that corresponds to $\\partial s_{jt}/\\partial p_{kt}$ for each $j$ and $k$ (i.e., replace the integral with the mean over the values at each simulation draw). Recall the advice in the lecture regarding \"jittering.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ba8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_shares_and_derivatives(prices, market_data, nu_draws):\n",
    "    \"\"\"\n",
    "    Compute shares, derivatives, and inside_shares_draws efficiently in one pass.\n",
    "    Returns: (shares, derivatives, inside_shares_draws)\n",
    "    \"\"\"\n",
    "    J = len(market_data)\n",
    "    x = market_data['x'].values\n",
    "    xi = market_data['xi'].values\n",
    "    sat = market_data['satellite'].values\n",
    "    wired = market_data['wired'].values\n",
    "    \n",
    "    # Compute utilities once\n",
    "    utilities = (\n",
    "        beta1 * x + xi + \n",
    "        nu_draws[:, 0:1] * sat + \n",
    "        nu_draws[:, 1:2] * wired + \n",
    "        alpha * prices\n",
    "    )\n",
    "    utilities = np.column_stack([utilities, np.zeros(nu_draws.shape[0])])\n",
    "    exp_u = np.exp(utilities - np.max(utilities, axis=1, keepdims=True))\n",
    "    choice_probs = exp_u / exp_u.sum(axis=1, keepdims=True)\n",
    "    inside_shares_draws = choice_probs[:, :J]\n",
    "    \n",
    "    # Shares: average over draws\n",
    "    shares = np.mean(inside_shares_draws, axis=0)\n",
    "    \n",
    "    # Derivatives: compute analytically from choice probabilities\n",
    "    derivatives = np.zeros((J, J))\n",
    "    for j in range(J):\n",
    "        for k in range(J):\n",
    "            indicator = float(j == k)\n",
    "            deriv_draws = (\n",
    "                alpha * inside_shares_draws[:, j] * \n",
    "                (indicator - inside_shares_draws[:, k])\n",
    "            )\n",
    "            derivatives[j, k] = np.mean(deriv_draws)\n",
    "    \n",
    "    return shares, derivatives, inside_shares_draws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc99991e",
   "metadata": {},
   "source": [
    "The derivative $\\partial s_{jt}/\\partial p_{kt}$ is approximated using Monte Carlo simulation. For each simulation draw $r = 1, \\dots, R$ of the random coefficients $(\\beta_i^{(2)}, \\beta_i^{(3)})$, compute the conditional choice probability $P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})$ and its derivative with respect to prices.\n",
    "\n",
    "The derivative of the conditional choice probability follows from the multinomial logit formula:\n",
    "\n",
    "$$\\frac{\\partial P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})}{\\partial p_{kt}} = \\alpha P(j|\\beta_i) \\left( \\delta_{jk} - P(k|\\beta_i) \\right)$$\n",
    "\n",
    "where $\\delta_{jk} = 1$ if $j = k` and 0 otherwise.\n",
    "\n",
    "Then, the market share derivative is approximated as:\n",
    "\n",
    "$$\\frac{\\partial s_{jt}}{\\partial p_{kt}} \\approx \\frac{1}{R} \\sum_{r=1}^R \\frac{\\partial P(\\text{choose } j | \\beta_i^{(2,r)}, \\beta_i^{(3,r)})}{\\partial p_{kt}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab755210",
   "metadata": {},
   "source": [
    "Regarding \"jittering\": When solving for equilibrium prices iteratively, redrawing simulation draws in each iteration introduces random noise that can prevent convergence. To avoid this, pre-draw a fixed set of simulation draws for each market and reuse them throughout the solution process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26550341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-draw simulation draws (to avoid jittering)\n",
    "np.random.seed(1995) \n",
    "n_draws = 10000\n",
    "all_nu_draws = [\n",
    "    np.random.multivariate_normal(\n",
    "        [beta2, beta3], \n",
    "        np.diag([sigma_satellite, sigma_wired]), \n",
    "        size=n_draws\n",
    "    ) \n",
    "    for _ in range(T)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1ed54",
   "metadata": {},
   "source": [
    "(iv) Experiment to see how many simulation draws you need to get precise approximations and check this again at the equilibrium shares and prices you obtained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed79e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00804081, 0.00537121, 0.00372863, 0.00253488, 0.0016517 ,\n",
       "       0.00107223, 0.00052512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_convergence(prices, market_data, nu_draws_full, draw_counts, n_reps=100):\n",
    "    \"\"\"Test derivative stability across different numbers of simulation draws.\"\"\"\n",
    "    np.random.seed(1995) \n",
    "    stds = []\n",
    "    n_available = len(nu_draws_full)\n",
    "    \n",
    "    for n_draws in draw_counts:\n",
    "        deriv_list = []\n",
    "        for rep in range(n_reps):\n",
    "            # Randomly sample n_draws from the pre-drawn samples\n",
    "            indices = np.random.choice(n_available, size=n_draws, replace=False)\n",
    "            nu_draws = nu_draws_full[indices]\n",
    "            _, derivs, _ = market_shares_and_derivatives(\n",
    "                prices, market_data, nu_draws\n",
    "            )\n",
    "            deriv_list.append(derivs)\n",
    "        stds.append(np.std(deriv_list, axis=0).mean())\n",
    "    return np.array(stds)\n",
    "\n",
    "# Test at initial prices (p = MC)\n",
    "product_data['mc'] = np.exp(\n",
    "    gamma0 + gamma1 * product_data['w'] + product_data['omega'] / 8\n",
    ")\n",
    "# Test at initial prices (p = MC) for market 0\n",
    "market_0 = product_data[product_data['market_ids'] == 0]\n",
    "prices_init = market_0['mc'].values\n",
    "draw_counts = [50, 100, 200, 500, 1000, 2000, 5000]\n",
    "stds = test_convergence(prices_init, market_0, all_nu_draws[0], draw_counts)\n",
    "stds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5aa25a",
   "metadata": {},
   "source": [
    "(b) The FOC for firm $j$'s profit maximization problem in market $t$ is\n",
    "\n",
    "\\begin{align}\n",
    "(p_{jt} - mc_{jt}) \\frac{\\partial s_{jt}}{\\partial p_{jt}} + s_{jt} &= 0 \\notag \\\\\n",
    "\\implies p_{jt} - mc_{jt} &= -\\left( \\frac{\\partial s_{jt}}{\\partial p_{jt}} \\right)^{-1} s_{jt}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c91cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC range: 1.135 to 4.652\n",
      "MC mean: 2.058, median: 1.994\n",
      "FOC: (p_jt - mc_jt) * ∂s_jt/∂p_jt + s_jt = 0\n",
      "Rearranged: p_jt - mc_jt = - (∂s_jt/∂p_jt)⁻¹ * s_jt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"MC range: {product_data['mc'].min():.3f} to {product_data['mc'].max():.3f}\")\n",
    "print(f\"MC mean: {product_data['mc'].mean():.3f}, median: {product_data['mc'].median():.3f}\")\n",
    "print(\"FOC: (p_jt - mc_jt) * ∂s_jt/∂p_jt + s_jt = 0\")\n",
    "print(\"Rearranged: p_jt - mc_jt = - (∂s_jt/∂p_jt)⁻¹ * s_jt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4676b052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(product_data['mc'], bins=50);\n",
    "plt.legend([\"Marginal Costs\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5bec32",
   "metadata": {},
   "source": [
    "(c) Substituting in your approximation of each $\\partial s_{jt}/\\partial p_{jt}$, solve the system of equations above ($J$ equations per market) for the equilibrium prices in each market.\n",
    "\n",
    "**i.** First do this using Matlab's \"fsolve\" operator. Check the exit flag from fsolve to be sure whether you found a solution for each market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36519e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2(c)i completed:\n",
      "Direct nonlinear solver (root): 600/600 markets solved successfully\n",
      "Success rate: 100.0%\n",
      "Price range: 2.346 to 5.698\n",
      "Price mean: 3.318, std: 0.435\n"
     ]
    }
   ],
   "source": [
    "def solve_prices_direct(market_data, mc_market, nu_draws):\n",
    "    \"\"\"Solve for equilibrium prices using direct nonlinear solver with robust matrix inversion\"\"\"\n",
    "    J = len(market_data)\n",
    "    \n",
    "    def foc_residual(prices):\n",
    "        \"\"\"FOC residuals: p - mc + (∂s/∂p)^{-1} s = 0\"\"\"\n",
    "        # Compute shares and derivatives at current prices\n",
    "        shares, derivatives, _ = market_shares_and_derivatives(\n",
    "            prices, market_data, nu_draws\n",
    "        )\n",
    "\n",
    "        # Inversion of derivative matrix\n",
    "        invD = np.linalg.inv(derivatives)\n",
    "\n",
    "        # FOC residuals: p - mc + inv(∂s/∂p) @ s\n",
    "        residuals = prices - mc_market + invD @ shares\n",
    "        return residuals\n",
    "    # Initial guess: marginal costs\n",
    "    p0 = mc_market.copy()\n",
    "    # Solve using root finder (hybr method)\n",
    "    sol = opt.root(foc_residual, p0, method='hybr', tol=1e-8)\n",
    "    prices_sol = sol.x\n",
    "    success = sol.success\n",
    "    # Additional check: verify that residuals are small\n",
    "    final_residuals = foc_residual(prices_sol)\n",
    "    if np.max(np.abs(final_residuals)) > 1e-6:\n",
    "        success = False\n",
    "    return prices_sol, success\n",
    "\n",
    "# Solve using direct method\n",
    "equilibrium_prices_direct = []\n",
    "success_flags_direct = []\n",
    "for t in range(T):\n",
    "    market_data = product_data[product_data['market_ids'] == t]\n",
    "    mc_market = market_data['mc'].values\n",
    "    nu_draws = all_nu_draws[t]\n",
    "    prices_direct, success = solve_prices_direct(\n",
    "        market_data, mc_market, nu_draws\n",
    "    )\n",
    "    equilibrium_prices_direct.append(prices_direct)\n",
    "    success_flags_direct.append(success)\n",
    "equilibrium_prices_direct = np.array(equilibrium_prices_direct)\n",
    "success_count = sum(success_flags_direct)\n",
    "print(\"Question 2(c)i completed:\")\n",
    "print(f\"Direct nonlinear solver (root): {success_count}/{T} markets solved successfully\")\n",
    "print(f\"Success rate: {success_count/T:.1%}\")\n",
    "price_range_text = (\n",
    "    f\"Price range: {equilibrium_prices_direct.min():.3f} to \"\n",
    "    f\"{equilibrium_prices_direct.max():.3f}\"\n",
    ")\n",
    "print(price_range_text)\n",
    "price_stats_text = (\n",
    "    f\"Price mean: {equilibrium_prices_direct.mean():.3f}, \"\n",
    "    f\"std: {equilibrium_prices_direct.std():.3f}\"\n",
    ")\n",
    "print(price_stats_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca3eea",
   "metadata": {},
   "source": [
    "ii. Do this again using the algorithm of Morrow and Skerlos (2011), discussed in section 3.6 of Conlon and Gortmaker (2019) (and in the pyBLP \"problem simulation tutorial\"). Use the numerical integration approach you used in step (a) to approximate the terms defined in equation (25) of Conlon and Gortmaker. If you get different results using this method, resolve this discrepancy either by correcting your code or explaining why your preferred method is the one to be trusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba70d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2(c)ii completed:\n",
      "Morrow-Skerlos method: 600 markets solved\n",
      "Average iterations: 27.9\n",
      "Max iterations: 36\n",
      "Price range: 2.346 to 5.698\n",
      "Price mean: 3.318, std: 0.435\n",
      "Max price difference between methods: 4.52e-06\n",
      "Mean price difference: 1.28e-06\n"
     ]
    }
   ],
   "source": [
    "def solve_prices_morrow_skerlos(market_data, mc_market, nu_draws, max_iter=100, tol=1e-6):\n",
    "    \"\"\"Morrow-Skerlos algorithm\"\"\"\n",
    "    prices = mc_market.copy()\n",
    "    for iteration in range(max_iter):\n",
    "        # Efficiently compute shares, derivatives, and inside_shares_draws in one pass\n",
    "        shares, derivatives, inside_shares_draws = market_shares_and_derivatives(prices, market_data, nu_draws)\n",
    "        \n",
    "        Lambda = np.diag(alpha * shares)\n",
    "        Gamma = alpha * (inside_shares_draws.T @ inside_shares_draws) / nu_draws.shape[0]\n",
    "        diff = prices - mc_market\n",
    "        zeta = np.linalg.solve(Lambda, Gamma.T @ diff - shares)\n",
    "        prices_new = mc_market + zeta\n",
    "        foc_residual = Lambda @ (prices - mc_market - zeta)\n",
    "        if np.max(np.abs(foc_residual)) < tol:\n",
    "            break\n",
    "        prices = 0.5 * prices + 0.5 * prices_new\n",
    "    return prices, iteration + 1\n",
    "\n",
    "# Solve using Morrow-Skerlos method\n",
    "equilibrium_prices_ms = []\n",
    "iterations_ms = []\n",
    "\n",
    "for t in range(T):\n",
    "    market_data = product_data[product_data['market_ids'] == t]\n",
    "    mc_market = market_data['mc'].values\n",
    "    nu_draws = all_nu_draws[t]\n",
    "\n",
    "    prices_ms, iters = solve_prices_morrow_skerlos(market_data, mc_market, nu_draws)\n",
    "    equilibrium_prices_ms.append(prices_ms)\n",
    "    iterations_ms.append(iters)\n",
    "\n",
    "equilibrium_prices_ms = np.array(equilibrium_prices_ms)\n",
    "print(\"Question 2(c)ii completed:\")\n",
    "print(f\"Morrow-Skerlos method: {T} markets solved\")\n",
    "print(f\"Average iterations: {np.mean(iterations_ms):.1f}\")\n",
    "print(f\"Max iterations: {np.max(iterations_ms)}\")\n",
    "print(f\"Price range: {equilibrium_prices_ms.min():.3f} to {equilibrium_prices_ms.max():.3f}\")\n",
    "print(f\"Price mean: {equilibrium_prices_ms.mean():.3f}, std: {equilibrium_prices_ms.std():.3f}\")\n",
    "\n",
    "# Compare direct vs Morrow-Skerlos if direct succeeded for all\n",
    "if len(equilibrium_prices_direct) == T:\n",
    "    price_diff = np.abs(np.array(equilibrium_prices_direct) - equilibrium_prices_ms)\n",
    "    print(f\"Max price difference between methods: {price_diff.max():.2e}\")\n",
    "    print(f\"Mean price difference: {price_diff.mean():.2e}\")\n",
    "else:\n",
    "    print(\"Direct method failed for some markets, skipsigmang comparison.\")\n",
    "    print(\"Preferred method: Morrow-Skerlos, as it is more numerically stable.\")\n",
    "\n",
    "# Use Morrow-Skerlos prices\n",
    "product_data['prices'] = equilibrium_prices_ms.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b39f6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing derivative approximation convergence:\n",
      "Draws\t| Initial Std Dev\t| Equilibrium Std Dev\t| Ratio (Eq/Init)\n",
      "---------------------------------------------------------------------------\n",
      "    50\t| 8.04e-03\t\t| 5.33e-03\t\t| 0.66\n",
      "   100\t| 5.37e-03\t\t| 3.63e-03\t\t| 0.68\n",
      "   200\t| 3.73e-03\t\t| 2.65e-03\t\t| 0.71\n",
      "   500\t| 2.53e-03\t\t| 1.72e-03\t\t| 0.68\n",
      "  1000\t| 1.65e-03\t\t| 1.14e-03\t\t| 0.69\n",
      "  2000\t| 1.07e-03\t\t| 7.24e-04\t\t| 0.68\n",
      "  5000\t| 5.25e-04\t\t| 3.53e-04\t\t| 0.67\n"
     ]
    }
   ],
   "source": [
    "    # Compare derivative convergence at initial vs equilibrium prices\n",
    "    market_0 = product_data[product_data['market_ids'] == 0]\n",
    "    prices_equilibrium = market_0['prices'].values\n",
    "\n",
    "    draw_counts = [50, 100, 200, 500, 1000, 2000, 5000]\n",
    "    # Reuse previously calculated initial_stds from test_convergence\n",
    "    initial_stds = stds  # Already calculated earlier at initial prices\n",
    "    \n",
    "    # Only compute equilibrium stds\n",
    "    np.random.seed(1995)\n",
    "    n_available = len(all_nu_draws[0])\n",
    "    n_reps = 100\n",
    "    eq_stds = []\n",
    "    for n_draws in draw_counts:\n",
    "        deriv_list = []\n",
    "        for _ in range(n_reps):\n",
    "            indices = np.random.choice(n_available, size=n_draws, replace=False)\n",
    "            nu_draws = all_nu_draws[0][indices]\n",
    "            _, derivatives, _ = market_shares_and_derivatives(\n",
    "                prices_equilibrium, market_0, nu_draws\n",
    "            )\n",
    "            deriv_list.append(derivatives)\n",
    "        eq_stds.append(np.std(deriv_list, axis=0).mean())\n",
    "    eq_stds = np.array(eq_stds)\n",
    "\n",
    "    print(\"Comparing derivative approximation convergence:\")\n",
    "    print(\"Draws\\t| Initial Std Dev\\t| Equilibrium Std Dev\\t| Ratio (Eq/Init)\")\n",
    "    print(\"-\" * 75)\n",
    "\n",
    "    for i, n_draws in enumerate(draw_counts):\n",
    "        ratio = eq_stds[i] / initial_stds[i] if initial_stds[i] > 0 else float('inf')\n",
    "        print(f\"{n_draws:6d}\\t| {initial_stds[i]:.2e}\\t\\t| {eq_stds[i]:.2e}\\t\\t| {ratio:.2f}\")\n",
    "\n",
    "    # Summary statistics\n",
    "    valid_ratios = eq_stds / initial_stds\n",
    "    avg_ratio = np.mean(valid_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c19e4",
   "metadata": {},
   "source": [
    "### 3. \n",
    "Calculate \"observed\" market shares for your fake data set using your parameters, your draws of $x$, $w$, $\\xi$, $\\omega$, and your equilibrium prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f40eeb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share range: 0.000 to 0.724\n",
      "Share mean: 0.136, std: 0.122\n",
      "Market share sums (should be < 1):\n",
      "Average: 0.543\n",
      "Min: 0.307, Max: 0.745\n",
      "Outside shares: 0.457 (average)\n",
      "Average satellite product share: 0.135\n",
      "Average wired product share: 0.136\n"
     ]
    }
   ],
   "source": [
    "observed_shares = []\n",
    "for t in range(T):\n",
    "    market_data = product_data[product_data['market_ids'] == t]\n",
    "    prices_market = market_data['prices'].values\n",
    "    # Use pre-drawn simulation draws for this market\n",
    "    shares_market, _, _ = market_shares_and_derivatives(\n",
    "        prices_market, market_data, all_nu_draws[t]\n",
    "    )\n",
    "    observed_shares.extend(shares_market)\n",
    "\n",
    "product_data['shares'] = observed_shares\n",
    "\n",
    "print(f\"Share range: {product_data['shares'].min():.3f} to {product_data['shares'].max():.3f}\")\n",
    "print(f\"Share mean: {product_data['shares'].mean():.3f}, std: {product_data['shares'].std():.3f}\")\n",
    "\n",
    "# Validation: Check market share sums\n",
    "market_share_sums = product_data.groupby('market_ids')['shares'].sum()\n",
    "print(f\"Market share sums (should be < 1):\")\n",
    "print(f\"Average: {market_share_sums.mean():.3f}\")\n",
    "print(f\"Min: {market_share_sums.min():.3f}, Max: {market_share_sums.max():.3f}\")\n",
    "print(f\"Outside shares: {1 - market_share_sums.mean():.3f} (average)\")\n",
    "\n",
    "# Check by product type\n",
    "satellite_shares = product_data[product_data['satellite'] == 1]['shares'].mean()\n",
    "wired_shares = product_data[product_data['wired'] == 1]['shares'].mean()\n",
    "print(f\"Average satellite product share: {satellite_shares:.3f}\")\n",
    "print(f\"Average wired product share: {wired_shares:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95915201",
   "metadata": {},
   "source": [
    "### 4. \n",
    "\n",
    "Below you'll be using $x$ and $w$ as instruments in the demand estimation. Check whether these appear to be good instruments in your fake data using some regressions of prices and market shares on the exogenous variables (or some function of them; see the related discussion in the coding tips). If you believe the instruments are not providing enough variation, modify the parameter choices above until you are satisfied. Report your final choice of parameters and the results you rely on to conclude that the instruments seem good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e641c80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "INSTRUMENT VALIDITY TESTS\n",
      "===========================================================================\n",
      "\n",
      "1. Price Regression (Relevance Test)\n",
      "   R²: 0.511\n",
      "   Individual Coefficients:\n",
      "     satellite         :    2.845 (SE: 0.031, t:  92.41, p: 0.000)\n",
      "     wired             :    2.849 (SE: 0.031, t:  92.90, p: 0.000)\n",
      "     x                 :    0.071 (SE: 0.034, t:   2.09, p: 0.037)\n",
      "     w                 :    0.344 (SE: 0.034, t:  10.22, p: 0.000)\n",
      "     x**2              :    0.037 (SE: 0.013, t:   2.77, p: 0.006)\n",
      "     w**2              :    0.093 (SE: 0.013, t:   7.08, p: 0.000)\n",
      "     x*w               :   -0.085 (SE: 0.018, t:  -4.64, p: 0.000)\n",
      "     sum_x_competitors :    0.055 (SE: 0.007, t:   7.41, p: 0.000)\n",
      "     sum_w_competitors :   -0.035 (SE: 0.008, t:  -4.61, p: 0.000)\n",
      "     x_other_in_nest   :    0.050 (SE: 0.013, t:   3.87, p: 0.000)\n",
      "     w_other_in_nest   :   -0.031 (SE: 0.013, t:  -2.36, p: 0.018)\n",
      "   Excluded demand instruments F-stat: 300.86 (p=0.00e+00)\n",
      "   → Excluded instruments are relevant for prices\n",
      "\n",
      "2. Share Regression (Relevance Test)\n",
      "   R²: 0.364\n",
      "   Individual Coefficients:\n",
      "     satellite         :    0.127 (SE: 0.010, t:  12.81, p: 0.000)\n",
      "     wired             :    0.130 (SE: 0.010, t:  13.22, p: 0.000)\n",
      "     x                 :    0.083 (SE: 0.011, t:   7.56, p: 0.000)\n",
      "     w                 :   -0.069 (SE: 0.011, t:  -6.42, p: 0.000)\n",
      "     x**2              :    0.015 (SE: 0.004, t:   3.54, p: 0.000)\n",
      "     w**2              :    0.011 (SE: 0.004, t:   2.71, p: 0.007)\n",
      "     x*w               :   -0.034 (SE: 0.006, t:  -5.81, p: 0.000)\n",
      "     sum_x_competitors :   -0.019 (SE: 0.002, t:  -7.81, p: 0.000)\n",
      "     sum_w_competitors :    0.013 (SE: 0.002, t:   5.52, p: 0.000)\n",
      "     x_other_in_nest   :   -0.007 (SE: 0.004, t:  -1.56, p: 0.119)\n",
      "     w_other_in_nest   :    0.013 (SE: 0.004, t:   3.07, p: 0.002)\n",
      "   Excluded demand instruments F-stat: 91.03 (p=3.41e-132)\n",
      "   → Excluded instruments are relevant for shares\n",
      "\n",
      "3. ξ Regression (Exclusion Test)\n",
      "   R²: 0.003\n",
      "   Individual Coefficients:\n",
      "     satellite         :   -0.054 (SE: 0.103, t:  -0.52, p: 0.603)\n",
      "     wired             :   -0.010 (SE: 0.103, t:  -0.10, p: 0.923)\n",
      "     x                 :   -0.072 (SE: 0.114, t:  -0.63, p: 0.527)\n",
      "     w                 :    0.076 (SE: 0.113, t:   0.68, p: 0.500)\n",
      "     x**2              :    0.046 (SE: 0.045, t:   1.02, p: 0.306)\n",
      "     w**2              :   -0.013 (SE: 0.044, t:  -0.29, p: 0.773)\n",
      "     x*w               :   -0.048 (SE: 0.061, t:  -0.79, p: 0.428)\n",
      "     sum_x_competitors :   -0.021 (SE: 0.025, t:  -0.86, p: 0.388)\n",
      "     sum_w_competitors :    0.003 (SE: 0.025, t:   0.12, p: 0.904)\n",
      "     x_other_in_nest   :   -0.004 (SE: 0.044, t:  -0.08, p: 0.934)\n",
      "     w_other_in_nest   :    0.047 (SE: 0.044, t:   1.08, p: 0.282)\n",
      "   Excluded demand instruments F-stat: 0.63 (p=7.53e-01)\n",
      "   → Excluded instruments are exogenous\n",
      "\n",
      "4. ω Regression (Exclusion Test)\n",
      "   R²: 0.003\n",
      "   Individual Coefficients:\n",
      "     satellite         :    0.100 (SE: 0.102, t:   0.98, p: 0.330)\n",
      "     wired             :    0.101 (SE: 0.102, t:   0.99, p: 0.321)\n",
      "     x                 :   -0.040 (SE: 0.113, t:  -0.35, p: 0.726)\n",
      "     w                 :   -0.029 (SE: 0.112, t:  -0.26, p: 0.798)\n",
      "     x**2              :    0.009 (SE: 0.045, t:   0.21, p: 0.836)\n",
      "     w**2              :    0.007 (SE: 0.044, t:   0.15, p: 0.878)\n",
      "     x*w               :   -0.041 (SE: 0.060, t:  -0.68, p: 0.496)\n",
      "     sum_x_competitors :   -0.031 (SE: 0.025, t:  -1.26, p: 0.207)\n",
      "     sum_w_competitors :   -0.002 (SE: 0.025, t:  -0.07, p: 0.941)\n",
      "     x_other_in_nest   :    0.057 (SE: 0.043, t:   1.31, p: 0.189)\n",
      "     w_other_in_nest   :   -0.012 (SE: 0.043, t:  -0.29, p: 0.776)\n",
      "   Excluded demand instruments F-stat: 0.58 (p=7.99e-01)\n",
      "   → Excluded instruments are exogenous\n",
      "\n",
      "===========================================================================\n",
      "FINAL PARAMETER CHOICE:\n",
      "===========================================================================\n",
      "Demand: α = -2, β^(1) = 1, β_i^(2) ~ N(4, 1²), β_i^(3) ~ N(4, 1²)\n",
      "Supply: γ^(0) = 0.5, γ^(1) = 0.25\n",
      "These parameters generate data with valid instruments and are retained as final.\n"
     ]
    }
   ],
   "source": [
    "# Create quadratic and interaction columns first\n",
    "product_data['x**2'] = product_data['x'] ** 2\n",
    "product_data['w**2'] = product_data['w'] ** 2\n",
    "product_data['x*w'] = product_data['x'] * product_data['w']\n",
    "\n",
    "# sum over competing goods in market t\n",
    "product_data['sum_x_competitors'] = (\n",
    "    product_data.groupby('market_ids')['x'].transform('sum') - \n",
    "    product_data['x']\n",
    ")\n",
    "product_data['sum_w_competitors'] = (\n",
    "    product_data.groupby('market_ids')['w'].transform('sum') - \n",
    "    product_data['w']\n",
    ")\n",
    "\n",
    "# index of the other good in the same nest\n",
    "product_data['x_other_in_nest'] = (\n",
    "    product_data.groupby(['market_ids', 'satellite'])['x'].transform('sum') - \n",
    "    product_data['x']\n",
    ")\n",
    "product_data['w_other_in_nest'] = (\n",
    "    product_data.groupby(['market_ids', 'satellite'])['w'].transform('sum') - \n",
    "    product_data['w']\n",
    ")\n",
    "\n",
    "# Use satellite and wired dummies instead of constant\n",
    "Z = product_data[[\n",
    "    'satellite', 'wired', 'x', 'w', 'x**2', 'w**2', 'x*w', \n",
    "    'sum_x_competitors', 'sum_w_competitors', 'x_other_in_nest', 'w_other_in_nest'\n",
    "]]\n",
    "\n",
    "# Regression 1: Prices on extended instruments (Relevance check)\n",
    "price_model = sm.OLS(product_data['prices'], Z).fit()\n",
    "\n",
    "# Regression 2: Market shares on extended instruments\n",
    "share_model = sm.OLS(product_data['shares'], Z).fit()\n",
    "\n",
    "# Regression 3: Demand unobservable ξ on instruments (Exclusion check)\n",
    "xi_model = sm.OLS(product_data['xi'], Z).fit()\n",
    "\n",
    "# Regression 4: Cost unobservable ω on instruments (Exclusion check)\n",
    "omega_model = sm.OLS(product_data['omega'], Z).fit()\n",
    "\n",
    "# Test joint significance of excluded instruments\n",
    "print(\"=\"*75)\n",
    "print(\"INSTRUMENT VALIDITY TESTS\")\n",
    "print(\"=\"*75)\n",
    "excluded_vars = ['w', 'x**2', 'w**2', 'x*w', \n",
    "                 'sum_x_competitors', 'sum_w_competitors', \n",
    "                 'x_other_in_nest', 'w_other_in_nest']\n",
    "\n",
    "# Create hypothesis string using actual variable names\n",
    "hypothesis = ', '.join([f'{var}=0' for var in excluded_vars])\n",
    "\n",
    "# F-test for excluded instruments in price regression\n",
    "price_f_test = price_model.f_test(hypothesis)\n",
    "print(f\"\\n1. Price Regression (Relevance Test)\")\n",
    "print(f\"   R²: {price_model.rsquared:.3f}\")\n",
    "print(f\"   Individual Coefficients:\")\n",
    "for i, var in enumerate(Z.columns):\n",
    "    print(f\"     {var:18s}: {price_model.params.iloc[i]:8.3f} (SE: {price_model.bse.iloc[i]:.3f}, t: {price_model.tvalues.iloc[i]:6.2f}, p: {price_model.pvalues.iloc[i]:.3f})\")\n",
    "print(f\"   Excluded demand instruments F-stat: {price_f_test.fvalue:.2f} (p={price_f_test.pvalue:.2e})\")\n",
    "print(f\"   → Excluded instruments are {'relevant' if price_f_test.pvalue < 0.01 else 'weak'} for prices\")\n",
    "\n",
    "# F-test for excluded instruments in share regression\n",
    "share_f_test = share_model.f_test(hypothesis)\n",
    "print(f\"\\n2. Share Regression (Relevance Test)\")\n",
    "print(f\"   R²: {share_model.rsquared:.3f}\")\n",
    "print(f\"   Individual Coefficients:\")\n",
    "for i, var in enumerate(Z.columns):\n",
    "    print(f\"     {var:18s}: {share_model.params.iloc[i]:8.3f} (SE: {share_model.bse.iloc[i]:.3f}, t: {share_model.tvalues.iloc[i]:6.2f}, p: {share_model.pvalues.iloc[i]:.3f})\")\n",
    "print(f\"   Excluded demand instruments F-stat: {share_f_test.fvalue:.2f} (p={share_f_test.pvalue:.2e})\")\n",
    "print(f\"   → Excluded instruments are {'relevant' if share_f_test.pvalue < 0.01 else 'weak'} for shares\")\n",
    "\n",
    "# F-test for excluded instruments in xi regression (should be insignificant)\n",
    "xi_f_test = xi_model.f_test(hypothesis)\n",
    "print(f\"\\n3. ξ Regression (Exclusion Test)\")\n",
    "print(f\"   R²: {xi_model.rsquared:.3f}\")\n",
    "print(f\"   Individual Coefficients:\")\n",
    "for i, var in enumerate(Z.columns):\n",
    "    print(f\"     {var:18s}: {xi_model.params.iloc[i]:8.3f} (SE: {xi_model.bse.iloc[i]:.3f}, t: {xi_model.tvalues.iloc[i]:6.2f}, p: {xi_model.pvalues.iloc[i]:.3f})\")\n",
    "print(f\"   Excluded demand instruments F-stat: {xi_f_test.fvalue:.2f} (p={xi_f_test.pvalue:.2e})\")\n",
    "print(f\"   → Excluded instruments are {'exogenous' if xi_f_test.pvalue >= 0.01 else 'endogenous'}\")\n",
    "\n",
    "# F-test for excluded instruments in omega regression (should be insignificant)\n",
    "omega_f_test = omega_model.f_test(hypothesis)\n",
    "print(f\"\\n4. ω Regression (Exclusion Test)\")\n",
    "print(f\"   R²: {omega_model.rsquared:.3f}\")\n",
    "print(f\"   Individual Coefficients:\")\n",
    "for i, var in enumerate(Z.columns):\n",
    "    print(f\"     {var:18s}: {omega_model.params.iloc[i]:8.3f} (SE: {omega_model.bse.iloc[i]:.3f}, t: {omega_model.tvalues.iloc[i]:6.2f}, p: {omega_model.pvalues.iloc[i]:.3f})\")\n",
    "print(f\"   Excluded demand instruments F-stat: {omega_f_test.fvalue:.2f} (p={omega_f_test.pvalue:.2e})\")\n",
    "print(f\"   → Excluded instruments are {'exogenous' if omega_f_test.pvalue >= 0.01 else 'endogenous'}\")\n",
    "\n",
    "# Assess instrument validity\n",
    "weak_instruments = (\n",
    "    (price_model.f_pvalue >= 0.01 and share_model.f_pvalue >= 0.01) or \n",
    "    (price_model.rsquared < 0.05 and share_model.rsquared < 0.05)\n",
    ")\n",
    "excluded_instruments = (\n",
    "    xi_model.f_pvalue < 0.01 or omega_model.f_pvalue < 0.01\n",
    ")\n",
    "print()\n",
    "print(\"=\"*75)\n",
    "print(\"FINAL PARAMETER CHOICE:\")\n",
    "print(\"=\"*75)\n",
    "if weak_instruments or excluded_instruments:\n",
    "    print(\"Parameters need adjustment - instruments are weak or invalid.\")\n",
    "else:\n",
    "    print(f\"Demand: α = {alpha}, β^(1) = {beta1}, β_i^(2) ~ N({beta2}, {sigma_satellite}²), β_i^(3) ~ N({beta3}, {sigma_wired}²)\")\n",
    "    print(f\"Supply: γ^(0) = {gamma0}, γ^(1) = {gamma1}\")\n",
    "    print(\"These parameters generate data with valid instruments and are retained as final.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00bc00c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   market_ids  firm_ids  product_ids      x      w  satellite  wired     xi  \\\n",
      "0           0         1            0  1.241  0.919          1      0 -0.629   \n",
      "1           0         2            1  1.471  2.068          1      0  1.005   \n",
      "2           0         3            2  2.101  0.009          0      1 -2.595   \n",
      "3           0         4            3  1.465  2.114          0      1 -0.403   \n",
      "4           1         1            0  0.818  1.106          1      0  0.846   \n",
      "5           1         2            1  1.057  0.265          1      0 -1.792   \n",
      "6           1         3            2  1.535  0.750          0      1  0.082   \n",
      "7           1         4            3  0.614  0.576          0      1 -0.624   \n",
      "\n",
      "   omega     mc  prices  shares   x**2       w**2    x*w  sum_x_competitors  \\\n",
      "0  0.676  2.258   3.466   0.052  1.539  8.452e-01  1.141              5.037   \n",
      "1 -1.620  2.258   3.467   0.333  2.163  4.278e+00  3.042              4.807   \n",
      "2  0.954  1.862   2.990   0.055  4.415  7.799e-05  0.019              4.176   \n",
      "3 -1.056  2.451   3.579   0.080  2.146  4.471e+00  3.097              4.812   \n",
      "4  0.646  2.357   3.583   0.131  0.669  1.224e+00  0.905              3.206   \n",
      "5  1.172  2.040   3.266   0.022  1.117  7.032e-02  0.280              2.967   \n",
      "6 -1.506  1.647   2.957   0.357  2.356  5.623e-01  1.151              2.489   \n",
      "7 -0.245  1.847   3.156   0.047  0.377  3.317e-01  0.354              3.410   \n",
      "\n",
      "   sum_w_competitors  x_other_in_nest  w_other_in_nest  \n",
      "0              4.192            1.471            2.068  \n",
      "1              3.043            1.241            0.919  \n",
      "2              5.102            1.465            2.114  \n",
      "3              2.997            2.101            0.009  \n",
      "4              1.591            1.057            0.265  \n",
      "5              2.432            0.818            1.106  \n",
      "6              1.948            0.614            0.576  \n",
      "7              2.122            1.535            0.750  \n"
     ]
    }
   ],
   "source": [
    "product_data.to_csv('blp.csv', index=False)\n",
    "print(product_data.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cc0d1c",
   "metadata": {},
   "source": [
    "## 4 Estimate Some Mis-specified Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df5711",
   "metadata": {},
   "source": [
    "### 5. Estimate the plain multinomial logit model of demand by OLS (ignoring the endogeneity of prices).\n",
    "\n",
    "For the plain multinomial logit model, the utility is:\n",
    "\n",
    "$$u_{ijt} = \\beta^{(1)} x_{jt} + \\beta^{(2)} satellite_{jt} + \\beta^{(3)} wired_{jt} + \\alpha p_{jt} + \\xi_{jt} + \\epsilon_{ijt}$$\n",
    "\n",
    "This implies the log-odds ratio:\n",
    "\n",
    "$$\\ln\\left(\\frac{s_{jt}}{s_{0t}}\\right) = \\delta_{jt} = \\beta^{(1)} x_{jt} + \\beta^{(2)} satellite_{jt} + \\beta^{(3)} wired_{jt} + \\alpha p_{jt} + \\xi_{jt}$$\n",
    "\n",
    "We can estimate this by OLS, regressing the logit-transformed shares on the observed product characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77b593d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Regression: ln(s_jt/s_0t) ~ x + satellite + wired + prices (no intercept)\n",
      "----------------------------------------------------------------------\n",
      "prices      :   -1.247 (SE: 0.051, t: -24.40, p: 0.000)\n",
      "x           :    0.855 (SE: 0.032, t:  26.36, p: 0.000)\n",
      "satellite   :    1.758 (SE: 0.165, t:  10.67, p: 0.000)\n",
      "wired       :    1.790 (SE: 0.164, t:  10.89, p: 0.000)\n"
     ]
    }
   ],
   "source": [
    "# Compute outside shares for each market\n",
    "product_data['outside_share'] = 1 - product_data.groupby('market_ids')['shares'].transform('sum')\n",
    "\n",
    "# Compute logit delta: ln(s_jt / s_0t)\n",
    "product_data['logit_delta'] = np.log(product_data['shares'] / product_data['outside_share'])\n",
    "\n",
    "# OLS using matrix algebra (no intercept)\n",
    "y = product_data['logit_delta'].values\n",
    "X = product_data[['prices', 'x', 'satellite', 'wired' ]].values\n",
    "\n",
    "# Compute OLS estimates: beta_hat = (X^T X)^(-1) X^T y\n",
    "beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "# Compute residuals and HC0 robust standard errors\n",
    "y_hat = X @ beta_hat\n",
    "residuals = y - y_hat\n",
    "n, k = X.shape\n",
    "\n",
    "# HC0 robust covariance matrix\n",
    "V = X.T @ np.diag(residuals**2) @ X\n",
    "cov_matrix_ols = np.linalg.inv(X.T @ X) @ V @ np.linalg.inv(X.T @ X)\n",
    "se_ols = np.sqrt(np.diag(cov_matrix_ols))\n",
    "\n",
    "# t-statistics and p-values\n",
    "t_stats = beta_hat / se_ols\n",
    "p_values = 2 * (1 - stats.norm.cdf(np.abs(t_stats)))\n",
    "\n",
    "print(\"OLS Regression: ln(s_jt/s_0t) ~ x + satellite + wired + prices (no intercept)\")\n",
    "print(\"-\" * 70)\n",
    "param_names = ['prices', 'x', 'satellite', 'wired']\n",
    "for i, param in enumerate(param_names):\n",
    "    print(f\"{param:12s}: {beta_hat[i]:8.3f} (SE: {se_ols[i]:.3f}, t: {t_stats[i]:6.2f}, p: {p_values[i]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afc88f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "==========================\n",
      " T    N     F    K1    MD \n",
      "---  ----  ---  ----  ----\n",
      "600  2400   4    4     4  \n",
      "==========================\n",
      "\n",
      "Formulations:\n",
      "=========================================================\n",
      "     Column Indices:          0      1       2        3  \n",
      "--------------------------  ------  ---  ---------  -----\n",
      "X1: Linear Characteristics  prices   x   satellite  wired\n",
      "=========================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dimensions:\n",
       "==========================\n",
       " T    N     F    K1    MD \n",
       "---  ----  ---  ----  ----\n",
       "600  2400   4    4     4  \n",
       "==========================\n",
       "\n",
       "Formulations:\n",
       "=========================================================\n",
       "     Column Indices:          0      1       2        3  \n",
       "--------------------------  ------  ---  ---------  -----\n",
       "X1: Linear Characteristics  prices   x   satellite  wired\n",
       "========================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_data['demand_instruments0'] = product_data['prices']\n",
    "ols_problem = pyblp.Problem(pyblp.Formulation('0 + prices + x + satellite + wired '), product_data)\n",
    "ols_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19dfdfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the problem ...\n",
      "Estimating standard errors ...\n",
      "Computed results after 00:00:00.\n",
      "\n",
      "Problem Results Summary:\n",
      "=============================================================\n",
      "GMM   Objective  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Shares   Condition Number  Condition Number \n",
      "----  ---------  -------  ----------------  -----------------\n",
      " 1    +1.29E-23     0        +1.53E+03          +1.94E+03    \n",
      "=============================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "========================\n",
      "Computation   Objective \n",
      "   Time      Evaluations\n",
      "-----------  -----------\n",
      " 00:00:00         1     \n",
      "========================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "==================================================\n",
      "  prices          x        satellite      wired   \n",
      "-----------  -----------  -----------  -----------\n",
      " -1.25E+00    +8.55E-01    +1.76E+00    +1.79E+00 \n",
      "(+5.11E-02)  (+3.24E-02)  (+1.65E-01)  (+1.64E-01)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Problem Results Summary:\n",
       "=============================================================\n",
       "GMM   Objective  Clipped  Weighting Matrix  Covariance Matrix\n",
       "Step    Value    Shares   Condition Number  Condition Number \n",
       "----  ---------  -------  ----------------  -----------------\n",
       " 1    +1.29E-23     0        +1.53E+03          +1.94E+03    \n",
       "=============================================================\n",
       "\n",
       "Cumulative Statistics:\n",
       "========================\n",
       "Computation   Objective \n",
       "   Time      Evaluations\n",
       "-----------  -----------\n",
       " 00:00:00         1     \n",
       "========================\n",
       "\n",
       "Beta Estimates (Robust SEs in Parentheses):\n",
       "==================================================\n",
       "  prices          x        satellite      wired   \n",
       "-----------  -----------  -----------  -----------\n",
       " -1.25E+00    +8.55E-01    +1.76E+00    +1.79E+00 \n",
       "(+5.11E-02)  (+3.24E-02)  (+1.65E-01)  (+1.64E-01)\n",
       "=================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_results = ols_problem.solve(method='1s')\n",
    "ols_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc6a2bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "('Estimates', 'Manual OLS')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('Estimates', 'PyBLP')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SEs', 'Manual OLS')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SEs', 'PyBLP')",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "be7af6aa-384d-4443-9a38-bbf1844c7798",
       "rows": [
        [
         "prices",
         "-1.2469292859721202",
         "-1.2469292859719705",
         "0.05110467529156648",
         "0.051104675291566926"
        ],
        [
         "x",
         "0.8546955133953722",
         "0.8546955133954175",
         "0.03243009285435498",
         "0.03243009285435494"
        ],
        [
         "satellite",
         "1.7582319376489783",
         "1.7582319376484663",
         "0.16483079228307596",
         "0.16483079228307385"
        ],
        [
         "wired",
         "1.7903366640065264",
         "1.7903366640059812",
         "0.16434060844976647",
         "0.16434060844976364"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Estimates</th>\n",
       "      <th colspan=\"2\" halign=\"left\">SEs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Manual OLS</th>\n",
       "      <th>PyBLP</th>\n",
       "      <th>Manual OLS</th>\n",
       "      <th>PyBLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prices</th>\n",
       "      <td>-1.247</td>\n",
       "      <td>-1.247</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>satellite</th>\n",
       "      <td>1.758</td>\n",
       "      <td>1.758</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wired</th>\n",
       "      <td>1.790</td>\n",
       "      <td>1.790</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Estimates               SEs       \n",
       "          Manual OLS  PyBLP Manual OLS  PyBLP\n",
       "prices        -1.247 -1.247      0.051  0.051\n",
       "x              0.855  0.855      0.032  0.032\n",
       "satellite      1.758  1.758      0.165  0.165\n",
       "wired          1.790  1.790      0.164  0.164"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(index=ols_results.beta_labels, data={\n",
    "    (\"Estimates\", \"Manual OLS\"): beta_hat,\n",
    "    (\"Estimates\", \"PyBLP\"): ols_results.beta.flat,\n",
    "    (\"SEs\", \"Manual OLS\"): se_ols,\n",
    "    (\"SEs\", \"PyBLP\"): ols_results.beta_se.flat,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b407c29",
   "metadata": {},
   "source": [
    "### 6. \n",
    "Re-estimate the multinomial logit model of demand by two-stage\n",
    "least squares, instrumenting for prices with the exogenous demand shifters $%\n",
    "x $ and excluded cost shifters w. Discuss how the results differ from those\n",
    "obtained by OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec453deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Stage Diagnostics:\n",
      "  R² = 0.5067\n",
      "  F-statistic (excluded instruments) = 394.82 (p = 0.0000)\n",
      "\n",
      "2SLS IV Regression: ln(s_jt/s_0t) ~ x + satellite + wired + prices_hat (no intercept)\n",
      "First stage instruments: x, w, x², w², x*w, sum_x_competitors, sum_w_competitors\n",
      "--------------------------------------------------------------------------------\n",
      "prices      :   -1.939 (SE: 0.064, t: -30.50, p: 0.000)\n",
      "x           :    0.923 (SE: 0.035, t:  26.15, p: 0.000)\n",
      "satellite   :    3.996 (SE: 0.208, t:  19.21, p: 0.000)\n",
      "wired       :    4.037 (SE: 0.209, t:  19.34, p: 0.000)\n",
      "2SLS IV Regression: ln(s_jt/s_0t) ~ x + satellite + wired + prices_hat (no intercept)\n",
      "First stage instruments: x, w, x², w², x*w, sum_x_competitors, sum_w_competitors\n",
      "--------------------------------------------------------------------------------\n",
      "prices      :   -1.939 (SE: 0.064, t: -30.50, p: 0.000)\n",
      "x           :    0.923 (SE: 0.035, t:  26.15, p: 0.000)\n",
      "satellite   :    3.996 (SE: 0.208, t:  19.21, p: 0.000)\n",
      "wired       :    4.037 (SE: 0.209, t:  19.34, p: 0.000)\n"
     ]
    }
   ],
   "source": [
    "# First stage: \n",
    "Z = product_data[['satellite', 'wired', 'x', 'w', 'x**2', 'w**2', 'x*w', 'sum_x_competitors', 'sum_w_competitors']].values  \n",
    "\n",
    "# First stage OLS:\n",
    "sigma_hat = np.linalg.inv(Z.T @ Z) @ Z.T @ product_data['prices'].values\n",
    "prices_hat = Z @ sigma_hat\n",
    "\n",
    "# First stage diagnostics\n",
    "first_stage_residuals = product_data['prices'].values - prices_hat\n",
    "SST = np.sum((product_data['prices'].values - product_data['prices'].mean())**2)\n",
    "SSR = np.sum(first_stage_residuals**2)\n",
    "R2_first_stage = 1 - SSR/SST\n",
    "\n",
    "# F-statistic for excluded instruments (w, x², w², x*w, sum_x_competitors, sum_w_competitors)\n",
    "# Restricted model: prices ~ satellite + wired + x\n",
    "Z_restricted = product_data[['satellite', 'wired', 'x']].values\n",
    "sigma_restricted = np.linalg.inv(Z_restricted.T @ Z_restricted) @ Z_restricted.T @ product_data['prices'].values\n",
    "prices_restricted = Z_restricted @ sigma_restricted\n",
    "SSR_restricted = np.sum((product_data['prices'].values - prices_restricted)**2)\n",
    "\n",
    "# F-test: F = [(SSR_r - SSR_ur)/q] / [SSR_ur/(n-k)]\n",
    "n = len(product_data)\n",
    "k = Z.shape[1]  # number of parameters in unrestricted model\n",
    "q = 6  # number of excluded instruments\n",
    "F_stat = ((SSR_restricted - SSR) / q) / (SSR / (n - k))\n",
    "p_value_F = 1 - stats.f.cdf(F_stat, q, n - k)\n",
    "\n",
    "print(f\"First Stage Diagnostics:\")\n",
    "print(f\"  R² = {R2_first_stage:.4f}\")\n",
    "print(f\"  F-statistic (excluded instruments) = {F_stat:.2f} (p = {p_value_F:.4f})\")\n",
    "print()\n",
    "\n",
    "# Second stage: Regress logit_delta on x + satellite + wired + predicted_prices\n",
    "y = product_data['logit_delta'].values\n",
    "X_hat = np.column_stack([\n",
    "    prices_hat,  # Use predicted prices from first stage\n",
    "    product_data['x'].values,\n",
    "    product_data['satellite'].values,\n",
    "    product_data['wired'].values\n",
    "])\n",
    "\n",
    "# 2SLS estimates: beta_hat_iv = (X_hat^T X_hat)^(-1) X_hat^T y\n",
    "beta_hat_iv = np.linalg.inv(X_hat.T @ X_hat) @ X_hat.T @ y\n",
    "\n",
    "# Compute 2SLS standard errors (HC0 robust)\n",
    "# Need to use original regressors X, not fitted X_hat\n",
    "X = np.column_stack([\n",
    "    product_data['prices'].values,  # Use actual prices for residuals and variance\n",
    "    product_data['x'].values,\n",
    "    product_data['satellite'].values,\n",
    "    product_data['wired'].values\n",
    "])\n",
    "\n",
    "residuals_iv = y - X @ beta_hat_iv\n",
    "\n",
    "# HC0 robust covariance for 2SLS: (X'Z(Z'Z)^{-1}Z'X)^{-1} X'Z(Z'Z)^{-1} Ω (Z'Z)^{-1}Z'X (X'Z(Z'Z)^{-1}Z'X)^{-1}\n",
    "# where Ω = diag(residuals²)\n",
    "P_Z = Z @ np.linalg.inv(Z.T @ Z) @ Z.T  # Projection matrix\n",
    "Omega = np.diag(residuals_iv**2)\n",
    "\n",
    "# Simplified: (X'P_Z X)^{-1} X'P_Z Ω P_Z X (X'P_Z X)^{-1}\n",
    "XPZ = X.T @ P_Z\n",
    "bread = np.linalg.inv(XPZ @ X)\n",
    "meat = XPZ @ Omega @ P_Z @ X\n",
    "cov_matrix_iv = bread @ meat @ bread\n",
    "se_iv = np.sqrt(np.diag(cov_matrix_iv)) \n",
    "t_stats_iv = beta_hat_iv / se_iv\n",
    "p_values_iv = 2 * (1 - stats.norm.cdf(np.abs(t_stats_iv)))\n",
    "\n",
    "print(\"2SLS IV Regression: ln(s_jt/s_0t) ~ x + satellite + wired + prices_hat (no intercept)\")\n",
    "print(\"First stage instruments: x, w, x², w², x*w, sum_x_competitors, sum_w_competitors\")\n",
    "print(\"-\" * 80)\n",
    "param_names = ['prices', 'x', 'satellite', 'wired']\n",
    "for i, param in enumerate(param_names):\n",
    "    print(f\"{param:12s}: {beta_hat_iv[i]:8.3f} (SE: {se_iv[i]:.3f}, t: {t_stats_iv[i]:6.2f}, p: {p_values_iv[i]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "904b4814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "==========================\n",
      " T    N     F    K1    MD \n",
      "---  ----  ---  ----  ----\n",
      "600  2400   4    4     9  \n",
      "==========================\n",
      "\n",
      "Formulations:\n",
      "=========================================================\n",
      "     Column Indices:          0      1       2        3  \n",
      "--------------------------  ------  ---  ---------  -----\n",
      "X1: Linear Characteristics  prices   x   satellite  wired\n",
      "=========================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dimensions:\n",
       "==========================\n",
       " T    N     F    K1    MD \n",
       "---  ----  ---  ----  ----\n",
       "600  2400   4    4     9  \n",
       "==========================\n",
       "\n",
       "Formulations:\n",
       "=========================================================\n",
       "     Column Indices:          0      1       2        3  \n",
       "--------------------------  ------  ---  ---------  -----\n",
       "X1: Linear Characteristics  prices   x   satellite  wired\n",
       "========================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add demand instruments for PyBLP\n",
    "product_data['demand_instruments0'] = product_data['w']\n",
    "product_data['demand_instruments1'] = product_data['x**2']\n",
    "product_data['demand_instruments2'] = product_data['w**2']\n",
    "product_data['demand_instruments3'] = product_data['x*w']\n",
    "product_data['demand_instruments4'] = product_data['sum_x_competitors']\n",
    "product_data['demand_instruments5'] = product_data['sum_w_competitors']\n",
    "\n",
    "iv_problem = pyblp.Problem(pyblp.Formulation('0 + prices + x + satellite + wired'), product_data)\n",
    "iv_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63d2e250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the problem ...\n",
      "Estimating standard errors ...\n",
      "Computed results after 00:00:00.\n",
      "\n",
      "Problem Results Summary:\n",
      "=============================================================\n",
      "GMM   Objective  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Shares   Condition Number  Condition Number \n",
      "----  ---------  -------  ----------------  -----------------\n",
      " 1    +4.04E+00     0        +1.26E+03          +2.79E+03    \n",
      "=============================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "========================\n",
      "Computation   Objective \n",
      "   Time      Evaluations\n",
      "-----------  -----------\n",
      " 00:00:00         1     \n",
      "========================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "==================================================\n",
      "  prices          x        satellite      wired   \n",
      "-----------  -----------  -----------  -----------\n",
      " -1.94E+00    +9.23E-01    +4.00E+00    +4.04E+00 \n",
      "(+6.36E-02)  (+3.53E-02)  (+2.08E-01)  (+2.09E-01)\n",
      "==================================================\n",
      "Computed results after 00:00:00.\n",
      "\n",
      "Problem Results Summary:\n",
      "=============================================================\n",
      "GMM   Objective  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Shares   Condition Number  Condition Number \n",
      "----  ---------  -------  ----------------  -----------------\n",
      " 1    +4.04E+00     0        +1.26E+03          +2.79E+03    \n",
      "=============================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "========================\n",
      "Computation   Objective \n",
      "   Time      Evaluations\n",
      "-----------  -----------\n",
      " 00:00:00         1     \n",
      "========================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "==================================================\n",
      "  prices          x        satellite      wired   \n",
      "-----------  -----------  -----------  -----------\n",
      " -1.94E+00    +9.23E-01    +4.00E+00    +4.04E+00 \n",
      "(+6.36E-02)  (+3.53E-02)  (+2.08E-01)  (+2.09E-01)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Problem Results Summary:\n",
       "=============================================================\n",
       "GMM   Objective  Clipped  Weighting Matrix  Covariance Matrix\n",
       "Step    Value    Shares   Condition Number  Condition Number \n",
       "----  ---------  -------  ----------------  -----------------\n",
       " 1    +4.04E+00     0        +1.26E+03          +2.79E+03    \n",
       "=============================================================\n",
       "\n",
       "Cumulative Statistics:\n",
       "========================\n",
       "Computation   Objective \n",
       "   Time      Evaluations\n",
       "-----------  -----------\n",
       " 00:00:00         1     \n",
       "========================\n",
       "\n",
       "Beta Estimates (Robust SEs in Parentheses):\n",
       "==================================================\n",
       "  prices          x        satellite      wired   \n",
       "-----------  -----------  -----------  -----------\n",
       " -1.94E+00    +9.23E-01    +4.00E+00    +4.04E+00 \n",
       "(+6.36E-02)  (+3.53E-02)  (+2.08E-01)  (+2.09E-01)\n",
       "=================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_results = iv_problem.solve(method='1s')\n",
    "iv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d140c557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "('Estimates', 'Manual IV')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('Estimates', 'PyBLP IV')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SEs', 'Manual IV')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SEs', 'PyBLP IV')",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "8b45ba96-f01e-4e77-91fb-6be025b92a09",
       "rows": [
        [
         "prices",
         "-1.9389301648893227",
         "-1.9389301648894677",
         "0.06356740349215473",
         "0.06356740349217077"
        ],
        [
         "x",
         "0.9231395885739994",
         "0.9231395885740113",
         "0.035300734739323616",
         "0.03530073473932449"
        ],
        [
         "satellite",
         "3.9961805068724976",
         "3.9961805068729195",
         "0.2080252928068301",
         "0.2080252928068782"
        ],
        [
         "wired",
         "4.036867191020655",
         "4.036867191021066",
         "0.2087005654173812",
         "0.20870056541742849"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Estimates</th>\n",
       "      <th colspan=\"2\" halign=\"left\">SEs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Manual IV</th>\n",
       "      <th>PyBLP IV</th>\n",
       "      <th>Manual IV</th>\n",
       "      <th>PyBLP IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prices</th>\n",
       "      <td>-1.939</td>\n",
       "      <td>-1.939</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>satellite</th>\n",
       "      <td>3.996</td>\n",
       "      <td>3.996</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wired</th>\n",
       "      <td>4.037</td>\n",
       "      <td>4.037</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Estimates                SEs         \n",
       "          Manual IV PyBLP IV Manual IV PyBLP IV\n",
       "prices       -1.939   -1.939     0.064    0.064\n",
       "x             0.923    0.923     0.035    0.035\n",
       "satellite     3.996    3.996     0.208    0.208\n",
       "wired         4.037    4.037     0.209    0.209"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(index=iv_results.beta_labels, data={\n",
    "    (\"Estimates\", \"Manual IV\"): beta_hat_iv,\n",
    "    (\"Estimates\", \"PyBLP IV\"): iv_results.beta.flat,\n",
    "    (\"SEs\", \"Manual IV\"): se_iv,\n",
    "    (\"SEs\", \"PyBLP IV\"): iv_results.beta_se.flat\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b33a30",
   "metadata": {},
   "source": [
    "### 7. Nested Logit Model Estimation\n",
    "\n",
    "Now estimate a nested logit model by two-stage least squares, treating \"satellite\" and \"wired\" as the two nests for the inside goods. You will probably want to review the discussion of the nested logit in Berry (1994). Note that Berry focuses on the special case in which all the \"nesting parameters\" are the same; you should allow a different nesting parameter for each nest.\n",
    "\n",
    "\n",
    "\n",
    "In Berry’s notation, this means letting the parameter become g(j) , where g (j) indicates the group (satellite\n",
    "or wired) to which each inside good j belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9d0579e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2SLS IV Regression: ln(s_jt/s_0t) ~ prices + x + satellite + wired + ln_within_share_sat + ln_within_share_wired (no intercept)\n",
      "First stage instruments: x, satellite, wired, w, x**2, w**2, x*w, sum_x_competitors, sum_w_competitors, x_other_in_nest, w_other_in_nest\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "prices              :   -1.607 (SE: 0.098, t: -16.46, p: 0.000)\n",
      "x                   :    0.803 (SE: 0.041, t:  19.47, p: 0.000)\n",
      "satellite           :    3.099 (SE: 0.606, t:   5.12, p: 0.000)\n",
      "wired               :    3.367 (SE: 0.487, t:   6.92, p: 0.000)\n",
      "ln_within_share_sat :    0.101 (SE: 0.451, t:   0.22, p: 0.823)\n",
      "ln_within_share_wired:    0.324 (SE: 0.468, t:   0.69, p: 0.488)\n"
     ]
    }
   ],
   "source": [
    "# Compute ln_within_share\n",
    "product_data[\"group_share\"] = product_data.groupby([\"market_ids\", \"satellite\"])[\"shares\"].transform(\"sum\")\n",
    "product_data[\"ln_within_share\"] = np.log(product_data[\"shares\"] / product_data[\"group_share\"])\n",
    "\n",
    "# Create nest-specific ln_within_share\n",
    "product_data[\"ln_within_share_sat\"] = product_data[\"ln_within_share\"] * product_data[\"satellite\"]\n",
    "product_data[\"ln_within_share_wired\"] = product_data[\"ln_within_share\"] * product_data[\"wired\"]\n",
    "\n",
    "# Define variables\n",
    "exog_vars = [\"x\", \"satellite\", \"wired\"]\n",
    "endog_vars = [\"prices\", \"ln_within_share_sat\", \"ln_within_share_wired\"]\n",
    "instr_vars = [\"w\", \"x**2\", \"w**2\", \"x*w\", \"sum_x_competitors\", \"sum_w_competitors\", \"x_other_in_nest\", \"w_other_in_nest\"]\n",
    "Z_vars = exog_vars + instr_vars\n",
    "\n",
    "# First stage: Z = exog + instr\n",
    "Z = product_data[Z_vars].values\n",
    "\n",
    "# First stage OLS for each endog\n",
    "n_endog = len(endog_vars)\n",
    "sigma_hat = np.zeros((Z.shape[1], n_endog))\n",
    "endog_hat = np.zeros((len(product_data), n_endog))\n",
    "for i, var in enumerate(endog_vars):\n",
    "    y_endog = product_data[var].values\n",
    "    sigma = np.linalg.inv(Z.T @ Z) @ Z.T @ y_endog\n",
    "    sigma_hat[:, i] = sigma\n",
    "    endog_hat[:, i] = Z @ sigma\n",
    "\n",
    "# Second stage: Regress logit_delta on exog + predicted_endog, reordered to match PyBLP\n",
    "y = product_data[\"logit_delta\"].values\n",
    "X_hat = np.column_stack([\n",
    "    endog_hat[:, 0],  # prices_hat\n",
    "    product_data[\"x\"].values,\n",
    "    product_data[\"satellite\"].values,\n",
    "    product_data[\"wired\"].values,\n",
    "    endog_hat[:, 1],  # ln_within_share_sat_hat\n",
    "    endog_hat[:, 2]   # ln_within_share_wired_hat\n",
    "])\n",
    "\n",
    "# 2SLS estimates\n",
    "beta_hat_iv_nested = np.linalg.inv(X_hat.T @ X_hat) @ X_hat.T @ y\n",
    "\n",
    "# Compute robust standard errors (HC0) - CORRECTED for 2SLS\n",
    "# Need to use original regressors X, not fitted X_hat\n",
    "X = np.column_stack([\n",
    "    product_data[\"prices\"].values,\n",
    "    product_data[\"x\"].values,\n",
    "    product_data[\"satellite\"].values,\n",
    "    product_data[\"wired\"].values,\n",
    "    product_data[\"ln_within_share_sat\"].values,\n",
    "    product_data[\"ln_within_share_wired\"].values\n",
    "])\n",
    "residuals_iv = y - X @ beta_hat_iv_nested\n",
    "P_Z = Z @ np.linalg.inv(Z.T @ Z) @ Z.T\n",
    "Omega = np.diag(residuals_iv**2)\n",
    "XPZ = X.T @ P_Z\n",
    "bread = np.linalg.inv(XPZ @ X)\n",
    "meat = XPZ @ Omega @ P_Z @ X\n",
    "cov_matrix_iv = bread @ meat @ bread\n",
    "se_iv_nested = np.sqrt(np.diag(cov_matrix_iv))\n",
    "t_stats_iv = beta_hat_iv_nested / se_iv_nested\n",
    "p_values_iv = 2 * (1 - stats.norm.cdf(np.abs(t_stats_iv)))\n",
    "\n",
    "print(\"2SLS IV Regression: ln(s_jt/s_0t) ~ prices + x + satellite + wired + ln_within_share_sat + ln_within_share_wired (no intercept)\")\n",
    "print(\"First stage instruments: \" + \", \".join(Z_vars))\n",
    "print(\"-\" * 120)\n",
    "param_names = [\"prices\", \"x\", \"satellite\", \"wired\", \"ln_within_share_sat\", \"ln_within_share_wired\"]\n",
    "for i, param in enumerate(param_names):\n",
    "    print(f\"{param:20s}: {beta_hat_iv_nested[i]:8.3f} (SE: {se_iv_nested[i]:.3f}, t: {t_stats_iv[i]:6.2f}, p: {p_values_iv[i]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6db266c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for nested logit\n",
    "# Note: nesting_ids needed for PyBLP, but use satellite/wired for groupby where possible\n",
    "product_data['nesting_ids'] = product_data['satellite'].map({1: 'satellite', 0: 'wired'})\n",
    "product_data['demand_instruments6'] = product_data['x_other_in_nest']\n",
    "product_data['demand_instruments7'] = product_data['w_other_in_nest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "656ee267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "===============================\n",
      " T    N     F    K1    MD    H \n",
      "---  ----  ---  ----  ----  ---\n",
      "600  2400   4    4     11    2 \n",
      "===============================\n",
      "\n",
      "Formulations:\n",
      "=========================================================\n",
      "     Column Indices:          0      1       2        3  \n",
      "--------------------------  ------  ---  ---------  -----\n",
      "X1: Linear Characteristics  prices   x   satellite  wired\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "# Nested logit formulation\n",
    "nl_problem = pyblp.Problem(pyblp.Formulation('0 + prices + x + satellite + wired'), product_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98759dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the problem ...\n",
      "\n",
      "Rho Initial Values:\n",
      "====================\n",
      "satellite    wired  \n",
      "---------  ---------\n",
      "+7.00E-01  +7.00E-01\n",
      "====================\n",
      "\n",
      "Rho Lower Bounds:\n",
      "====================\n",
      "satellite    wired  \n",
      "---------  ---------\n",
      "+0.00E+00  +0.00E+00\n",
      "====================\n",
      "\n",
      "Rho Upper Bounds:\n",
      "====================\n",
      "satellite    wired  \n",
      "---------  ---------\n",
      "+9.90E-01  +9.90E-01\n",
      "====================\n",
      "\n",
      "\n",
      "\n",
      "Rho Initial Values:\n",
      "====================\n",
      "satellite    wired  \n",
      "---------  ---------\n",
      "+7.00E-01  +7.00E-01\n",
      "====================\n",
      "\n",
      "Rho Lower Bounds:\n",
      "====================\n",
      "satellite    wired  \n",
      "---------  ---------\n",
      "+0.00E+00  +0.00E+00\n",
      "====================\n",
      "\n",
      "Rho Upper Bounds:\n",
      "====================\n",
      "satellite    wired  \n",
      "---------  ---------\n",
      "+9.90E-01  +9.90E-01\n",
      "====================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Objective   Objective     Projected                        \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares     Value    Improvement  Gradient Norm         Theta        \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  ---------  -----------  -------------  --------------------\n",
      " 1     00:00:00         0             1            0            0          0     +7.73E+01                 +1.57E+02    +7.00E-01, +7.00E-01\n",
      " 1     00:00:00         0             2            0            0          0     +1.58E+01   +6.14E+01     +6.70E+01    +0.00E+00, +0.00E+00\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Objective   Objective     Projected                        \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares     Value    Improvement  Gradient Norm         Theta        \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  ---------  -----------  -------------  --------------------\n",
      " 1     00:00:00         0             1            0            0          0     +7.73E+01                 +1.57E+02    +7.00E-01, +7.00E-01\n",
      " 1     00:00:00         0             2            0            0          0     +1.58E+01   +6.14E+01     +6.70E+01    +0.00E+00, +0.00E+00\n",
      " 1     00:00:00         1             3            0            0          0     +1.89E+00   +1.39E+01     +3.55E-01    +2.09E-01, +2.12E-01\n",
      " 1     00:00:00         2             4            0            0          0     +1.89E+00   +7.95E-04     +3.53E-01    +2.08E-01, +2.13E-01\n",
      " 1     00:00:00         1             3            0            0          0     +1.89E+00   +1.39E+01     +3.55E-01    +2.09E-01, +2.12E-01\n",
      " 1     00:00:00         2             4            0            0          0     +1.89E+00   +7.95E-04     +3.53E-01    +2.08E-01, +2.13E-01\n",
      " 1     00:00:00         2             5            0            0          0     +1.89E+00   +3.10E-03     +3.46E-01    +2.04E-01, +2.17E-01\n",
      " 1     00:00:00         2             6            0            0          0     +1.88E+00   +1.11E-02     +3.19E-01    +1.86E-01, +2.36E-01\n",
      " 1     00:00:00         2             5            0            0          0     +1.89E+00   +3.10E-03     +3.46E-01    +2.04E-01, +2.17E-01\n",
      " 1     00:00:00         2             6            0            0          0     +1.88E+00   +1.11E-02     +3.19E-01    +1.86E-01, +2.36E-01\n",
      " 1     00:00:00         3             7            0            0          0     +1.85E+00   +2.42E-02     +1.10E-04    +1.01E-01, +3.24E-01\n",
      " 1     00:00:00         3             7            0            0          0     +1.85E+00   +2.42E-02     +1.10E-04    +1.01E-01, +3.24E-01\n",
      " 1     00:00:00         4             8            0            0          0     +1.85E+00   +3.67E-11     +7.66E-09    +1.01E-01, +3.24E-01\n",
      "\n",
      "Optimization completed after 00:00:02.\n",
      "Computing the Hessian and estimating standard errors ...\n",
      " 1     00:00:00         4             8            0            0          0     +1.85E+00   +3.67E-11     +7.66E-09    +1.01E-01, +3.24E-01\n",
      "\n",
      "Optimization completed after 00:00:02.\n",
      "Computing the Hessian and estimating standard errors ...\n",
      "Computed results after 00:00:01.\n",
      "\n",
      "Problem Results Summary:\n",
      "==============================================================================================================\n",
      "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares   Condition Number  Condition Number \n",
      "----  ---------  -------------  ---------------  ---------------  -------  ----------------  -----------------\n",
      " 1    +1.85E+00    +7.66E-09       +3.21E+00        +3.15E+02        0        +1.36E+03          +4.06E+04    \n",
      "==============================================================================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "=================================================\n",
      "Computation  Optimizer  Optimization   Objective \n",
      "   Time      Converged   Iterations   Evaluations\n",
      "-----------  ---------  ------------  -----------\n",
      " 00:00:02       Yes          5             9     \n",
      "=================================================\n",
      "\n",
      "Rho Estimates (Robust SEs in Parentheses):\n",
      "========================\n",
      " satellite      wired   \n",
      "-----------  -----------\n",
      " +1.01E-01    +3.24E-01 \n",
      "(+4.51E-01)  (+4.68E-01)\n",
      "========================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "==================================================\n",
      "  prices          x        satellite      wired   \n",
      "-----------  -----------  -----------  -----------\n",
      " -1.61E+00    +8.03E-01    +3.10E+00    +3.37E+00 \n",
      "(+9.76E-02)  (+4.12E-02)  (+6.06E-01)  (+4.87E-01)\n",
      "==================================================\n",
      "Computed results after 00:00:01.\n",
      "\n",
      "Problem Results Summary:\n",
      "==============================================================================================================\n",
      "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares   Condition Number  Condition Number \n",
      "----  ---------  -------------  ---------------  ---------------  -------  ----------------  -----------------\n",
      " 1    +1.85E+00    +7.66E-09       +3.21E+00        +3.15E+02        0        +1.36E+03          +4.06E+04    \n",
      "==============================================================================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "=================================================\n",
      "Computation  Optimizer  Optimization   Objective \n",
      "   Time      Converged   Iterations   Evaluations\n",
      "-----------  ---------  ------------  -----------\n",
      " 00:00:02       Yes          5             9     \n",
      "=================================================\n",
      "\n",
      "Rho Estimates (Robust SEs in Parentheses):\n",
      "========================\n",
      " satellite      wired   \n",
      "-----------  -----------\n",
      " +1.01E-01    +3.24E-01 \n",
      "(+4.51E-01)  (+4.68E-01)\n",
      "========================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "==================================================\n",
      "  prices          x        satellite      wired   \n",
      "-----------  -----------  -----------  -----------\n",
      " -1.61E+00    +8.03E-01    +3.10E+00    +3.37E+00 \n",
      "(+9.76E-02)  (+4.12E-02)  (+6.06E-01)  (+4.87E-01)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Problem Results Summary:\n",
       "==============================================================================================================\n",
       "GMM   Objective    Projected    Reduced Hessian  Reduced Hessian  Clipped  Weighting Matrix  Covariance Matrix\n",
       "Step    Value    Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares   Condition Number  Condition Number \n",
       "----  ---------  -------------  ---------------  ---------------  -------  ----------------  -----------------\n",
       " 1    +1.85E+00    +7.66E-09       +3.21E+00        +3.15E+02        0        +1.36E+03          +4.06E+04    \n",
       "==============================================================================================================\n",
       "\n",
       "Cumulative Statistics:\n",
       "=================================================\n",
       "Computation  Optimizer  Optimization   Objective \n",
       "   Time      Converged   Iterations   Evaluations\n",
       "-----------  ---------  ------------  -----------\n",
       " 00:00:02       Yes          5             9     \n",
       "=================================================\n",
       "\n",
       "Rho Estimates (Robust SEs in Parentheses):\n",
       "========================\n",
       " satellite      wired   \n",
       "-----------  -----------\n",
       " +1.01E-01    +3.24E-01 \n",
       "(+4.51E-01)  (+4.68E-01)\n",
       "========================\n",
       "\n",
       "Beta Estimates (Robust SEs in Parentheses):\n",
       "==================================================\n",
       "  prices          x        satellite      wired   \n",
       "-----------  -----------  -----------  -----------\n",
       " -1.61E+00    +8.03E-01    +3.10E+00    +3.37E+00 \n",
       "(+9.76E-02)  (+4.12E-02)  (+6.06E-01)  (+4.87E-01)\n",
       "=================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho_initial = [0.7, 0.7]  # Initial values for rho_sat and rho_wired\n",
    "nl_results = nl_problem.solve(rho=rho_initial, method='1s')\n",
    "nl_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fe60b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta Comparison for Nested Logit:\n",
      "              Estimates                        SEs             \n",
      "          Manual Nested PyBLP Nested Manual Nested PyBLP Nested\n",
      "prices           -1.607       -1.607         0.098        0.098\n",
      "x                 0.803        0.803         0.041        0.041\n",
      "satellite         3.099        3.099         0.606        0.606\n",
      "wired             3.367        3.367         0.487        0.487\n",
      "\n",
      "Rho Comparison for Nested Logit:\n",
      "              Estimates                        SEs             \n",
      "          Manual Nested PyBLP Nested Manual Nested PyBLP Nested\n",
      "satellite         0.101        0.101         0.451        0.451\n",
      "wired             0.324        0.324         0.468        0.468\n"
     ]
    }
   ],
   "source": [
    "# Compare manual nested logit estimates with PyBLP nested logit estimates for beta\n",
    "nested_beta_comparison = pd.DataFrame(index=nl_results.beta_labels, data={\n",
    "    (\"Estimates\", \"Manual Nested\"): beta_hat_iv_nested[:4],  # prices, x, satellite, wired\n",
    "    (\"Estimates\", \"PyBLP Nested\"): nl_results.beta.flat,\n",
    "    (\"SEs\", \"Manual Nested\"): se_iv_nested[:4],\n",
    "    (\"SEs\", \"PyBLP Nested\"): nl_results.beta_se.flat\n",
    "})\n",
    "\n",
    "print(\"Beta Comparison for Nested Logit:\")\n",
    "print(nested_beta_comparison)\n",
    "\n",
    "# Compare rho estimates\n",
    "nested_rho_comparison = pd.DataFrame(index=nl_results.rho_labels, data={\n",
    "    (\"Estimates\", \"Manual Nested\"): beta_hat_iv_nested[4:],  # rho_sat, rho_wired\n",
    "    (\"Estimates\", \"PyBLP Nested\"): nl_results.rho.flat,\n",
    "    (\"SEs\", \"Manual Nested\"): se_iv_nested[4:],\n",
    "    (\"SEs\", \"PyBLP Nested\"): nl_results.rho_se.flat\n",
    "})\n",
    "\n",
    "print(\"\\nRho Comparison for Nested Logit:\")\n",
    "print(nested_rho_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e598ac",
   "metadata": {},
   "source": [
    "### 8.\n",
    "Using the nested logit results, provide a table comparing the estimated own-price elasticities to the true own-price elasticities. The procedure you developed above for approximating derivatives cannot be used for your estimates based\n",
    "on the nested logit model. But because we have analytic expressions for market shares in the nested logit model,\n",
    "you could either differentiate these or use “finite difference” approximation of derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b6f9beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Nested Logit Elasticities (Analytical Derivatives)...\n",
      "Computing True RC Logit Elasticities (True Parameters on OBSERVED shares)...\n",
      "\n",
      "======================================================================\n",
      "OWN-PRICE ELASTICITY COMPARISON\n",
      "======================================================================\n",
      "Nested Logit (Estimated) vs RC Logit (True params, observed shares)\n",
      "    Product  True (RC)  Estimated (NL)  Abs % Error\n",
      "Satellite 1     -5.480          -4.998        8.800\n",
      "Satellite 2     -5.315          -4.855        8.649\n",
      "    Wired 1     -5.377          -5.904        9.795\n",
      "    Wired 2     -5.458          -6.001        9.955\n",
      "\n",
      "Mean Absolute % Error: 9.30%\n",
      "\n",
      "Note: NL model misspecified (true DGP is RC), so errors expected\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "OWN-PRICE ELASTICITY COMPARISON\n",
      "======================================================================\n",
      "Nested Logit (Estimated) vs RC Logit (True params, observed shares)\n",
      "    Product  True (RC)  Estimated (NL)  Abs % Error\n",
      "Satellite 1     -5.480          -4.998        8.800\n",
      "Satellite 2     -5.315          -4.855        8.649\n",
      "    Wired 1     -5.377          -5.904        9.795\n",
      "    Wired 2     -5.458          -6.001        9.955\n",
      "\n",
      "Mean Absolute % Error: 9.30%\n",
      "\n",
      "Note: NL model misspecified (true DGP is RC), so errors expected\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract nested logit parameters\n",
    "alpha_nl, beta_x_nl, rho_sat_nl, rho_wired_nl = beta_hat_iv_nested[[0, 1, 4, 5]]\n",
    "\n",
    "def compute_nested_logit_elasticities_analytic(market_df, alpha, beta_x, rho_sat, rho_wired):\n",
    "    \"\"\"Compute elasticities using pyBLP's exact Jacobian formula for nested logit.\n",
    "    \n",
    "    Based on pyBLP's compute_capital_lamda_gamma:\n",
    "    - Lambda_jj = alpha * s_j / (1 - rho_j)\n",
    "    - Gamma_jk = alpha * s_j * s_k + rho/(1-rho) * membership_jk * alpha * s_j|g * s_k\n",
    "    - Jacobian[j,k] = Lambda_jj - Gamma_jk (if j==k), -Gamma_jk (if j!=k)\n",
    "    - Elasticity[j,k] = Jacobian[j,k] * price[k] / share[j]\n",
    "    \n",
    "    This matches pyBLP to within ~1% numerical precision.\n",
    "    \"\"\"\n",
    "    J = len(market_df)\n",
    "    prices = market_df['prices'].values\n",
    "    shares = market_df['shares'].values\n",
    "    satellite, wired = market_df['satellite'].values, market_df['wired'].values\n",
    "    \n",
    "    # Compute within-nest shares (conditionals in pyBLP terminology)\n",
    "    s_group = market_df.groupby('satellite')['shares'].transform('sum').values\n",
    "    conditionals = shares / s_group\n",
    "    \n",
    "    # Nesting parameter for each product\n",
    "    rho = np.where(satellite == 1, rho_sat, rho_wired)\n",
    "    \n",
    "    # Compute full elasticity matrix using pyBLP's formula\n",
    "    elasticities = np.zeros((J, J))\n",
    "    for j in range(J):\n",
    "        # Lambda diagonal element\n",
    "        lambda_jj = alpha * shares[j] / (1 - rho[j])\n",
    "        \n",
    "        for k in range(J):\n",
    "            # Gamma matrix element\n",
    "            same_nest = (satellite[j] == satellite[k]) and (wired[j] == wired[k])\n",
    "            gamma_jk = alpha * shares[j] * shares[k]\n",
    "            if same_nest:\n",
    "                gamma_jk += (rho[j] / (1 - rho[j])) * alpha * conditionals[j] * shares[k]\n",
    "            \n",
    "            # Jacobian = Lambda - Gamma (on diagonal), -Gamma (off-diagonal)\n",
    "            if j == k:\n",
    "                jac_jk = lambda_jj - gamma_jk\n",
    "            else:\n",
    "                jac_jk = -gamma_jk\n",
    "            \n",
    "            # Elasticity = Jacobian * price / share\n",
    "            elasticities[j, k] = jac_jk * prices[k] / shares[j]\n",
    "    \n",
    "    return elasticities\n",
    "\n",
    "def compute_rc_elasticities_observed_shares(market_df, nu_draws, alpha, beta_x, beta_sat, beta_wired, sigma_sat, sigma_wired):\n",
    "    \"\"\"Compute elasticities from RC logit using OBSERVED shares (not recomputed from xi).\n",
    "    \n",
    "    This matches pyBLP's approach:\n",
    "    1. Start with observed shares\n",
    "    2. Back out mean utilities (delta) that rationalize these shares via contraction mapping\n",
    "    3. Compute individual choice probabilities using delta + random coefficients\n",
    "    4. Compute elasticities via analytical derivatives\n",
    "    \n",
    "    Key difference from old method:\n",
    "    - OLD: Uses TRUE xi to compute shares, then elasticities (wrong for comparison!)\n",
    "    - NEW: Uses OBSERVED shares, backs out delta, then computes elasticities (correct!)\n",
    "    \"\"\"\n",
    "    J = len(market_df)\n",
    "    prices = market_df['prices'].values\n",
    "    observed_shares = market_df['shares'].values\n",
    "    x, satellite, wired = market_df['x'].values, market_df['satellite'].values, market_df['wired'].values\n",
    "    \n",
    "    # Compute random coefficient deviations (the part that varies across individuals)\n",
    "    # Delta will absorb everything else: beta_x*x + beta_sat*satellite + beta_wired*wired + alpha*prices + xi\n",
    "    rc_deviation = sigma_sat*nu_draws[:,0:1]*satellite + sigma_wired*nu_draws[:,1:2]*wired\n",
    "    \n",
    "    # Back out mean utilities (delta) via contraction mapping\n",
    "    # Goal: Find delta such that observed_shares = E[exp(delta + rc_deviation) / (1 + sum exp(delta + rc_deviation))]\n",
    "    delta = np.log(observed_shares)  # Initial guess\n",
    "    \n",
    "    for iteration in range(1000):\n",
    "        # Compute individual choice probabilities\n",
    "        utilities = delta[np.newaxis, :] + rc_deviation  # Shape: (n_draws, J)\n",
    "        exp_utils = np.exp(utilities)\n",
    "        denom = 1 + exp_utils.sum(axis=1, keepdims=True)\n",
    "        choice_probs = exp_utils / denom  # Shape: (n_draws, J)\n",
    "        \n",
    "        # Predicted shares\n",
    "        predicted_shares = choice_probs.mean(axis=0)\n",
    "        \n",
    "        # Contraction update: delta_new = delta + log(s_obs) - log(s_pred)\n",
    "        delta_new = delta + np.log(observed_shares) - np.log(predicted_shares)\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.max(np.abs(delta_new - delta)) < 1e-14:\n",
    "            delta = delta_new\n",
    "            break\n",
    "        delta = delta_new\n",
    "    \n",
    "    # Compute final choice probabilities with converged delta\n",
    "    utilities = delta[np.newaxis, :] + rc_deviation\n",
    "    exp_utils = np.exp(utilities)\n",
    "    choice_probs = exp_utils / (1 + exp_utils.sum(axis=1, keepdims=True))\n",
    "    \n",
    "    # Compute elasticities using analytical derivatives\n",
    "    elasticities = np.zeros((J, J))\n",
    "    for j in range(J):\n",
    "        for k in range(J):\n",
    "            if j == k:\n",
    "                # Own-price: E[s_ij * (1 - s_ij)]\n",
    "                deriv = alpha * np.mean(choice_probs[:, j] * (1 - choice_probs[:, j]))\n",
    "            else:\n",
    "                # Cross-price: -E[s_ij * s_ik]\n",
    "                deriv = -alpha * np.mean(choice_probs[:, j] * choice_probs[:, k])\n",
    "            \n",
    "            if observed_shares[j] > 1e-10:\n",
    "                elasticities[j, k] = (prices[k] / observed_shares[j]) * deriv\n",
    "    \n",
    "    return elasticities\n",
    "\n",
    "# ============================================================================\n",
    "# Compute elasticities for Q8 comparison\n",
    "# ============================================================================\n",
    "\n",
    "# Compute Nested Logit elasticities (analytical derivatives)\n",
    "# Compute Nested Logit elasticities (analytical derivatives)\n",
    "print(\"Computing Nested Logit Elasticities (Analytical Derivatives)...\")\n",
    "elasticity_matrices_analytic = [compute_nested_logit_elasticities_analytic(\n",
    "    product_data[product_data['market_ids'] == t], alpha_nl, beta_x_nl, rho_sat_nl, rho_wired_nl\n",
    ") for t in range(T)]\n",
    "\n",
    "print(\"Computing True RC Logit Elasticities (True Parameters on OBSERVED shares)...\")\n",
    "# Use the new function that works with observed shares for fair comparison\n",
    "true_elasticity_matrices = [compute_rc_elasticities_observed_shares(\n",
    "    product_data[product_data['market_ids'] == t], all_nu_draws[t], -2.0, 1.0, 4.0, 4.0, 1.0, 1.0\n",
    ") for t in range(T)]\n",
    "\n",
    "avg_elasticity_matrix_nl = np.mean(elasticity_matrices_analytic, axis=0)\n",
    "avg_elasticity_matrix_true = np.mean(true_elasticity_matrices, axis=0)\n",
    "\n",
    "# Comparison table\n",
    "print(\"\\n\" + \"=\"*70 + \"\\nOWN-PRICE ELASTICITY COMPARISON\\n\" + \"=\"*70)\n",
    "print(\"Nested Logit (Estimated) vs RC Logit (True params, observed shares)\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Product': ['Satellite 1', 'Satellite 2', 'Wired 1', 'Wired 2'],\n",
    "    'True (RC)': np.diag(avg_elasticity_matrix_true),\n",
    "    'Estimated (NL)': np.diag(avg_elasticity_matrix_nl),\n",
    "    'Abs % Error': np.abs(100 * (np.diag(avg_elasticity_matrix_nl) - np.diag(avg_elasticity_matrix_true)) / np.diag(avg_elasticity_matrix_true))\n",
    "})\n",
    "print(comparison_df.to_string(index=False, float_format=lambda x: f'{x:8.3f}'))\n",
    "print(f\"\\nMean Absolute % Error: {comparison_df['Abs % Error'].mean():.2f}%\")\n",
    "print(\"\\nNote: NL model misspecified (true DGP is RC), so errors expected\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Store elasticities in product_data\n",
    "product_data['true_elasticity_rc'] = [true_elasticity_matrices[t][j, j] for t in range(T) for j in range(J)]\n",
    "product_data['estimated_elasticity_nl'] = [elasticity_matrices_analytic[t][j, j] for t in range(T) for j in range(J)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47b846f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing elasticities with respect to prices ...\n",
      "Finished after 00:00:00.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-4.99800789, -4.85483762, -5.90389083, -6.00138066])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticities_nl = nl_results.compute_elasticities()\n",
    "avg_elasticities_nl = elasticities_nl.reshape((T, J, J)).mean(axis=0)\n",
    "own_elasticities_nl = np.diag(avg_elasticities_nl)\n",
    "own_elasticities_nl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa6d2b",
   "metadata": {},
   "source": [
    "Provide two additional tables showing the true\n",
    "matrix of diversion ratios and the diversion ratios implied by your estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b71944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Diversion Ratios...\n",
      "Computing TRUE RC diversion ratios (true params, observed shares)...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DIVERSION RATIOS\n",
    "# ============================================================================\n",
    "# Using PyBLP's derivative-based method for both RC and NL models\n",
    "# Convention: Diagonal shows diversion to outside option D_j0 instead of D_jj=-1\n",
    "\n",
    "print(\"Computing Diversion Ratios...\")\n",
    "\n",
    "# Unified function using PyBLP's derivative-based approach\n",
    "def compute_diversion_ratios_pyblp(elasticity_matrices, product_data, T, J):\n",
    "    \"\"\"\n",
    "    Compute diversion ratios using pyBLP's derivative-based method.\n",
    "    \n",
    "    This method:\n",
    "    1. Converts elasticities to Jacobian (derivatives)\n",
    "    2. Replaces diagonal with outside option derivative using adding-up constraint\n",
    "    3. Computes diversion ratios as D_jk = -(∂s_k/∂p_j) / (∂s_j/∂p_j)\n",
    "    \n",
    "    Works for any model (RC, NL, etc.) - just supply the elasticity matrices.\n",
    "    \"\"\"\n",
    "    diversion_matrices = []\n",
    "    \n",
    "    for t in range(T):\n",
    "        elast_matrix = elasticity_matrices[t]\n",
    "        market_data_t = product_data[product_data['market_ids'] == t]\n",
    "        shares = market_data_t['shares'].values\n",
    "        prices = market_data_t['prices'].values\n",
    "        \n",
    "        # Convert elasticities to Jacobian (derivatives): ∂s_j/∂p_k = (s_j/p_k) * ε_jk\n",
    "        jacobian = np.zeros((J, J))\n",
    "        for j in range(J):\n",
    "            for k in range(J):\n",
    "                jacobian[j, k] = (shares[j] / prices[k]) * elast_matrix[j, k]\n",
    "        \n",
    "        # PyBLP's method: Replace diagonal with outside option derivative\n",
    "        # ∂s_0/∂p_j = -Σ_k ∂s_k/∂p_j (by adding-up constraint)\n",
    "        jacobian_diag = np.diag(jacobian).copy()\n",
    "        np.fill_diagonal(jacobian, -jacobian.sum(axis=1))\n",
    "        \n",
    "        # Compute diversion ratios: D_jk = -Jacobian[j,k] / Jacobian[j,j]\n",
    "        diversion = -jacobian / jacobian_diag[:, None]\n",
    "        \n",
    "        diversion_matrices.append(diversion)\n",
    "    \n",
    "    return diversion_matrices\n",
    "\n",
    "# --- TRUE DIVERSION RATIOS (from RC model with true parameters on OBSERVED shares) ---\n",
    "# Note: We recompute true elasticities here to ensure we use observed shares\n",
    "print(\"Computing TRUE RC diversion ratios (true params, observed shares)...\")\n",
    "true_elasticity_matrices_for_div = [compute_rc_elasticities_observed_shares(\n",
    "    product_data[product_data['market_ids'] == t], all_nu_draws[t], -2.0, 1.0, 4.0, 4.0, 1.0, 1.0\n",
    ") for t in range(T)]\n",
    "\n",
    "true_diversion_matrices = compute_diversion_ratios_pyblp(\n",
    "    true_elasticity_matrices_for_div, product_data, T, J\n",
    ")\n",
    "true_avg_diversion = np.mean(true_diversion_matrices, axis=0)\n",
    "\n",
    "# --- ESTIMATED DIVERSION RATIOS (from Nested Logit) ---\n",
    "estimated_diversion_matrices = compute_diversion_ratios_pyblp(\n",
    "    elasticity_matrices_analytic, product_data, T, J\n",
    ")\n",
    "estimated_avg_diversion = np.mean(estimated_diversion_matrices, axis=0)\n",
    "\n",
    "# --- DISPLAY RESULTS ---\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DIVERSION RATIO MATRICES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "product_labels = ['Sat 1', 'Sat 2', 'Wired 1', 'Wired 2']\n",
    "\n",
    "print(\"\\nTrue Diversion Ratios (RC Logit with TRUE params on OBSERVED shares):\")\n",
    "print(\"Diagonal = diversion to outside option D_j0\")\n",
    "true_df = pd.DataFrame(true_avg_diversion, index=product_labels, columns=product_labels)\n",
    "print(true_df.to_string(float_format=lambda x: f'{x:7.4f}'))\n",
    "\n",
    "print(\"\\n\\nEstimated Diversion Ratios (from Nested Logit - PyBLP Method):\")\n",
    "print(\"Diagonal = diversion to outside option D_j0\")\n",
    "est_df = pd.DataFrame(estimated_avg_diversion, index=product_labels, columns=product_labels)\n",
    "print(est_df.to_string(float_format=lambda x: f'{x:7.4f}'))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Note: D_jk = -(∂s_k/∂p_j) / (∂s_j/∂p_j)\")\n",
    "print(\"Off-diagonal: share of j's lost customers who switch to product k\")\n",
    "print(\"Diagonal: share of j's lost customers who leave the market (outside)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940ab563",
   "metadata": {},
   "source": [
    "## 5 Estimate the Correctly Specified Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19841e0a",
   "metadata": {},
   "source": [
    "Use the pyBLP software to estimate the correctly specified model. Allow pyBLP to construct\n",
    "approximations to the optimal instruments, using the exogenous demand shifters and exogenous\n",
    "cost shifters. For your own benefit, you may want to see what happens without the approximation of the optimal instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e160701",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data.drop(columns=['nesting_ids'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c983afe3",
   "metadata": {},
   "source": [
    "### 9. \n",
    "Report a table with the estimates of the demand parameters and standard errors. Do\n",
    "this twice: once when you estimate demand alone, then again when you estimate jointly\n",
    "with supply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b54f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_formulation = pyblp.Formulation('0 + prices + x + satellite + wired')\n",
    "X2_formulation = pyblp.Formulation('0 + satellite + wired')\n",
    "product_formulations1 = (X1_formulation, X2_formulation)\n",
    "product_data['demand_instruments0'] = product_data['w']\n",
    "product_data['demand_instruments1'] = product_data['x**2']\n",
    "product_data['demand_instruments2'] = product_data['w**2']\n",
    "product_data['demand_instruments3'] = product_data['x*w']\n",
    "product_data['demand_instruments4'] = product_data['sum_x_competitors']\n",
    "product_data['demand_instruments5'] = product_data['sum_w_competitors']\n",
    "product_data['demand_instruments6'] = product_data['x_other_in_nest']\n",
    "product_data['demand_instruments7'] = product_data['w_other_in_nest']\n",
    "integration =  pyblp.Integration('product', 10)\n",
    "problem1 = pyblp.Problem(product_formulations1, product_data, integration=integration)\n",
    "results1 = problem1.solve(sigma=np.eye(2), initial_update=True)\n",
    "optimal_iv1 = results1.compute_optimal_instruments(seed=1995)\n",
    "optimal_problem1 = optimal_iv1.to_problem()\n",
    "optimal_iv_results1 = optimal_problem1.solve(sigma=np.eye(2), initial_update=True)\n",
    "optimal_iv_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_formulation = pyblp.Formulation('1 + w')\n",
    "product_formulations2 = (X1_formulation, X2_formulation, X3_formulation)\n",
    "columns_to_drop = [col for col in product_data.columns if 'instruments' in col]\n",
    "product_data = product_data.drop(columns=columns_to_drop)\n",
    "product_data['demand_instruments0'] = optimal_iv1.demand_instruments[:, 0]\n",
    "product_data['demand_instruments1'] = optimal_iv1.demand_instruments[:, 1]\n",
    "product_data['demand_instruments2'] = product_data['w']\n",
    "problem2 = pyblp.Problem(product_formulations2, product_data, costs_type='log', integration=integration)\n",
    "results2 = problem2.solve(sigma=np.eye(2), beta=optimal_iv_results1.beta, initial_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-estimate with optimal instruments\n",
    "columns_to_drop = [col for col in product_data.columns \n",
    "                   if 'instruments' in col]\n",
    "product_data = product_data.drop(columns=columns_to_drop)\n",
    "optimal_iv2 = results2.compute_optimal_instruments(seed=1995)\n",
    "for i in range(optimal_iv2.demand_instruments.shape[1]-3):\n",
    "    product_data[f'demand_instruments{i}'] = optimal_iv2.demand_instruments[:, i]\n",
    "problem3 = pyblp.Problem(product_formulations2, product_data, \n",
    "                         costs_type='log', integration=integration)\n",
    "optimal_iv_results2 = problem3.solve(sigma=np.eye(2), beta=results2.beta, initial_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d4c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare individual and joint PyBLP estimates for beta\n",
    "pyblp_beta_comparison = pd.DataFrame(index=optimal_iv_results1.beta_labels, data={\n",
    "    (\"Estimates\", \"PyBLP D\"): optimal_iv_results1.beta.flat,  # prices, x, satellite, wired\n",
    "    (\"Estimates\", \"PyBLP D & S\"): optimal_iv_results2.beta.flat,\n",
    "    (\"SEs\", \"PyBLP D\"): optimal_iv_results1.beta_se.flat,\n",
    "    (\"SEs\", \"PyBLP D & S\"): optimal_iv_results2.beta_se.flat\n",
    "})\n",
    "print(\"Beta Comparison:\")\n",
    "print(pyblp_beta_comparison)\n",
    "# Compare sigma estimates\n",
    "pyblp_sigma_comparison = pd.DataFrame(index=optimal_iv_results1.sigma_labels, data={\n",
    "    (\"Estimates\", \"PyBLP D\"): optimal_iv_results1.sigma.diagonal(),\n",
    "    (\"Estimates\", \"PyBLP D & S\"): optimal_iv_results2.sigma.diagonal(),\n",
    "    (\"SEs\", \"PyBLP D\"): optimal_iv_results1.sigma_se.diagonal(),\n",
    "    (\"SEs\", \"PyBLP D & S\"): optimal_iv_results2.sigma_se.diagonal()\n",
    "})\n",
    "print(\"\\nSigma Comparison:\")\n",
    "print(pyblp_sigma_comparison)\n",
    "\n",
    "# Compare gamma estimates (only available in joint estimation)\n",
    "print(\"\\n\\nGamma Estimates (only from joint D & S estimation):\")\n",
    "pyblp_gamma_comparison = pd.DataFrame(index=optimal_iv_results2.gamma_labels, data={\n",
    "    (\"Estimates\", \"PyBLP D & S\"): optimal_iv_results2.gamma.flat,\n",
    "    (\"SEs\", \"PyBLP D & S\"): optimal_iv_results2.gamma_se.flat,\n",
    "})\n",
    "print(pyblp_gamma_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8228d9",
   "metadata": {},
   "source": [
    "### 10. \n",
    "Using your preferred estimates from the prior step (explain your preference), provide\n",
    "a table comparing the estimated own-price elasticities to the true own-price elasticities.\n",
    "Provide two additional tables showing the true matrix of diversion ratios and the diversion\n",
    "ratios implied by your estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "#VSC-7655b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Q9: Compare TRUE vs ESTIMATED Random Coefficients Elasticities/Diversions\n",
    "# ============================================================================\n",
    "# Reuse TRUE elasticities computed in Q8 to avoid redundancy\n",
    "print(\"Using TRUE elasticities from Q8 (true params, observed shares)...\")\n",
    "print(f\"  (Already computed {len(true_elasticity_matrices_for_div)} markets)\")\n",
    "true_elasticity_matrices_obs = true_elasticity_matrices_for_div  # Reuse from Q8\n",
    "avg_elasticity_matrix_true_rc = np.mean(true_elasticity_matrices_obs, axis=0)\n",
    "own_elasticities_rc_true = np.diag(avg_elasticity_matrix_true_rc)\n",
    "\n",
    "# Compute ESTIMATED elasticities - DEMAND ONLY\n",
    "print(\"Computing ESTIMATED elasticities (demand-only params, observed shares)...\")\n",
    "elasticities_rc_est1 = optimal_iv_results1.compute_elasticities()\n",
    "avg_elasticities_rc_est1 = elasticities_rc_est1.reshape((T, J, J)).mean(axis=0)\n",
    "own_elasticities_rc_est1 = np.diag(avg_elasticities_rc_est1)\n",
    "\n",
    "# Compute ESTIMATED elasticities - JOINT DEMAND & SUPPLY\n",
    "print(\"Computing ESTIMATED elasticities (joint D&S params, observed shares)...\")\n",
    "elasticities_rc_est2 = optimal_iv_results2.compute_elasticities()\n",
    "avg_elasticities_rc_est2 = elasticities_rc_est2.reshape((T, J, J)).mean(axis=0)\n",
    "own_elasticities_rc_est2 = np.diag(avg_elasticities_rc_est2)\n",
    "\n",
    "# Show parameter differences\n",
    "print(\"\\nParameter Comparison:\")\n",
    "print(\"                 True      Demand-only    Joint D&S\")\n",
    "print(f\"α (price):      -2.000    {optimal_iv_results1.beta[0,0]:7.3f}      {optimal_iv_results2.beta[0,0]:7.3f}\")\n",
    "print(f\"σ_satellite:     1.000    {optimal_iv_results1.sigma[0,0]:7.3f}      {optimal_iv_results2.sigma[0,0]:7.3f}\")\n",
    "print(f\"σ_wired:         1.000    {optimal_iv_results1.sigma[1,1]:7.3f}      {optimal_iv_results2.sigma[1,1]:7.3f}\")\n",
    "print()\n",
    "\n",
    "# Create comparison table with THREE columns\n",
    "product_labels = ['Sat 1', 'Sat 2', 'Wired 1', 'Wired 2']\n",
    "elasticity_comparison_rc = pd.DataFrame({\n",
    "    'Product': product_labels,\n",
    "    'True': own_elasticities_rc_true,\n",
    "    'Demand-only': own_elasticities_rc_est1,\n",
    "    'Joint D&S': own_elasticities_rc_est2,\n",
    "    '% Error (D-only)': np.abs((own_elasticities_rc_est1 - own_elasticities_rc_true) / own_elasticities_rc_true * 100),\n",
    "    '% Error (Joint)': np.abs((own_elasticities_rc_est2 - own_elasticities_rc_true) / own_elasticities_rc_true * 100)\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 95)\n",
    "print(\"TABLE 1: OWN-PRICE ELASTICITY COMPARISON\")\n",
    "print(\"True = RC logit with TRUE params (-2, 1, 4, 4, 1, 1) on OBSERVED shares\")\n",
    "print(\"Demand-only = RC logit with demand-only estimated params on OBSERVED shares\")\n",
    "print(\"Joint D&S = RC logit with joint demand & supply estimated params on OBSERVED shares\")\n",
    "print(\"=\" * 95)\n",
    "print(elasticity_comparison_rc.to_string(index=False, float_format=lambda x: f'{x:9.4f}'))\n",
    "print(f\"\\nMean Absolute % Error (Demand-only): {elasticity_comparison_rc['% Error (D-only)'].mean():.2f}%\")\n",
    "print(f\"Mean Absolute % Error (Joint D&S):   {elasticity_comparison_rc['% Error (Joint)'].mean():.2f}%\")\n",
    "\n",
    "\n",
    "# --- DIVERSION RATIO COMPARISON ---\n",
    "# Reuse TRUE diversion ratios computed in Q8 to avoid redundancy\n",
    "print(\"\\nUsing TRUE diversion ratios from Q8 (true params, observed shares)...\")\n",
    "print(f\"  (Already computed {len(true_diversion_matrices)} markets)\")\n",
    "true_diversion_matrices_obs = true_diversion_matrices  # Reuse from Q8\n",
    "true_avg_diversion_rc = np.mean(true_diversion_matrices_obs, axis=0)\n",
    "\n",
    "# RC estimated diversion ratios - DEMAND ONLY\n",
    "diversion_rc_est1 = optimal_iv_results1.compute_diversion_ratios()\n",
    "avg_diversion_rc_est1 = diversion_rc_est1.reshape((T, J, J)).mean(axis=0)\n",
    "\n",
    "# RC estimated diversion ratios - JOINT D&S\n",
    "diversion_rc_est2 = optimal_iv_results2.compute_diversion_ratios()\n",
    "avg_diversion_rc_est2 = diversion_rc_est2.reshape((T, J, J)).mean(axis=0)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TABLE 2: TRUE DIVERSION RATIOS\")\n",
    "print(\"(from RC Logit with TRUE params: σ_sat=1.0, σ_wired=1.0, on OBSERVED shares)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Diagonal = diversion to outside option D_j0\")\n",
    "true_div_df_rc = pd.DataFrame(true_avg_diversion_rc, index=product_labels, columns=product_labels)\n",
    "print(true_div_df_rc.to_string(float_format=lambda x: f'{x:7.4f}'))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TABLE 3: ESTIMATED DIVERSION RATIOS - DEMAND ONLY\")\n",
    "print(f\"(from RC Logit with DEMAND-ONLY params: σ_sat={optimal_iv_results1.sigma[0,0]:.3f}, σ_wired={optimal_iv_results1.sigma[1,1]:.3f})\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Diagonal = diversion to outside option D_j0\")\n",
    "est_div_df_rc1 = pd.DataFrame(avg_diversion_rc_est1, index=product_labels, columns=product_labels)\n",
    "print(est_div_df_rc1.to_string(float_format=lambda x: f'{x:7.4f}'))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TABLE 4: ESTIMATED DIVERSION RATIOS - JOINT DEMAND & SUPPLY\")\n",
    "print(f\"(from RC Logit with JOINT D&S params: σ_sat={optimal_iv_results2.sigma[0,0]:.3f}, σ_wired={optimal_iv_results2.sigma[1,1]:.3f})\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Diagonal = diversion to outside option D_j0\")\n",
    "est_div_df_rc2 = pd.DataFrame(avg_diversion_rc_est2, index=product_labels, columns=product_labels)\n",
    "print(est_div_df_rc2.to_string(float_format=lambda x: f'{x:7.4f}'))\n",
    "\n",
    "# Calculate diversion errors\n",
    "div_error_d_only = np.abs((avg_diversion_rc_est1 - true_avg_diversion_rc) / true_avg_diversion_rc * 100)\n",
    "div_error_joint = np.abs((avg_diversion_rc_est2 - true_avg_diversion_rc) / true_avg_diversion_rc * 100)\n",
    "print(f\"  • True model (σ=1.0):                 {true_avg_diversion_rc[0,0]:.1%} to outside\")\n",
    "print(f\"  • Demand-only (σ_sat={optimal_iv_results1.sigma[0,0]:.2f}, σ_wired={optimal_iv_results1.sigma[1,1]:.2f}): {avg_diversion_rc_est1[0,0]:.1%} to outside\")\n",
    "print(f\"  • Joint D&S (σ_sat={optimal_iv_results2.sigma[0,0]:.2f}, σ_wired={optimal_iv_results2.sigma[1,1]:.2f}):   {avg_diversion_rc_est2[0,0]:.1%} to outside\")\n",
    "print()\n",
    "print(f\"Mean Absolute % Error in Diversion Ratios:\")\n",
    "print(f\"  • Demand-only: {div_error_d_only.mean():.2f}%\")\n",
    "print(f\"  • Joint D&S:   {div_error_joint.mean():.2f}%\")\n",
    "print()\n",
    "print(\"Example: When Sat 1 price ↑ 1%, where do lost customers go?\")\n",
    "print(f\"  TRUE model:       {true_avg_diversion_rc[0,0]:.1%} to outside, {true_avg_diversion_rc[0,1]:.1%} to Sat 2\")\n",
    "print(f\"  DEMAND-only:      {avg_diversion_rc_est1[0,0]:.1%} to outside, {avg_diversion_rc_est1[0,1]:.1%} to Sat 2\")\n",
    "print(f\"  JOINT D&S:        {avg_diversion_rc_est2[0,0]:.1%} to outside, {avg_diversion_rc_est2[0,1]:.1%} to Sat 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873bc298",
   "metadata": {},
   "source": [
    "## 6 Merger Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b777443f",
   "metadata": {},
   "source": [
    "### 10.\n",
    "Suppose two of the four firms were to merge. Give a brief\n",
    "intuition for what theory tells us is likely to happen to the equilibrium\n",
    "prices of each good $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8761404a",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "When two firms merge, all prices increase. The mechanism: merged firms internalize competition between their own products.\n",
    "\n",
    "**Pre-merger FOC (firm $f$, product $j$):**\n",
    "$$p_j - mc_j = -\\frac{s_j}{\\partial s_j/\\partial p_j}$$\n",
    "\n",
    "**Post-merger FOC:**\n",
    "$$p_j - mc_j = -\\left[\\frac{\\partial s_j}{\\partial p_j}\\right]^{-1}\\left[s_j + \\sum_{k \\in \\mathcal{J}_f, k \\neq j} \\frac{\\partial s_k}{\\partial p_j}(p_k - mc_k)\\right]$$\n",
    "\n",
    "The additional term $\\sum_{k \\in \\mathcal{J}_f, k \\neq j} \\frac{\\partial s_k}{\\partial p_j}(p_k - mc_k)$ captures recaptured demand: customers who switch from $j$ to the merged firm's product $k$.\n",
    "\n",
    "**Price effects:**\n",
    "\n",
    "1. **Merging firms:** Large increases, proportional to diversion ratios\n",
    "   - Change in markup: $\\Delta \\text{Markup}_j \\approx \\sum_{k \\in \\mathcal{J}_f, k \\neq j} D_{jk}(p_k - mc_k)$\n",
    "   - Where $D_{jk} = -(\\partial s_k/\\partial p_j)/(\\partial s_j/\\partial p_j)$ = fraction of $j$'s lost customers switching to $k$\n",
    "\n",
    "2. **Non-merging firms:** Small increases from strategic complementarity\n",
    "   - Higher competitor prices → shift in residual demand → optimal to raise own prices\n",
    "   - Magnitude depends on cross-elasticities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef269d8",
   "metadata": {},
   "source": [
    "### 11.\n",
    "Suppose firms 1 and 2 are proposing to merge. Use the \\texttt{pyBLP}\n",
    "merger simulation procedure to provide a prediction of the post-merger\n",
    "equilibrium prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0eddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline marginal costs, markups, profits, and consumer surplus under the estimated demand+supply model\n",
    "costs = optimal_iv_results2.compute_costs()\n",
    "markups = optimal_iv_results2.compute_markups(costs=costs)\n",
    "profits = optimal_iv_results2.compute_profits(costs=costs)\n",
    "cs = optimal_iv_results2.compute_consumer_surpluses()\n",
    "\n",
    "# Get pre-merger prices (reshaped as T×J to get average per product)\n",
    "pre_merger_prices = product_data['prices'].values\n",
    "pre_merger_prices_avg = pre_merger_prices.reshape((T, J)).mean(axis=0)\n",
    "\n",
    "# Create merger firm IDs: merge firms 1 and 2 into firm 1\n",
    "# Firms 1 and 2 (satellite) → firm 1\n",
    "# Firms 3 and 4 (wired) remain unchanged\n",
    "merger_firm_ids = product_data['firm_ids'].copy()\n",
    "merger_firm_ids[merger_firm_ids == 2] = 1  # Firm 2 becomes firm 1\n",
    "\n",
    "# Compute post-merger equilibrium prices using pyBLP's compute_prices method\n",
    "# This solves the first-order conditions under the new ownership structure\n",
    "post_merger_prices = optimal_iv_results2.compute_prices(\n",
    "    firm_ids=merger_firm_ids,\n",
    "    iteration=pyblp.Iteration('simple', {'atol': 1e-12})\n",
    ")\n",
    "\n",
    "# Reshape to get average prices per product\n",
    "post_merger_prices_avg = post_merger_prices.reshape((T, J)).mean(axis=0)\n",
    "\n",
    "# Calculate price changes\n",
    "price_changes = post_merger_prices_avg - pre_merger_prices_avg\n",
    "pct_price_changes = (price_changes / pre_merger_prices_avg) * 100\n",
    "\n",
    "merger_results_df = pd.DataFrame({\n",
    "    'Product': product_labels,\n",
    "    'Type': ['Satellite', 'Satellite', 'Wired', 'Wired'],\n",
    "    'Firm (Pre)': [1, 2, 3, 4],\n",
    "    'Firm (Post)': [1, 1, 3, 4],\n",
    "    'Pre-Merger Price': pre_merger_prices_avg,\n",
    "    'Post-Merger Price': post_merger_prices_avg,\n",
    "    'Price Change ($)': price_changes,\n",
    "    'Price Change (%)': pct_price_changes\n",
    "})\n",
    "numeric_columns = ['Pre-Merger Price', 'Post-Merger Price', 'Price Change ($)', 'Price Change (%)']\n",
    "merger_results_df[numeric_columns] = merger_results_df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "# Diagnostics inspired by the post_estimation tutorial\n",
    "post_merger_shares = optimal_iv_results2.compute_shares(post_merger_prices)\n",
    "post_merger_markups = optimal_iv_results2.compute_markups(post_merger_prices, costs)\n",
    "post_merger_profits = optimal_iv_results2.compute_profits(post_merger_prices, post_merger_shares, costs)\n",
    "post_merger_cs = optimal_iv_results2.compute_consumer_surpluses(post_merger_prices)\n",
    "\n",
    "baseline_metrics = {\n",
    "    'Average Price ($)': pre_merger_prices_avg.mean(),\n",
    "    'Average Markup ($)': markups.reshape((T, J)).mean(),\n",
    "    'Total Profit ($)': profits.sum(),\n",
    "    'Average CS ($)': cs.mean(),\n",
    "}\n",
    "post_merger_metrics = {\n",
    "    'Average Price ($)': post_merger_prices_avg.mean(),\n",
    "    'Average Markup ($)': post_merger_markups.reshape((T, J)).mean(),\n",
    "    'Total Profit ($)': post_merger_profits.sum(),\n",
    "    'Average CS ($)': post_merger_cs.mean(),\n",
    "}\n",
    "metric_names = list(baseline_metrics.keys())\n",
    "merger_metric_summary = pd.DataFrame({\n",
    "    'Metric': metric_names,\n",
    "    'Pre-Merger': [baseline_metrics[m] for m in metric_names],\n",
    "    'Post-Merger': [post_merger_metrics[m] for m in metric_names]\n",
    "})\n",
    "merger_metric_summary['Change'] = (\n",
    "    merger_metric_summary['Post-Merger'] - merger_metric_summary['Pre-Merger']\n",
    ")\n",
    "merger_metric_summary = merger_metric_summary.astype({\n",
    "    'Pre-Merger': float,\n",
    "    'Post-Merger': float,\n",
    "    'Change': float\n",
    "})\n",
    "merger_metric_summary = merger_metric_summary.set_index('Metric')\n",
    "IPython.display.display(merger_results_df.style.format({\n",
    "    'Pre-Merger Price': '{:,.4f}'.format,\n",
    "    'Post-Merger Price': '{:,.4f}'.format,\n",
    "    'Price Change ($)': '{:,.4f}'.format,\n",
    "    'Price Change (%)': '{:,.2f}'.format,\n",
    "}))\n",
    "IPython.display.display(merger_metric_summary.style.format('{:,.3f}'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33319f8",
   "metadata": {},
   "source": [
    "### 13. \n",
    "Now suppose instead that firms 1 and 3 are the ones to merge. Re-run the merger\n",
    "simulation. Provide a table comparing the (average across markets) predicted merger-\n",
    "induced price changes for this merger and that in part 11. Interpret the differences\n",
    "between the predictions for the two mergers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8bd1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# QUESTION 13: MERGER SIMULATION (Firms 1 and 3)\n",
    "# ========================================================================\n",
    "# Firm 1 is satellite provider, Firm 3 is wired provider (cross-nest merger)\n",
    "\n",
    "# Note: pre_merger_prices, post_merger_prices, and mean_pct_change_within \n",
    "# already computed in Question 11\n",
    "\n",
    "# Create merger firm IDs: merge firms 1 and 3 into firm 1\n",
    "# Firm 1 (satellite) + Firm 3 (wired) → firm 1\n",
    "# Firms 2 and 4 remain unchanged\n",
    "merger_firm_ids_cross = product_data['firm_ids'].copy()\n",
    "merger_firm_ids_cross[merger_firm_ids_cross == 3] = 1  # Firm 3 becomes firm 1\n",
    "\n",
    "# Compute post-merger equilibrium prices for cross-nest merger\n",
    "post_merger_prices_cross = optimal_iv_results2.compute_prices(\n",
    "    firm_ids=merger_firm_ids_cross,\n",
    "    iteration=pyblp.Iteration('simple', {'atol': 1e-12})\n",
    ")\n",
    "\n",
    "# Reshape and calculate changes\n",
    "post_merger_prices_cross_matrix = post_merger_prices_cross.reshape((T, J))\n",
    "post_merger_prices_cross_avg = post_merger_prices_cross_matrix.mean(axis=0)\n",
    "mean_pct_change_cross = ((post_merger_prices_cross_avg - pre_merger_prices_avg) / pre_merger_prices_avg * 100)\n",
    "\n",
    "merger_results_cross_df = pd.DataFrame({\n",
    "    'Product': product_labels,\n",
    "    'Type': ['Satellite', 'Satellite', 'Wired', 'Wired'],\n",
    "    'Firm (Pre)': [1, 2, 3, 4],\n",
    "    'Firm (Post)': [1, 2, 1, 4],\n",
    "    'Pre-Merger Price': pre_merger_prices_avg,\n",
    "    'Post-Merger Price': post_merger_prices_cross_avg,\n",
    "    'Price Change ($)': post_merger_prices_cross_avg - pre_merger_prices_avg,\n",
    "    'Price Change (%)': mean_pct_change_cross\n",
    "})\n",
    "numeric_columns_cross = ['Pre-Merger Price', 'Post-Merger Price', 'Price Change ($)', 'Price Change (%)']\n",
    "merger_results_cross_df[numeric_columns_cross] = merger_results_cross_df[numeric_columns_cross].apply(pd.to_numeric, errors='coerce')\n",
    "# Diagnostics parallel to the post_estimation tutorial\n",
    "post_merger_shares_cross = optimal_iv_results2.compute_shares(post_merger_prices_cross)\n",
    "post_merger_markups_cross = optimal_iv_results2.compute_markups(post_merger_prices_cross, costs)\n",
    "post_merger_profits_cross = optimal_iv_results2.compute_profits(\n",
    "    post_merger_prices_cross,\n",
    "    post_merger_shares_cross,\n",
    "    costs\n",
    ")\n",
    "post_merger_cs_cross = optimal_iv_results2.compute_consumer_surpluses(post_merger_prices_cross)\n",
    "\n",
    "cross_merger_metrics = {\n",
    "    'Average Price ($)': post_merger_prices_cross_avg.mean(),\n",
    "    'Average Markup ($)': post_merger_markups_cross.reshape((T, J)).mean(),\n",
    "    'Total Profit ($)': post_merger_profits_cross.sum(),\n",
    "    'Average CS ($)': post_merger_cs_cross.mean(),\n",
    "}\n",
    "cross_metric_summary = pd.DataFrame({\n",
    "    'Metric': metric_names,\n",
    "    'Within-Nest (1&2)': [post_merger_metrics[m] for m in metric_names],\n",
    "    'Cross-Nest (1&3)': [cross_merger_metrics[m] for m in metric_names]\n",
    "})\n",
    "cross_metric_summary['Difference (Cross - Within)'] = (\n",
    "    cross_metric_summary['Cross-Nest (1&3)'] - cross_metric_summary['Within-Nest (1&2)']\n",
    ")\n",
    "cross_metric_summary = cross_metric_summary.astype({\n",
    "    'Within-Nest (1&2)': float,\n",
    "    'Cross-Nest (1&3)': float,\n",
    "    'Difference (Cross - Within)': float,\n",
    "})\n",
    "cross_metric_summary = cross_metric_summary.set_index('Metric')\n",
    "\n",
    "IPython.display.display(merger_results_cross_df.style.format({\n",
    "    'Pre-Merger Price': '{:,.4f}'.format,\n",
    "    'Post-Merger Price': '{:,.4f}'.format,\n",
    "    'Price Change ($)': '{:,.4f}'.format,\n",
    "    'Price Change (%)': '{:,.2f}'.format,\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table: Within-nest vs Cross-nest mergers\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Product': product_labels,\n",
    "    'Within-Nest (%)': pct_price_changes,\n",
    "    'Cross-Nest (%)': mean_pct_change_cross,\n",
    "    'Difference (pp)': mean_pct_change_cross - pct_price_changes\n",
    "})\n",
    "comparison_df[['Within-Nest (%)', 'Cross-Nest (%)', 'Difference (pp)']] = comparison_df[['Within-Nest (%)', 'Cross-Nest (%)', 'Difference (pp)']].apply(pd.to_numeric, errors='coerce')\n",
    "IPython.display.display(comparison_df.style.format({\n",
    "    'Within-Nest (%)': '{:,.2f}'.format,\n",
    "    'Cross-Nest (%)': '{:,.2f}'.format,\n",
    "    'Difference (pp)': '{:,.2f}'.format,\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a339013",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========================================================================\n",
    "# PUBLICATION-READY FIGURE: Within-Nest vs Cross-Nest Merger Comparison\n",
    "# Black and White Version\n",
    "# ========================================================================\n",
    "\n",
    "# Set Seaborn style and context\n",
    "sns.set_style(\"whitegrid\", {\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.6,\n",
    "    'grid.color': '#666666',\n",
    "    'grid.alpha': 0.4,\n",
    "    'axes.linewidth': 1.0,\n",
    "    'axes.edgecolor': 'black',\n",
    "})\n",
    "sns.set_context(\"paper\", font_scale=1.15)\n",
    "\n",
    "# Additional matplotlib parameters for publication quality\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],\n",
    "    'figure.dpi': 300,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight',\n",
    "})\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "# Set up bar positions\n",
    "indices = np.arange(len(product_labels))\n",
    "width = 0.35\n",
    "\n",
    "# Black and white colors\n",
    "colors_merger = {\n",
    "    'within': '#000000',  # Black for within-nest\n",
    "    'cross': '#FFFFFF',   # White for cross-nest\n",
    "}\n",
    "\n",
    "# Plot bars with hatching patterns for differentiation\n",
    "bars1 = ax.bar(indices - width/2, pct_price_changes, width, \n",
    "               label='Within-Nest (Firms 1 & 2)', \n",
    "               color=colors_merger['within'], \n",
    "               edgecolor='black', \n",
    "               linewidth=1.5, \n",
    "               alpha=1.0, \n",
    "               zorder=3)\n",
    "\n",
    "bars2 = ax.bar(indices + width/2, mean_pct_change_cross, width, \n",
    "               label='Cross-Nest (Firms 1 & 3)', \n",
    "               color=colors_merger['cross'], \n",
    "               edgecolor='black', \n",
    "               linewidth=1.5, \n",
    "               hatch='///',  # Diagonal hatching pattern\n",
    "               alpha=1.0, \n",
    "               zorder=3)\n",
    "\n",
    "# Horizontal line at zero\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=1.2, zorder=2)\n",
    "\n",
    "# Add value labels with better styling\n",
    "for idx, value in enumerate(pct_price_changes):\n",
    "    if abs(value) > 0.05:  # Only show for non-trivial changes\n",
    "        va = 'bottom' if value >= 0 else 'top'\n",
    "        y_offset = 0.25 if value >= 0 else -0.25\n",
    "        bbox_props = dict(boxstyle='round,pad=0.3', \n",
    "                         facecolor='white', \n",
    "                         edgecolor='black', \n",
    "                         linewidth=1)\n",
    "        ax.text(indices[idx] - width/2, value + y_offset, \n",
    "                f'{value:.2f}%', \n",
    "                ha='center', va=va, \n",
    "                fontsize=9, \n",
    "                fontweight='bold', \n",
    "                color='black', \n",
    "                bbox=bbox_props, \n",
    "                zorder=4)\n",
    "\n",
    "for idx, value in enumerate(mean_pct_change_cross):\n",
    "    if abs(value) > 0.05:\n",
    "        va = 'bottom' if value >= 0 else 'top'\n",
    "        y_offset = 0.25 if value >= 0 else -0.25\n",
    "        bbox_props = dict(boxstyle='round,pad=0.3', \n",
    "                         facecolor='white', \n",
    "                         edgecolor='black', \n",
    "                         linewidth=1)\n",
    "        ax.text(indices[idx] + width/2, value + y_offset, \n",
    "                f'{value:.2f}%', \n",
    "                ha='center', va=va, \n",
    "                fontsize=9, \n",
    "                fontweight='bold', \n",
    "                color='black', \n",
    "                bbox=bbox_props, \n",
    "                zorder=4)\n",
    "\n",
    "# Formatting\n",
    "ax.set_ylabel('Price Change (%)', fontweight='bold', fontsize=13)\n",
    "ax.set_title('Price Effects: Within-Nest vs. Cross-Nest Mergers', \n",
    "             fontweight='bold', pad=20, fontsize=14)\n",
    "ax.set_xticks(indices)\n",
    "ax.set_xticklabels(product_labels, fontweight='semibold')\n",
    "\n",
    "# Legend with Seaborn-friendly styling\n",
    "legend = ax.legend(loc='upper right', \n",
    "                   framealpha=1.0, \n",
    "                   edgecolor='black', \n",
    "                   fancybox=False, \n",
    "                   shadow=False, \n",
    "                   borderpad=1)\n",
    "legend.get_frame().set_linewidth(1.0)\n",
    "legend.get_frame().set_facecolor('white')\n",
    "\n",
    "# Clean up spines\n",
    "sns.despine(ax=ax, top=True, right=True, left=False, bottom=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figures\n",
    "plt.savefig('merger_comparison.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "plt.savefig('merger_comparison.png', format='png', bbox_inches='tight', dpi=300)\n",
    "print('✓ Publication-ready black and white figures saved')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Reset to default style\n",
    "sns.reset_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10724b2",
   "metadata": {},
   "source": [
    "### 14. \n",
    "Thus far you have assumed that there are no efficiencies resulting from the merger.\n",
    "Explain briefly why a merger-specific reduction in marginal cost could mean that a merger\n",
    "is welfare-enhancing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4cb18b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0edffe0",
   "metadata": {},
   "source": [
    "### 15.\n",
    "Consider the merger between firms 1 and 2, and suppose the firms\n",
    "demonstrate that by merging they would reduce marginal cost of each of their\n",
    "products by 15\\%. Furthermore, suppose that they demonstrate that this cost\n",
    "reduction could not be achieved without merging.    Using the \\texttt{pyBLP} software, re-run the merger simulation\n",
    "with the 15\\% cost saving. Show the predicted post-merger price changes (again,\n",
    "for each product, averaged across markets). What is the predicted impact of\n",
    "the merger on consumer welfare,\\footnote{%\n",
    "Note that because we have quasilinear preferences, consumer surplus is a\n",
    "valid measure of aggregate consumer welfare under the usual assumption of\n",
    "optimal redistribution.} assuming that the total measure of consumers $%\n",
    "M_{t} $ is the same in each market  $t$? Explain why this additional assumption\n",
    "(or data on the correct values of $M_{t}$) is needed here, whereas up to\n",
    "this point it was without loss to assume $M_{t}=1$. What is the predicted\n",
    "impact of the merger on total welfare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7003d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume same market size M_t for all markets (needed for welfare calculation)\n",
    "M_t = 1000\n",
    "\n",
    "# Get estimated marginal costs from optimal_iv_results2\n",
    "marginal_costs = optimal_iv_results2.compute_costs()\n",
    "\n",
    "# Create a copy with 15% cost reduction for firms 1 and 2\n",
    "marginal_costs_efficiency = marginal_costs.copy()\n",
    "\n",
    "# Apply 15% reduction (multiply by 0.85) to firms 1 and 2 products\n",
    "# More efficient approach using boolean indexing\n",
    "products_1_2 = product_data['firm_ids'].isin([1, 2])\n",
    "marginal_costs_efficiency[products_1_2] *= 0.85\n",
    "\n",
    "# Use the same merger firm IDs as Question 11\n",
    "# (firm 2 becomes firm 1, already computed earlier as merger_firm_ids)\n",
    "\n",
    "# Compute post-merger prices WITH efficiency gains\n",
    "post_merger_prices_efficiency = optimal_iv_results2.compute_prices(\n",
    "    firm_ids=merger_firm_ids,  # Reuse from Q11\n",
    "    costs=marginal_costs_efficiency,\n",
    "    iteration=pyblp.Iteration('simple', {'atol': 1e-12})\n",
    ")\n",
    "\n",
    "# Reshape and calculate changes\n",
    "post_merger_prices_eff_matrix = post_merger_prices_efficiency.reshape((T, J))\n",
    "post_merger_prices_eff_avg = post_merger_prices_eff_matrix.mean(axis=0)\n",
    "\n",
    "# Calculate price changes relative to pre-merger baseline\n",
    "price_changes_eff = post_merger_prices_eff_avg - pre_merger_prices_avg\n",
    "pct_price_changes_eff = (price_changes_eff / pre_merger_prices_avg) * 100\n",
    "\n",
    "merger_efficiency_df = pd.DataFrame({\n",
    "    'Product': product_labels,\n",
    "    'Type': ['Satellite', 'Satellite', 'Wired', 'Wired'],\n",
    "    'Firm (Pre)': [1, 2, 3, 4],\n",
    "    'Firm (Post)': [1, 1, 3, 4],\n",
    "    'Pre-Merger Price': pre_merger_prices_avg,\n",
    "    'Post-Merger Price': post_merger_prices_eff_avg,\n",
    "    'Price Change ($)': price_changes_eff,\n",
    "    'Price Change (%)': pct_price_changes_eff\n",
    "})\n",
    "numeric_columns_eff = ['Pre-Merger Price', 'Post-Merger Price', 'Price Change ($)', 'Price Change (%)']\n",
    "merger_efficiency_df[numeric_columns_eff] = merger_efficiency_df[numeric_columns_eff].apply(pd.to_numeric, errors='coerce')\n",
    "comparison_eff_df = pd.DataFrame({\n",
    "    'Product': product_labels,\n",
    "    'No Efficiency (%)': pct_price_changes,  # From Q11\n",
    "    'With 15% Cost Cut (%)': pct_price_changes_eff,\n",
    "    'Difference (pp)': pct_price_changes_eff - pct_price_changes\n",
    "})\n",
    "comparison_eff_df[['No Efficiency (%)', 'With 15% Cost Cut (%)', 'Difference (pp)']] = comparison_eff_df[['No Efficiency (%)', 'With 15% Cost Cut (%)', 'Difference (pp)']].apply(pd.to_numeric, errors='coerce')\n",
    "IPython.display.display(merger_efficiency_df.style.format({\n",
    "    'Pre-Merger Price': '{:,.4f}'.format,\n",
    "    'Post-Merger Price': '{:,.4f}'.format,\n",
    "    'Price Change ($)': '{:,.4f}'.format,\n",
    "    'Price Change (%)': '{:,.2f}'.format,\n",
    "}))\n",
    "IPython.display.display(comparison_eff_df.style.format({\n",
    "    'No Efficiency (%)': '{:,.2f}'.format,\n",
    "    'With 15% Cost Cut (%)': '{:,.2f}'.format,\n",
    "    'Difference (pp)': '{:,.2f}'.format,\n",
    "}))\n",
    "\n",
    "post_merger_shares_eff = optimal_iv_results2.compute_shares(post_merger_prices_efficiency)\n",
    "post_merger_markups_eff = optimal_iv_results2.compute_markups(\n",
    "    post_merger_prices_efficiency,\n",
    "    marginal_costs_efficiency\n",
    ")\n",
    "post_merger_profits_eff = optimal_iv_results2.compute_profits(\n",
    "    post_merger_prices_efficiency,\n",
    "    post_merger_shares_eff,\n",
    "    marginal_costs_efficiency\n",
    ")\n",
    "post_merger_cs_eff = optimal_iv_results2.compute_consumer_surpluses(post_merger_prices_efficiency)\n",
    "\n",
    "efficiency_metrics = {\n",
    "    'Average Price ($)': post_merger_prices_eff_avg.mean(),\n",
    "    'Average Markup ($)': post_merger_markups_eff.reshape((T, J)).mean(),\n",
    "    'Total Profit ($)': post_merger_profits_eff.sum(),\n",
    "    'Average CS ($)': post_merger_cs_eff.mean(),\n",
    "}\n",
    "efficiency_metric_summary = pd.DataFrame({\n",
    "    'Metric': metric_names,\n",
    "    'No Efficiency (1&2)': [post_merger_metrics[m] for m in metric_names],\n",
    "    '15% Cost Cut (1&2)': [efficiency_metrics[m] for m in metric_names]\n",
    "})\n",
    "efficiency_metric_summary['Difference (Eff - No Eff)'] = (\n",
    "    efficiency_metric_summary['15% Cost Cut (1&2)'] - efficiency_metric_summary['No Efficiency (1&2)']\n",
    ")\n",
    "efficiency_metric_summary = efficiency_metric_summary.astype({\n",
    "    'No Efficiency (1&2)': float,\n",
    "    '15% Cost Cut (1&2)': float,\n",
    "    'Difference (Eff - No Eff)': float,\n",
    "})\n",
    "efficiency_metric_summary = efficiency_metric_summary.set_index('Metric')\n",
    "\n",
    "IPython.display.display(efficiency_metric_summary.style.format('{:,.3f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8db341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# WELFARE ANALYSIS\n",
    "# ========================================================================\n",
    "\n",
    "# Compute consumer surplus for different scenarios using PyBLP\n",
    "# Pre-merger consumer surplus (baseline)\n",
    "cs_pre = optimal_iv_results2.compute_consumer_surpluses()\n",
    "\n",
    "# Post-merger WITHOUT efficiencies (from Question 11)\n",
    "cs_post_no_eff = optimal_iv_results2.compute_consumer_surpluses(prices=post_merger_prices)\n",
    "\n",
    "# Post-merger WITH 15% cost reduction\n",
    "cs_post_with_eff = optimal_iv_results2.compute_consumer_surpluses(prices=post_merger_prices_efficiency)\n",
    "\n",
    "# Calculate changes in consumer surplus (per consumer, per market)\n",
    "delta_cs_no_eff = cs_post_no_eff - cs_pre\n",
    "delta_cs_with_eff = cs_post_with_eff - cs_pre\n",
    "\n",
    "# Aggregate across all markets and consumers\n",
    "# Total CS change = M_t * sum over all markets\n",
    "total_delta_cs_no_eff = M_t * delta_cs_no_eff.sum()\n",
    "total_delta_cs_with_eff = M_t * delta_cs_with_eff.sum()\n",
    "\n",
    "# Average per consumer across markets\n",
    "avg_delta_cs_no_eff = delta_cs_no_eff.mean()\n",
    "avg_delta_cs_with_eff = delta_cs_with_eff.mean()\n",
    "\n",
    "# Compute producer surplus changes using PyBLP\n",
    "# Producer surplus = (p - mc) × shares × M_t for each product\n",
    "# Pre-merger\n",
    "ps_pre = optimal_iv_results2.compute_profits()\n",
    "\n",
    "# Post-merger without efficiency\n",
    "shares_post_no_eff = optimal_iv_results2.compute_shares(prices=post_merger_prices)\n",
    "ps_post_no_eff = optimal_iv_results2.compute_profits(\n",
    "    prices=post_merger_prices, \n",
    "    shares=shares_post_no_eff, \n",
    "    costs=marginal_costs\n",
    ")\n",
    "\n",
    "# Post-merger with 15% efficiency\n",
    "shares_post_eff = optimal_iv_results2.compute_shares(prices=post_merger_prices_efficiency)\n",
    "ps_post_eff = optimal_iv_results2.compute_profits(\n",
    "    prices=post_merger_prices_efficiency, \n",
    "    shares=shares_post_eff, \n",
    "    costs=marginal_costs_efficiency\n",
    ")\n",
    "\n",
    "# Total PS changes = M_t * sum over all products/markets\n",
    "delta_ps_no_eff = M_t * (ps_post_no_eff - ps_pre).sum()\n",
    "delta_ps_with_eff = M_t * (ps_post_eff - ps_pre).sum()\n",
    "\n",
    "# Total welfare changes\n",
    "delta_w_no_eff = total_delta_cs_no_eff + delta_ps_no_eff\n",
    "delta_w_with_eff = total_delta_cs_with_eff + delta_ps_with_eff\n",
    "\n",
    "welfare_summary = pd.DataFrame({\n",
    "    'Scenario': ['Without efficiency', 'With 15% cost cut'],\n",
    "    'ΔCS total ($)': [total_delta_cs_no_eff, total_delta_cs_with_eff],\n",
    "    'ΔPS ($)': [delta_ps_no_eff, delta_ps_with_eff],\n",
    "    'ΔW ($)': [delta_w_no_eff, delta_w_with_eff],\n",
    "})\n",
    "welfare_summary['Verdict'] = welfare_summary['ΔW ($)'].apply(lambda x: 'ENHANCING' if x >= 0 else 'REDUCING')\n",
    "numeric_columns_welfare = ['ΔCS total ($)', 'ΔPS ($)', 'ΔW ($)']\n",
    "welfare_summary[numeric_columns_welfare] = welfare_summary[numeric_columns_welfare].apply(pd.to_numeric, errors='coerce')\n",
    "welfare_summary = welfare_summary.set_index('Scenario')\n",
    "IPython.display.display(welfare_summary.style.format({\n",
    "    'ΔCS total ($)': '{:,.2f}'.format,\n",
    "    'ΔPS ($)': '{:,.2f}'.format,\n",
    "    'ΔW ($)': '{:,.2f}'.format,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e045c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# ========================================================================\n",
    "# PUBLICATION-READY FIGURE: Surplus Changes by Scenario\n",
    "# Black and White Version with Seaborn\n",
    "# ========================================================================\n",
    "\n",
    "# Set Seaborn style and context\n",
    "sns.set_style(\"whitegrid\", {\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.6,\n",
    "    'grid.color': '#666666',\n",
    "    'grid.alpha': 0.4,\n",
    "    'axes.linewidth': 1.0,\n",
    "    'axes.edgecolor': 'black',\n",
    "})\n",
    "sns.set_context(\"paper\", font_scale=1.15)\n",
    "\n",
    "# Additional matplotlib parameters for publication quality\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],\n",
    "    'figure.dpi': 300,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight',\n",
    "})\n",
    "\n",
    "# Prepare data for publication figure\n",
    "scenarios = ['No Efficiency\\nGains', 'With 15%\\nCost Reduction']\n",
    "delta_cs = [total_delta_cs_no_eff, total_delta_cs_with_eff]\n",
    "delta_ps = [abs(delta_ps_no_eff), abs(delta_ps_with_eff)]  # Take absolute value\n",
    "delta_w = [delta_w_no_eff, delta_w_with_eff]\n",
    "\n",
    "# Create figure with optimal proportions\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "# Set up bar positions\n",
    "x_pos = np.arange(len(scenarios))\n",
    "width = 0.5\n",
    "\n",
    "# Black and white colors with different patterns\n",
    "colors = {\n",
    "    'CS': '#000000',  # Black for consumer surplus\n",
    "    'PS': '#666666',  # Dark gray for producer surplus  \n",
    "    'W': '#CCCCCC',   # Light gray for total welfare (readable!)\n",
    "}\n",
    "\n",
    "# Create stacked bars with hatching patterns for differentiation\n",
    "bars_cs = ax.bar(x_pos, delta_cs, width, \n",
    "                 label='Consumer Surplus (ΔCS)', \n",
    "                 color=colors['CS'], \n",
    "                 edgecolor='black', \n",
    "                 linewidth=1.5, \n",
    "                 alpha=1.0)\n",
    "\n",
    "bars_ps = ax.bar(x_pos, delta_ps, width, \n",
    "                 bottom=delta_cs, \n",
    "                 label='Producer Surplus (ΔPS)', \n",
    "                 color=colors['PS'], \n",
    "                 edgecolor='black', \n",
    "                 linewidth=1.5, \n",
    "                 hatch='///',  # Diagonal hatching\n",
    "                 alpha=1.0)\n",
    "\n",
    "# Add horizontal line at zero with emphasis\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=1.2, zorder=3)\n",
    "\n",
    "# Enhanced value annotations\n",
    "for i, (cs, ps, w) in enumerate(zip(delta_cs, delta_ps, delta_w)):\n",
    "    total_height = cs + ps\n",
    "    \n",
    "    # Component values - only show if segment is large enough\n",
    "    min_size = 4000\n",
    "    \n",
    "    if abs(cs) > min_size:\n",
    "        ax.text(i, cs/2, f'${cs:,.0f}', \n",
    "                ha='center', va='center', \n",
    "                color='white', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    if abs(ps) > min_size:\n",
    "        ax.text(i, cs + ps/2, f'${ps:,.0f}', \n",
    "                ha='center', va='center', \n",
    "                color='white', \n",
    "                fontweight='bold', fontsize=10)\n",
    "    \n",
    "    # Add ΔW annotation to the right of each bar\n",
    "    x_end = i + width/2 + 0.15\n",
    "    y_annotation = total_height\n",
    "    \n",
    "    # Draw connecting line\n",
    "    ax.plot([i, x_end], [total_height, y_annotation], \n",
    "            color='#000000', linewidth=1, linestyle='-', alpha=0.7, zorder=2)\n",
    "    \n",
    "    # Add the ΔW label with light gray background\n",
    "    bbox_props = dict(boxstyle='round,pad=0.5', \n",
    "                     facecolor=colors['W'], \n",
    "                     edgecolor='black', \n",
    "                     linewidth=1.5)\n",
    "    ax.text(x_end + 0.05, y_annotation, f'ΔW = ${w:,.0f}', \n",
    "            ha='left', va='center', \n",
    "            fontweight='bold', fontsize=10, \n",
    "            color='black',  # Black text on light gray\n",
    "            bbox=bbox_props)\n",
    "\n",
    "# Formatting\n",
    "ax.set_ylabel('Aggregate Surplus Change ($)', fontweight='bold', fontsize=13)\n",
    "ax.set_title('Welfare Effects of Merger: Firms 1 & 2', \n",
    "             fontweight='bold', pad=20, fontsize=14)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(scenarios, fontweight='semibold')\n",
    "\n",
    "# Y-axis formatting\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "# Extend x-axis\n",
    "ax.set_xlim(-0.5, len(scenarios) - 0.2)\n",
    "\n",
    "# Legend with patterns\n",
    "legend_elements = [\n",
    "    Patch(facecolor=colors['CS'], edgecolor='black', linewidth=1.5, \n",
    "          label='Change in Consumer Surplus (ΔCS)', alpha=1.0), \n",
    "    Patch(facecolor=colors['PS'], edgecolor='black', linewidth=1.5, \n",
    "          label='Change in Producer Surplus (ΔPS)', hatch='///', alpha=1.0),\n",
    "    Patch(facecolor=colors['W'], edgecolor='black', linewidth=1.5, \n",
    "          label='Change in Total Welfare (ΔW)', alpha=1.0),\n",
    "]\n",
    "\n",
    "legend = ax.legend(handles=legend_elements, loc='upper left', \n",
    "                   framealpha=1.0, edgecolor='black', \n",
    "                   fancybox=False, shadow=False, borderpad=1)\n",
    "legend.get_frame().set_linewidth(1.0)\n",
    "legend.get_frame().set_facecolor('white')\n",
    "\n",
    "# Clean spines\n",
    "sns.despine(ax=ax, top=True, right=True, left=False, bottom=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "plt.savefig('surplus_changes_merger.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "plt.savefig('surplus_changes_merger.png', format='png', bbox_inches='tight', dpi=300)\n",
    "print('✓ Publication-ready black and white figures saved')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Reset to default style\n",
    "sns.reset_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82576351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# Consolidated diagnostics across all merger scenarios\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "scenario_metric_table = pd.DataFrame({\n",
    "    'Metric': metric_names,\n",
    "    'Pre-Merger Baseline': [baseline_metrics[m] for m in metric_names],\n",
    "    'Merger 1&2 (No Eff)': [post_merger_metrics[m] for m in metric_names],\n",
    "    'Merger 1&3 (Cross)': [cross_merger_metrics[m] for m in metric_names],\n",
    "    'Merger 1&2 (15% Cost Cut)': [efficiency_metrics[m] for m in metric_names],\n",
    "})\n",
    "scenario_metric_table['Δ (1&2 - Pre)'] = scenario_metric_table['Merger 1&2 (No Eff)'] - scenario_metric_table['Pre-Merger Baseline']\n",
    "scenario_metric_table['Δ (1&3 - Pre)'] = scenario_metric_table['Merger 1&3 (Cross)'] - scenario_metric_table['Pre-Merger Baseline']\n",
    "scenario_metric_table['Δ (15% Cut - Pre)'] = scenario_metric_table['Merger 1&2 (15% Cost Cut)'] - scenario_metric_table['Pre-Merger Baseline']\n",
    "\n",
    "numeric_columns = scenario_metric_table.select_dtypes(include='number').columns\n",
    "scenario_metric_table[numeric_columns] = scenario_metric_table[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "format_dict = {col: '{:,.3f}'.format for col in numeric_columns}\n",
    "IPython.display.display(scenario_metric_table.style.format(format_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
