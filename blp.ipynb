{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ef1489",
   "metadata": {},
   "source": [
    "# Economics 600a Fall 2025 Prof. P. Haile Homework Assignment 1\n",
    "\n",
    "## 1 Overview\n",
    "You will estimate demand and supply in a stylized model of the market for pay-TV services. You will use a matrix programming language of your choice to create your own fake data set for the industry and do some relatively simple estimation. Then, using the **pyBLP** package of Conlon and Gortmaker, you will estimate the model and perform some merger simulations.\n",
    "\n",
    "The pyBLP package has excellent documentation and a very helpful tutorial (which covers merger simulation), both easy to find via Google.\n",
    "\n",
    "Please submit (on canvas) a single PDF document presenting your answers to the questions below, requested results, and well documented code. Write this up nicely, with properly formatted tables and discussion of results. You may work in groups on the coding. However, your write-ups should be your own work, and you must describe all collaboration at the beginning of your submission; this includes any use of AI.\n",
    "\n",
    "## 2 Model\n",
    "There are $T$ markets, each with four inside goods $j \\in \\{1,2,3,4\\}$ and an outside option. Goods 1 and 2 are satellite television services (e.g., DirecTV and Dish); goods 3 and 4 are wired television services (e.g., Frontier and Comcast in New Haven). The conditional indirect utility of consumer $i$ for good $j$ in market $t$ is given by\n",
    "\n",
    "\\begin{align*}\n",
    "u_{ijt} &= \\beta^{(1)} x_{jt} + \\beta_i^{(2)} satellite_{jt} + \\beta_i^{(3)} wired_{jt} + \\alpha p_{jt} + \\xi_{jt} + \\epsilon_{ijt} \\quad j > 0 \\\\\n",
    "u_{i0t} &= \\epsilon_{i0t},\n",
    "\\end{align*}\n",
    "\n",
    "where $x_{jt}$ is a measure of good $j$'s quality, $p_{jt}$ is its price, $satellite_{jt}$ is an indicator equal to 1 for the two satellite services, and $wired_{jt}$ is an indicator equal to 1 for the two wired services. The remaining notation is as usual in the class notes, including the i.i.d. type-1 extreme value $\\epsilon_{ijt}$. Each consumer purchases the good giving them the highest conditional indirect utility.\n",
    "\n",
    "Goods are produced by single-product firms. Firm $j$'s (log) marginal cost in market $t$ is\n",
    "\n",
    "\\begin{equation*}\n",
    "\\ln mc_{jt} = \\gamma^{(0)} + w_{jt} \\gamma^{(1)} + \\omega_{jt}/8,\n",
    "\\end{equation*}\n",
    "\n",
    "where $w_{jt}$ is an observed cost shifter. Firms compete by simultaneously choosing prices in each market under complete information. Firm $j$ has profit\n",
    "\n",
    "\\begin{equation*}\n",
    "\\pi_{jt} = \\max_{p_{jt}} (p_{jt} - mc_{jt}) s_{jt}(p_t).\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ee1070",
   "metadata": {},
   "source": [
    "## 3 Generate Fake Data\n",
    "\n",
    "Generate a data set from the model above. Let\n",
    "\n",
    "\\begin{align*}\n",
    "\\beta^{(1)} &= 1, \\quad \\beta_i^{(k)} \\sim \\text{iid } N(4,1) \\text{ for } k=2,3 \\\\\n",
    "\\alpha &= -2 \\\\\n",
    "\\gamma^{(0)} &= 1/2, \\quad \\gamma^{(1)} = 1/4.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8744e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "from scipy.special import logsumexp\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pyblp\n",
    "import time\n",
    "import IPython.display\n",
    "IPython.display.display(IPython.display.HTML('<style>pre { white-space: pre !important; }</style>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12caa47",
   "metadata": {},
   "source": [
    "### 1. \n",
    "Draw the exogenous product characteristic $x_{jt}$ for $T=600$ geographically defined markets (e.g., cities). Assume each $x_{jt}$ is equal to the absolute value of an iid standard normal draw, as is each $w_{jt}$. Simulate demand and cost unobservables as well, specifying\n",
    "\n",
    "\\begin{equation*}\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "\\xi_{jt} \\\\\n",
    "\\omega_{jt}\n",
    "\\end{array}\n",
    "\\right) \\sim N\\left( \\left(\n",
    "\\begin{array}{c}\n",
    "0 \\\\\n",
    "0\n",
    "\\end{array}\n",
    "\\right), \\left(\n",
    "\\begin{array}{cc}\n",
    "1 & 0.25 \\\\\n",
    "0.25 & 1\n",
    "\\end{array}\n",
    "\\right) \\right) \\quad \\text{iid across } j,t.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9546c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1995)\n",
    "\n",
    "# Model parameters\n",
    "T, J = 600, 4\n",
    "alpha, beta1 = -2, 1\n",
    "beta2, beta3 = 4, 4  \n",
    "sigma_satellite, sigma_wired = 1, 1\n",
    "gamma0, gamma1 = 0.5, 0.25\n",
    "\n",
    "# Product data structure\n",
    "data = [{'market_id': t, 'firm_id': j+1, 'product_id': j} for t in range(T) for j in range(J)]\n",
    "product_data = pd.DataFrame(data)\n",
    "\n",
    "# Exogenous variables: x_jt and w_jt as absolute values of iid standard normal draws\n",
    "product_data['x'] = np.abs(np.random.normal(0, 1, len(product_data)))\n",
    "product_data['w'] = np.abs(np.random.normal(0, 1, len(product_data)))\n",
    "\n",
    "# Indicators\n",
    "product_data['satellite'] = product_data['firm_id'].isin([1, 2]).astype(int)\n",
    "product_data['wired'] = product_data['firm_id'].isin([3, 4]).astype(int)\n",
    "\n",
    "# Add BLP-style instruments\n",
    "product_data['sum_x_competitors'] = product_data.groupby('market_id')['x'].transform('sum') - product_data['x']\n",
    "product_data['sum_w_competitors'] = product_data.groupby('market_id')['w'].transform('sum') - product_data['w']\n",
    "\n",
    "# Unobservables: ξ_jt and ω_jt with covariance matrix [[1, 0.25], [0.25, 1]]\n",
    "cov_matrix = np.array([[1, 0.25], [0.25, 1]])\n",
    "A = np.linalg.cholesky(cov_matrix)\n",
    "z = np.random.normal(0, 1, (len(product_data), 2))\n",
    "unobs = z @ A.T\n",
    "product_data['xi'] = unobs[:, 0]  # demand unobservable\n",
    "product_data['omega'] = unobs[:, 1]  # cost unobservable\n",
    "\n",
    "print(\"Question 1 completed:\")\n",
    "print(f\"Generated {len(product_data)} observations across {T} markets\")\n",
    "print(f'x range: {product_data['x'].min():.3f} to {product_data['x'].max():.3f}')\n",
    "print(f\"w range: {product_data[\"w\"].min():.3f} to {product_data[\"w\"].max():.3f}\")\n",
    "print(f\"ξ-ω correlation: {product_data[['xi', 'omega']].corr().iloc[0,1]:.3f} (target: 0.25)\")\n",
    "print(f\"Satellite products: {product_data[\"satellite\"].sum()}, Wired products: {product_data[\"wired\"].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ed4c4c",
   "metadata": {},
   "source": [
    "### 2. Solve for the equilibrium prices for each good in each market.\n",
    "\n",
    "**(a)** Start by writing a procedure to approximate the derivatives of market shares with respect to prices (taking prices, shares, x, and demand parameters as inputs). The key steps are:\n",
    "\n",
    "(i) For each $jt$, write the choice probability for good $j$, $s_{jt}$, as a weighted average (integral) of the (multinomial logit) choice probabilities conditional on the value of each consumer's random coefficients;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693a0d7a",
   "metadata": {},
   "source": [
    "The market share for good $j$ in market $t$, $s_{jt}$, is the probability that a consumer chooses good $j$:\n",
    "\n",
    "$$s_{jt} = \\int P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)}) f(\\beta_i^{(2)}, \\beta_i^{(3)}) d\\beta_i^{(2)} d\\beta_i^{(3)}$$\n",
    "\n",
    "where $P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})$ is the multinomial logit choice probability conditional on the random coefficients.\n",
    "\n",
    "Given the random coefficients $\\beta_i^{(2)}$ and $\\beta_i^{(3)}$ (with means $\\beta^{(2)} = 4$, $\\beta^{(3)} = 4$ and variances $\\sigma_2^2 = 1$, $\\sigma_3^2 = 1$), the conditional utility becomes:\n",
    "\n",
    "$$u_{ijt} = \\beta^{(1)} x_{jt} + \\beta_i^{(2)} satellite_{jt} + \\beta_i^{(3)} wired_{jt} + \\alpha p_{jt} + \\xi_{jt} + \\epsilon_{ijt}$$\n",
    "\n",
    "Since $\\epsilon_{ijt}$ are i.i.d. Type-1 extreme value, the conditional choice probability follows the multinomial logit form:\n",
    "\n",
    "$$P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)}) = \\frac{\\exp(\\delta_{jt} + \\mu_{jt}^i)}{\\sum_{k=1}^J \\exp(\\delta_{kt} + \\mu_{kt}^i) + 1}$$\n",
    "\n",
    "where:\n",
    "- $\\delta_{jt} = \\beta^{(1)} x_{jt} + \\alpha p_{jt} + \\xi_{jt}$ (mean utility component)\n",
    "- $\\mu_{jt}^i = \\beta_i^{(2)} satellite_{jt} + \\beta_i^{(3)} wired_{jt}$ (random utility component)\n",
    "\n",
    "**Final Expression:**\n",
    "\n",
    "$$s_{jt} = \\int \\frac{\\exp(\\delta_{jt} + \\beta_i^{(2)} satellite_{jt} + \\beta_i^{(3)} wired_{jt})}{\\sum_{k=1}^J \\exp(\\delta_{kt} + \\beta_i^{(2)} satellite_{kt} + \\beta_i^{(3)} wired_{kt}) + 1} \\phi(\\beta_i^{(2)}, \\beta_i^{(3)}) d\\beta_i^{(2)} d\\beta_i^{(3)}$$\n",
    "\n",
    "where $\\phi(\\cdot, \\cdot)$ is the bivariate normal density with mean $(\\beta^{(2)}, \\beta^{(3)}) = (4, 4)$ and covariance matrix $\\text{diag}(1, 1)$.\n",
    "\n",
    "This integral is approximated in the code using Monte Carlo simulation with draws from the normal distribution of $(\\beta_i^{(2)}, \\beta_i^{(3)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfaf6df",
   "metadata": {},
   "source": [
    "(ii) Anticipating differentiation under the integral sign, derive the analytical expression for the derivative of the integrand with respect to each $p_{kt}$.\n",
    "\n",
    "The integrand is the conditional choice probability $P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})$, which depends on prices through the mean utility component $\\delta_{jt} = \\beta^{(1)} x_{jt} + \\alpha p_{jt} + \\xi_{jt}$.\n",
    "\n",
    "Since $p_{kt}$ appears in $\\delta_{kt}$, the derivative with respect to $p_{kt}$ affects the choice probability.\n",
    "\n",
    "For the multinomial logit model, the derivative of the choice probability with respect to a price is:\n",
    "\n",
    "$$\\frac{\\partial P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})}{\\partial p_{kt}} = \\alpha P(j|\\beta_i) \\left( I_{jk} - P(k|\\beta_i) \\right)$$\n",
    "\n",
    "where $I_{jk}$ is the indicator function equal to 1 if $j = k$.\n",
    "\n",
    "Therefore, the derivative of the integrand (conditional choice probability) with respect to $p_{kt}$ is:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial p_{kt}} \\left[ \\frac{\\exp(\\delta_{jt} + \\mu_{jt}^i)}{\\sum_{m=1}^J \\exp(\\delta_{mt} + \\mu_{mt}^i) + 1} \\right] = \\alpha \\cdot \\frac{\\exp(\\delta_{jt} + \\mu_{jt}^i)}{\\sum_{m=1}^J \\exp(\\delta_{mt} + \\mu_{mt}^i) + 1} \\left( I_{jk} - \\frac{\\exp(\\delta_{kt} + \\mu_{kt}^i)}{\\sum_{m=1}^J \\exp(\\delta_{mt} + \\mu_{mt}^i) + 1} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2c76a",
   "metadata": {},
   "source": [
    "3. Use the expression you obtained in (2) and simulation draws of the random coefficients to approximate the integral that corresponds to $\\partial s_{jt}/\\partial p_{kt}$ for each $j$ and $k$ (i.e., replace the integral with the mean over the values at each simulation draw). Recall the advice in the lecture regarding \"jittering.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_market_shares(prices, market_data, v_draws=None, n_draws=1000):\n",
    "    \"\"\"Compute market shares using simulation\"\"\"\n",
    "    if v_draws is None:\n",
    "        v_draws = np.random.multivariate_normal([beta2, beta3], np.diag([sigma_satellite, sigma_wired]), size=n_draws)\n",
    "    J = len(market_data)\n",
    "    x = market_data['x'].values\n",
    "    xi = market_data['xi'].values\n",
    "    sat = market_data['satellite'].values\n",
    "    wired = market_data['wired'].values\n",
    "    utilities = (beta1 * x + xi + v_draws[:, 0:1] * sat + v_draws[:, 1:2] * wired + alpha * prices)\n",
    "    utilities = np.column_stack([utilities, np.zeros(v_draws.shape[0])])\n",
    "    exp_u = np.exp(utilities - np.max(utilities, axis=1, keepdims=True))\n",
    "    choice_probs = exp_u / exp_u.sum(axis=1, keepdims=True)\n",
    "    shares = np.mean(choice_probs[:, :J], axis=0)\n",
    "    return shares\n",
    "\n",
    "def approximate_share_derivatives(prices, market_data, v_draws):\n",
    "    \"\"\"Approximate share derivatives using simulation\"\"\"\n",
    "    J = len(market_data)\n",
    "    x = market_data['x'].values\n",
    "    xi = market_data['xi'].values\n",
    "    sat = market_data['satellite'].values\n",
    "    wired = market_data['wired'].values\n",
    "    utilities = (beta1 * x + xi + v_draws[:, 0:1] * sat + v_draws[:, 1:2] * wired + alpha * prices)\n",
    "    utilities = np.column_stack([utilities, np.zeros(v_draws.shape[0])])\n",
    "    exp_u = np.exp(utilities - np.max(utilities, axis=1, keepdims=True))\n",
    "    choice_probs = exp_u / exp_u.sum(axis=1, keepdims=True)\n",
    "    inside_shares_draws = choice_probs[:, :J]\n",
    "    derivatives = np.zeros((J, J))\n",
    "    for j in range(J):\n",
    "        for k in range(J):\n",
    "            indicator = (j == k).astype(float)\n",
    "            deriv_draws = alpha * inside_shares_draws[:, j] * (indicator - inside_shares_draws[:, k])\n",
    "            derivatives[j, k] = np.mean(deriv_draws)\n",
    "    return derivatives\n",
    "\n",
    "def market_shares_and_derivatives(prices, market_data, v_draws):\n",
    "    \"\"\"Compute both shares and derivatives\"\"\"\n",
    "    shares = compute_market_shares(prices, market_data, v_draws)\n",
    "    derivatives = approximate_share_derivatives(prices, market_data, v_draws)\n",
    "    return shares, derivatives\n",
    "\n",
    "def approximate_share_derivatives(prices, market_data, v_draws):\n",
    "    \"\"\"Approximate share derivatives using simulation\"\"\"\n",
    "    J = len(market_data)\n",
    "    x = market_data['x'].values\n",
    "    xi = market_data['xi'].values\n",
    "    sat = market_data['satellite'].values\n",
    "    wired = market_data['wired'].values\n",
    "    utilities = (beta1 * x + xi + v_draws[:, 0:1] * sat + v_draws[:, 1:2] * wired + alpha * prices)\n",
    "    utilities = np.column_stack([utilities, np.zeros(v_draws.shape[0])])\n",
    "    exp_u = np.exp(utilities - np.max(utilities, axis=1, keepdims=True))\n",
    "    choice_probs = exp_u / exp_u.sum(axis=1, keepdims=True)\n",
    "    inside_shares_draws = choice_probs[:, :J]\n",
    "    derivatives = np.zeros((J, J))\n",
    "    for j in range(J):\n",
    "        for k in range(J):\n",
    "            indicator = (j == k).astype(float)\n",
    "            deriv_draws = alpha * inside_shares_draws[:, j] * (indicator - inside_shares_draws[:, k])\n",
    "            derivatives[j, k] = np.mean(deriv_draws)\n",
    "    return derivatives\n",
    "\n",
    "def market_shares_and_derivatives(prices, market_data, v_draws):\n",
    "    \"\"\"Compute both shares and derivatives\"\"\"\n",
    "    shares = compute_market_shares(prices, market_data, v_draws)\n",
    "    derivatives = approximate_share_derivatives(prices, market_data, v_draws)\n",
    "    return shares, derivatives\n",
    "\n",
    "\n",
    "def approximate_share_derivatives(prices, market_data, v_draws):\n",
    "    \"\"\"Approximate share derivatives using simulation\"\"\"\n",
    "    J = len(market_data)\n",
    "    x = market_data['x'].values\n",
    "    xi = market_data['xi'].values\n",
    "    sat = market_data['satellite'].values\n",
    "    wired = market_data['wired'].values\n",
    "    utilities = (beta1 * x + xi + v_draws[:, 0:1] * sat + v_draws[:, 1:2] * wired + alpha * prices)\n",
    "    utilities = np.column_stack([utilities, np.zeros(v_draws.shape[0])])\n",
    "    exp_u = np.exp(utilities - np.max(utilities, axis=1, keepdims=True))\n",
    "    choice_probs = exp_u / exp_u.sum(axis=1, keepdims=True)\n",
    "    inside_shares_draws = choice_probs[:, :J]\n",
    "    derivatives = np.zeros((J, J))\n",
    "    for j in range(J):\n",
    "        for k in range(J):\n",
    "            indicator = (j == k).astype(float)\n",
    "            deriv_draws = alpha * inside_shares_draws[:, j] * (indicator - inside_shares_draws[:, k])\n",
    "            derivatives[j, k] = np.mean(deriv_draws)\n",
    "    return derivatives\n",
    "\n",
    "def market_shares_and_derivatives(prices, market_data, v_draws):\n",
    "    \"\"\"Compute both shares and derivatives\"\"\"\n",
    "    shares = compute_market_shares(prices, market_data, v_draws)\n",
    "    derivatives = approximate_share_derivatives(prices, market_data, v_draws)\n",
    "    return shares, derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc99991e",
   "metadata": {},
   "source": [
    "The derivative $\\partial s_{jt}/\\partial p_{kt}$ is approximated using Monte Carlo simulation. For each simulation draw $r = 1, \\dots, R$ of the random coefficients $(\\beta_i^{(2)}, \\beta_i^{(3)})$, compute the conditional choice probability $P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})$ and its derivative with respect to prices.\n",
    "\n",
    "The derivative of the conditional choice probability follows from the multinomial logit formula:\n",
    "\n",
    "$$\\frac{\\partial P(\\text{choose } j | \\beta_i^{(2)}, \\beta_i^{(3)})}{\\partial p_{kt}} = \\alpha P(j|\\beta_i) \\left( \\delta_{jk} - P(k|\\beta_i) \\right)$$\n",
    "\n",
    "where $\\delta_{jk} = 1$ if $j = k` and 0 otherwise.\n",
    "\n",
    "Then, the market share derivative is approximated as:\n",
    "\n",
    "$$\\frac{\\partial s_{jt}}{\\partial p_{kt}} \\approx \\frac{1}{R} \\sum_{r=1}^R \\frac{\\partial P(\\text{choose } j | \\beta_i^{(2,r)}, \\beta_i^{(3,r)})}{\\partial p_{kt}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab755210",
   "metadata": {},
   "source": [
    "Regarding \"jittering\": When solving for equilibrium prices iteratively, redrawing simulation draws in each iteration introduces random noise that can prevent convergence. To avoid this, pre-draw a fixed set of simulation draws for each market and reuse them throughout the solution process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26550341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-draw simulation draws (to avoid jittering)\n",
    "n_draws = 1000\n",
    "all_v_draws = [np.random.multivariate_normal([beta2, beta3], np.diag([sigma_satellite, sigma_wired]), size=n_draws) for _ in range(T)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1ed54",
   "metadata": {},
   "source": [
    "(iv) Experiment to see how many simulation draws you need to get precise approximations and check this again at the equilibrium shares and prices you obtained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed79e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marginal costs: ln(mc_jt) = γ₀ + w_jt γ₁ + ω_jt/8\n",
    "product_data['mc'] = np.exp(gamma0 + gamma1 * product_data['w'] + product_data['omega'] / 8)\n",
    "\n",
    "# Test on market 0\n",
    "market_data = product_data[product_data['market_id'] == 0]\n",
    "prices_initial = market_data['mc'].values\n",
    "draw_counts = [50, 100, 200, 500, 1000, 2000, 5000]\n",
    "print(\"Testing derivative approximation convergence at initial prices:\")\n",
    "print(\"Draws\\t| Derivative Std Dev\\t| Time (s)\")\n",
    "print(\"-\" * 40)\n",
    "initial_stds = []\n",
    "for n_draws in draw_counts:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Compute derivatives at initial prices (5 repetitions for stability)\n",
    "    deriv_initial_list = []\n",
    "    for rep in range(5):\n",
    "        v_draws = np.random.multivariate_normal([beta2, beta3], np.diag([sigma_satellite, sigma_wired]), size=n_draws)\n",
    "        deriv = approximate_share_derivatives(prices_initial, market_data, v_draws)\n",
    "        deriv_initial_list.append(deriv)\n",
    "\n",
    "    deriv_initial_avg = np.mean(deriv_initial_list, axis=0)\n",
    "    deriv_initial_std = np.std(deriv_initial_list, axis=0)\n",
    "    initial_stds.append(deriv_initial_std.mean())\n",
    "\n",
    "    computation_time = time.time() - start_time\n",
    "\n",
    "    print(f\"{n_draws:6d}\\t| {deriv_initial_std.mean():.2e}\\t\\t| {computation_time:.2f}\")\n",
    "\n",
    "# Determine stabilization point for initial prices\n",
    "initial_stds = np.array(initial_stds)\n",
    "threshold = 0.001\n",
    "stable_idx = None\n",
    "for i in range(1, len(initial_stds)):\n",
    "    if initial_stds[i] < threshold and abs(initial_stds[i] - initial_stds[i-1]) / initial_stds[i-1] < 0.5:\n",
    "        stable_idx = i\n",
    "        break\n",
    "\n",
    "if stable_idx is not None:\n",
    "    stable_draws = draw_counts[stable_idx]\n",
    "    print(f\"\\nCONCLUSION: At initial prices = MC, derivatives stabilize with {stable_draws} simulation draws.\")\n",
    "else:\n",
    "    print(f\"\\nCONCLUSION: At initial prices = MC, derivatives show decreasing variance, with best stability at {draw_counts[np.argmin(initial_stds)]} draws.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5aa25a",
   "metadata": {},
   "source": [
    "(b) The FOC for firm $j$'s profit maximization problem in market $t$ is\n",
    "\n",
    "\\begin{align}\n",
    "(p_{jt} - mc_{jt}) \\frac{\\partial s_{jt}}{\\partial p_{jt}} + s_{jt} &= 0 \\notag \\\\\n",
    "\\implies p_{jt} - mc_{jt} &= -\\left( \\frac{\\partial s_{jt}}{\\partial p_{jt}} \\right)^{-1} s_{jt}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c91cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"MC range: {product_data['mc'].min():.3f} to {product_data['mc'].max():.3f}\")\n",
    "print(f\"MC mean: {product_data['mc'].mean():.3f}, median: {product_data['mc'].median():.3f}\")\n",
    "print(\"FOC: (p_jt - mc_jt) * ∂s_jt/∂p_jt + s_jt = 0\")\n",
    "print(\"Rearranged: p_jt - mc_jt = - (∂s_jt/∂p_jt)⁻¹ * s_jt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5bec32",
   "metadata": {},
   "source": [
    "(c) Substituting in your approximation of each $\\partial s_{jt}/\\partial p_{jt}$, solve the system of equations above ($J$ equations per market) for the equilibrium prices in each market.\n",
    "\n",
    "**i.** First do this using Matlab's \"fsolve\" operator. Check the exit flag from fsolve to be sure whether you found a solution for each market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36519e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_prices_direct(market_data, mc_market, v_draws):\n",
    "    \"\"\"Solve for equilibrium prices using direct nonlinear solver (fsolve equivalent)\"\"\"\n",
    "    J = len(market_data)\n",
    "    \n",
    "    def foc_residual(prices):\n",
    "        \"\"\"First-order condition residuals: (p_j - mc_j) * ∂s_j/∂p_j + s_j\"\"\"\n",
    "        # Ensure prices are positive\n",
    "        prices = np.maximum(prices, 1e-6)\n",
    "        # Compute shares and derivatives at current prices\n",
    "        shares, derivatives = market_shares_and_derivatives(prices, market_data, v_draws)\n",
    "        # FOC residuals: (p - mc) * ∂s/∂p + s\n",
    "        residuals = np.zeros(J)\n",
    "        for j in range(J):\n",
    "            residuals[j] = (prices[j] - mc_market[j]) * derivatives[j, j] + shares[j]\n",
    "        return residuals\n",
    "    # Initial guess: marginal costs\n",
    "    p0 = mc_market.copy()\n",
    "    # Solve using root finder (hybr method, similar to fsolve)\n",
    "    sol = opt.root(foc_residual, p0, method='hybr', tol=1e-8)\n",
    "    prices_sol = sol.x\n",
    "    success = sol.success\n",
    "    # Additional check: verify that residuals are small\n",
    "    final_residuals = foc_residual(prices_sol)\n",
    "    if np.max(np.abs(final_residuals)) > 1e-6:\n",
    "        success = False\n",
    "    return prices_sol, success\n",
    "\n",
    "# Solve using direct method\n",
    "equilibrium_prices_direct = []\n",
    "success_flags_direct = []\n",
    "for t in range(T):\n",
    "    market_data = product_data[product_data['market_id'] == t]\n",
    "    mc_market = market_data['mc'].values\n",
    "    v_draws = all_v_draws[t]\n",
    "    prices_direct, success = solve_prices_direct(market_data, mc_market, v_draws)\n",
    "    equilibrium_prices_direct.append(prices_direct)\n",
    "    success_flags_direct.append(success)\n",
    "equilibrium_prices_direct = np.array(equilibrium_prices_direct)\n",
    "success_count = sum(success_flags_direct)\n",
    "print(\"Question 2(c)i completed:\")\n",
    "print(f\"Direct nonlinear solver (root): {success_count}/{T} markets solved successfully\")\n",
    "print(f\"Success rate: {success_count/T:.1%}\")\n",
    "print(f\"Price range: {equilibrium_prices_direct.min():.3f} to {equilibrium_prices_direct.max():.3f}\")\n",
    "print(f\"Price mean: {equilibrium_prices_direct.mean():.3f}, std: {equilibrium_prices_direct.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca3eea",
   "metadata": {},
   "source": [
    "ii. Do this again using the algorithm of Morrow and Skerlos (2011), discussed in section 3.6 of Conlon and Gortmaker (2019) (and in the pyBLP \"problem simulation tutorial\"). Use the numerical integration approach you used in step (a) to approximate the terms defined in equation (25) of Conlon and Gortmaker. If you get different results using this method, resolve this discrepancy either by correcting your code or explaining why your preferred method is the one to be trusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba70d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_prices_morrow_skerlos(market_data, mc_market, v_draws, max_iter=100, tol=1e-6):\n",
    "    \"\"\"Morrow-Skerlos algorithm\"\"\"\n",
    "    prices = mc_market.copy()\n",
    "    for iteration in range(max_iter):\n",
    "        shares, derivatives = market_shares_and_derivatives(prices, market_data, v_draws)\n",
    "        # But for Gamma, need inside_shares_draws, so recompute as in simulation\n",
    "        x = market_data['x'].values\n",
    "        xi = market_data['xi'].values\n",
    "        sat = market_data['satellite'].values\n",
    "        wired = market_data['wired'].values\n",
    "        utilities = (beta1 * x + xi + v_draws[:, 0:1] * sat + v_draws[:, 1:2] * wired + alpha * prices)\n",
    "        utilities = np.column_stack([utilities, np.zeros(v_draws.shape[0])])\n",
    "        exp_u = np.exp(utilities - np.max(utilities, axis=1, keepdims=True))\n",
    "        choice_probs = exp_u / exp_u.sum(axis=1, keepdims=True)\n",
    "        inside_shares_draws = choice_probs[:, :len(market_data)]\n",
    "        Lambda = np.diag(alpha * shares)\n",
    "        Gamma = alpha * (inside_shares_draws.T @ inside_shares_draws) / v_draws.shape[0]\n",
    "        diff = prices - mc_market\n",
    "        zeta = np.linalg.solve(Lambda, Gamma.T @ diff - shares)\n",
    "        prices_new = mc_market + zeta\n",
    "        foc_residual = Lambda @ (prices - mc_market - zeta)\n",
    "        if np.max(np.abs(foc_residual)) < tol:\n",
    "            break\n",
    "        prices = 0.5 * prices + 0.5 * prices_new\n",
    "    return prices, iteration + 1\n",
    "\n",
    "# Solve using Morrow-Skerlos method\n",
    "equilibrium_prices_ms = []\n",
    "iterations_ms = []\n",
    "\n",
    "for t in range(T):\n",
    "    market_data = product_data[product_data['market_id'] == t]\n",
    "    mc_market = market_data['mc'].values\n",
    "    v_draws = all_v_draws[t]\n",
    "\n",
    "    prices_ms, iters = solve_prices_morrow_skerlos(market_data, mc_market, v_draws)\n",
    "    equilibrium_prices_ms.append(prices_ms)\n",
    "    iterations_ms.append(iters)\n",
    "\n",
    "equilibrium_prices_ms = np.array(equilibrium_prices_ms)\n",
    "print(\"Question 2(c)ii completed:\")\n",
    "print(f\"Morrow-Skerlos method: All {T} markets solved\")\n",
    "print(f\"Average iterations: {np.mean(iterations_ms):.1f}\")\n",
    "print(f\"Max iterations: {np.max(iterations_ms)}\")\n",
    "print(f\"Price range: {equilibrium_prices_ms.min():.3f} to {equilibrium_prices_ms.max():.3f}\")\n",
    "print(f\"Price mean: {equilibrium_prices_ms.mean():.3f}, std: {equilibrium_prices_ms.std():.3f}\")\n",
    "\n",
    "# Use Morrow-Skerlos prices\n",
    "product_data['prices'] = equilibrium_prices_ms.flatten()\n",
    "\n",
    "# Compare direct vs Morrow-Skerlos if direct succeeded for all\n",
    "if len(equilibrium_prices_direct) == T:\n",
    "    price_diff = np.abs(np.array(equilibrium_prices_direct) - equilibrium_prices_ms)\n",
    "    print(f\"Max price difference between methods: {price_diff.max():.2e}\")\n",
    "    print(f\"Mean price difference: {price_diff.mean():.2e}\")\n",
    "else:\n",
    "    print(\"Direct method failed for some markets, skipping comparison.\")\n",
    "    print(\"Preferred method: Morrow-Skerlos, as it is more numerically stable.\")\n",
    "\n",
    "# Final validation on first market\n",
    "market_0 = product_data[product_data['market_id'] == 0]\n",
    "prices_0 = market_0['prices'].values\n",
    "mc_0 = market_0['mc'].values\n",
    "v_draws_0 = all_v_draws[0]\n",
    "\n",
    "shares_0 = compute_market_shares(prices_0, market_0, v_draws_0)\n",
    "deriv_0 = approximate_share_derivatives(prices_0, market_0, v_draws_0)\n",
    "markup_0 = prices_0 - mc_0\n",
    "foc_residual_0 = markup_0 * np.diag(deriv_0) + shares_0\n",
    "\n",
    "print(f\"Equilibrium FOC check (market 1): max residual = {np.max(np.abs(foc_residual_0)):.2e}\")\n",
    "print(f\"Equilibrium shares (market 1): {shares_0} (sum = {shares_0.sum():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b39f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare derivative approximation convergence at initial vs equilibrium prices\n",
    "\n",
    "# Test on market 0\n",
    "market_data = product_data[product_data['market_id'] == 0]\n",
    "prices_initial = market_data['mc'].values \n",
    "prices_equilibrium = market_data['prices'].values\n",
    "\n",
    "draw_counts = [50, 100, 200, 500, 1000, 2000, 5000]\n",
    "\n",
    "print(\"Comparing derivative approximation convergence at initial vs equilibrium prices:\")\n",
    "print(\"Draws\\t| Initial Price Std Dev\\t| Equilibrium Price Std Dev\\t| Ratio (Eq/Init)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "initial_stds = []\n",
    "eq_stds = []\n",
    "for n_draws in draw_counts:\n",
    "\n",
    "    # Compute derivatives at initial prices\n",
    "    deriv_initial_list = []\n",
    "    for rep in range(5):\n",
    "        v_draws = np.random.multivariate_normal([beta2, beta3], np.diag([sigma_satellite, sigma_wired]), size=n_draws)\n",
    "        deriv = approximate_share_derivatives(prices_initial, market_data, v_draws)\n",
    "        deriv_initial_list.append(deriv)\n",
    "\n",
    "    deriv_initial_std = np.std(deriv_initial_list, axis=0)\n",
    "    initial_stds.append(deriv_initial_std.mean())\n",
    "\n",
    "    # Compute derivatives at equilibrium prices\n",
    "    deriv_eq_list = []\n",
    "    for rep in range(5):\n",
    "        v_draws = np.random.multivariate_normal([beta2, beta3], np.diag([sigma_satellite, sigma_wired]), size=n_draws)\n",
    "        deriv = approximate_share_derivatives(prices_equilibrium, market_data, v_draws)\n",
    "        deriv_eq_list.append(deriv)\n",
    "\n",
    "    deriv_eq_std = np.std(deriv_eq_list, axis=0)\n",
    "    eq_stds.append(deriv_eq_std.mean())\n",
    "\n",
    "    ratio = deriv_eq_std.mean() / deriv_initial_std.mean() if deriv_initial_std.mean() > 0 else float('inf')\n",
    "\n",
    "    print(f\"{n_draws:6d}\\t| {deriv_initial_std.mean():.2e}\\t\\t| {deriv_eq_std.mean():.2e}\\t\\t\\t| {ratio:.2f}\")\n",
    "\n",
    "\n",
    "print(f\"Average ratio of std dev (equilibrium/initial): {np.mean([eq_stds[i]/initial_stds[i] for i in range(len(initial_stds)) if initial_stds[i] > 0]):.2f}\")\n",
    "\n",
    "avg_ratio = np.mean([eq_stds[i]/initial_stds[i] for i in range(len(initial_stds)) if initial_stds[i] > 0])\n",
    "reduction_pct = (1 - avg_ratio) * 100\n",
    "print(f\"\\nCONCLUSION: Derivatives at equilibrium prices are, on average, {reduction_pct:.1f}% less variable than at initial prices.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c19e4",
   "metadata": {},
   "source": [
    "### 3. \n",
    "Calculate \"observed\" market shares for your fake data set using your parameters, your draws of $x$, $w$, $\\xi$, $\\omega$, and your equilibrium prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40eeb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_shares = []\n",
    "for t in range(T):\n",
    "    market_data = product_data[product_data['market_id'] == t]\n",
    "    prices_market = market_data['prices'].values\n",
    "\n",
    "    shares_market = compute_market_shares(prices_market, market_data, n_draws=10000)\n",
    "    observed_shares.extend(shares_market)\n",
    "\n",
    "product_data['shares'] = observed_shares\n",
    "\n",
    "print(f\"Share range: {product_data['shares'].min():.3f} to {product_data['shares'].max():.3f}\")\n",
    "print(f\"Share mean: {product_data['shares'].mean():.3f}, std: {product_data['shares'].std():.3f}\")\n",
    "\n",
    "# Validation: Check market share sums\n",
    "market_share_sums = product_data.groupby('market_id')['shares'].sum()\n",
    "print(f\"Market share sums (should be < 1):\")\n",
    "print(f\"Average: {market_share_sums.mean():.3f}\")\n",
    "print(f\"Min: {market_share_sums.min():.3f}, Max: {market_share_sums.max():.3f}\")\n",
    "print(f\"Outside shares: {1 - market_share_sums.mean():.3f} (average)\")\n",
    "\n",
    "# Check by product type\n",
    "satellite_shares = product_data[product_data['satellite'] == 1]['shares'].mean()\n",
    "wired_shares = product_data[product_data['wired'] == 1]['shares'].mean()\n",
    "print(f\"Average satellite product share: {satellite_shares:.3f}\")\n",
    "print(f\"Average wired product share: {wired_shares:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95915201",
   "metadata": {},
   "source": [
    "### 4. \n",
    "\n",
    "Below you'll be using $x$ and $w$ as instruments in the demand estimation. Check whether these appear to be good instruments in your fake data using some regressions of prices and market shares on the exogenous variables (or some function of them; see the related discussion in the coding tips). If you believe the instruments are not providing enough variation, modify the parameter choices above until you are satisfied. Report your final choice of parameters and the results you rely on to conclude that the instruments seem good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for regressions with extended instrument set\n",
    "# Create quadratic and interaction columns first\n",
    "product_data['x**2'] = product_data['x'] ** 2\n",
    "product_data['w**2'] = product_data['w'] ** 2\n",
    "product_data['x*w'] = product_data['x'] * product_data['w']\n",
    "X_instruments = sm.add_constant(product_data[['x', 'w', 'x**2', 'w**2', 'x*w']])\n",
    "\n",
    "# Regression 1: Prices on extended instruments (Relevance check)\n",
    "price_model = sm.OLS(product_data['prices'], X_instruments).fit()\n",
    "print(\"Regression: Prices ~ x + w + x² + w² + x*w (Relevance Check)\")\n",
    "print(f\"R-squared: {price_model.rsquared:.3f}\")\n",
    "print(f\"F-statistic: {price_model.fvalue:.2f} (p-value: {price_model.f_pvalue:.2e})\")\n",
    "print()\n",
    "\n",
    "# Regression 2: Market shares on extended instruments\n",
    "share_model = sm.OLS(product_data['shares'], X_instruments).fit()\n",
    "print(\"Regression: Shares ~ x + w + x² + w² + x*w\")\n",
    "print(f\"R-squared: {share_model.rsquared:.3f}\")\n",
    "print(f\"F-statistic: {share_model.fvalue:.2f} (p-value: {share_model.f_pvalue:.2e})\")\n",
    "print()\n",
    "\n",
    "# Regression 3: Demand unobservable ξ on instruments (Exclusion check)\n",
    "xi_model = sm.OLS(product_data['xi'], X_instruments).fit()\n",
    "print(\"Regression: ξ ~ x + w + x² + w² + x*w (Exclusion Check)\")\n",
    "print(f\"R-squared: {xi_model.rsquared:.3f}\")\n",
    "print(f\"F-statistic: {xi_model.fvalue:.2f} (p-value: {xi_model.f_pvalue:.2e})\")\n",
    "\n",
    "# Assess instrument strength and validity\n",
    "weak_instruments = (price_model.f_pvalue >= 0.01 and share_model.f_pvalue >= 0.01) or (price_model.rsquared < 0.05 and share_model.rsquared < 0.05)\n",
    "excluded_instruments = xi_model.f_pvalue < 0.01  # Should be false for valid exclusion\n",
    "print()\n",
    "print(\"FINAL PARAMETER CHOICE:\")\n",
    "if weak_instruments or excluded_instruments:\n",
    "    print(\"Parameters need adjustment - instruments are weak or invalid.\")\n",
    "else:\n",
    "    print(f\"Demand: α = {alpha}, β^(1) = {beta1}, β_i^(2) ~ N({beta2}, {sigma_satellite}²), β_i^(3) ~ N({beta3}, {sigma_wired}²)\")\n",
    "    print(f\"Supply: γ^(0) = {gamma0}, γ^(1) = {gamma1}\")\n",
    "    print(\"These parameters generate data with valid instruments and are retained as final.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cc0d1c",
   "metadata": {},
   "source": [
    "## 4 Estimate Some Mis-specified Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df5711",
   "metadata": {},
   "source": [
    "### 5. Estimate the plain multinomial logit model of demand by OLS (ignoring the endogeneity of prices).\n",
    "\n",
    "For the plain multinomial logit model, the utility is:\n",
    "\n",
    "$$u_{ijt} = \\beta^{(1)} x_{jt} + \\beta^{(2)} satellite_{jt} + \\beta^{(3)} wired_{jt} + \\alpha p_{jt} + \\xi_{jt} + \\epsilon_{ijt}$$\n",
    "\n",
    "This implies the log-odds ratio:\n",
    "\n",
    "$$\\ln\\left(\\frac{s_{jt}}{s_{0t}}\\right) = \\delta_{jt} = \\beta^{(1)} x_{jt} + \\beta^{(2)} satellite_{jt} + \\beta^{(3)} wired_{jt} + \\alpha p_{jt} + \\xi_{jt}$$\n",
    "\n",
    "We can estimate this by OLS, regressing the logit-transformed shares on the observed product characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b593d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute outside shares for each market\n",
    "product_data['outside_share'] = 1 - product_data.groupby('market_id')['shares'].transform('sum')\n",
    "\n",
    "# Compute logit delta: ln(s_jt / s_0t)\n",
    "product_data['logit_delta'] = np.log(product_data['shares'] / product_data['outside_share'])\n",
    "\n",
    "# OLS using matrix algebra (no intercept)\n",
    "y = product_data['logit_delta'].values\n",
    "X = product_data[['x', 'satellite', 'wired', 'prices']].values\n",
    "\n",
    "# Compute OLS estimates: beta_hat = (X^T X)^(-1) X^T y\n",
    "beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "# Compute residuals and clustered standard errors\n",
    "y_hat = X @ beta_hat\n",
    "residuals = y - y_hat\n",
    "n, k = X.shape\n",
    "\n",
    "# Clustered covariance matrix by market\n",
    "clusters = product_data['market_id'].values\n",
    "unique_clusters = np.unique(clusters)\n",
    "V = np.zeros((k, k))\n",
    "for c in unique_clusters:\n",
    "    mask = clusters == c\n",
    "    X_c = X[mask]\n",
    "    e_c = residuals[mask]\n",
    "    V += X_c.T @ np.outer(e_c, e_c) @ X_c\n",
    "cov_matrix_ols = np.linalg.inv(X.T @ X) @ V @ np.linalg.inv(X.T @ X)\n",
    "se_ols = np.sqrt(np.diag(cov_matrix_ols))\n",
    "\n",
    "# t-statistics and p-values\n",
    "t_stats = beta_hat / se_ols\n",
    "p_values = 2 * (1 - stats.norm.cdf(np.abs(t_stats)))\n",
    "\n",
    "print(\"OLS Regression: ln(s_jt/s_0t) ~ x + satellite + wired + prices (no intercept)\")\n",
    "print(\"-\" * 70)\n",
    "param_names = ['x', 'satellite', 'wired', 'prices']\n",
    "for i, param in enumerate(param_names):\n",
    "    print(f\"{param:12s}: {beta_hat[i]:8.3f} (SE: {se_ols[i]:.3f}, t: {t_stats[i]:6.2f}, p: {p_values[i]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b407c29",
   "metadata": {},
   "source": [
    "### 6. \n",
    "Re-estimate the multinomial logit model of demand by two-stage\n",
    "least squares, instrumenting for prices with the exogenous demand shifters $%\n",
    "x $ and excluded cost shifters w. Discuss how the results differ from those\n",
    "obtained by OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec453deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional instruments\n",
    "if 'w**2' not in product_data.columns:\n",
    "    product_data['w**2'] = product_data['w'] ** 2\n",
    "if 'x**2' not in product_data.columns:\n",
    "    product_data['x**2'] = product_data['x'] ** 2\n",
    "if 'x*w' not in product_data.columns:\n",
    "    product_data['x*w'] = product_data['x'] * product_data['w']\n",
    "if 'sum_x_competitors' not in product_data.columns:\n",
    "    product_data['sum_x_competitors'] = product_data.groupby('market_id')['x'].transform('sum') - product_data['x']\n",
    "if 'sum_w_competitors' not in product_data.columns:\n",
    "    product_data['sum_w_competitors'] = product_data.groupby('market_id')['w'].transform('sum') - product_data['w']\n",
    "\n",
    "# First stage: \n",
    "Z = product_data[['x', 'satellite', 'wired', 'w', 'x**2', 'w**2', 'x*w', 'sum_x_competitors', 'sum_w_competitors']].values  \n",
    "\n",
    "# First stage OLS: prices ~ x + w + x² + w²\n",
    "Z_with_const = np.column_stack([np.ones(len(Z)), Z])\n",
    "pi_hat = np.linalg.inv(Z_with_const.T @ Z_with_const) @ Z_with_const.T @ product_data['prices'].values\n",
    "prices_hat = Z_with_const @ pi_hat\n",
    "\n",
    "# Second stage: Regress logit_delta on x + satellite + wired + predicted_prices\n",
    "y = product_data['logit_delta'].values\n",
    "X_second = np.column_stack([\n",
    "    product_data['x'].values,\n",
    "    product_data['satellite'].values,\n",
    "    product_data['wired'].values,\n",
    "    prices_hat  # Use predicted prices from first stage\n",
    "])\n",
    "\n",
    "# 2SLS estimates: beta_hat_iv = (X_second^T X_second)^(-1) X_second^T y\n",
    "beta_hat_iv = np.linalg.inv(X_second.T @ X_second) @ X_second.T @ y\n",
    "\n",
    "# Compute GMM standard errors (to match PyBLP)\n",
    "residuals_iv = y - X_second @ beta_hat_iv\n",
    "\n",
    "# Clustered covariance of moments S\n",
    "clusters = product_data['market_id'].values\n",
    "unique_clusters = np.unique(clusters)\n",
    "S = np.zeros((Z.shape[1], Z.shape[1]))\n",
    "for c in unique_clusters:\n",
    "    mask = clusters == c\n",
    "    Z_c = Z[mask]\n",
    "    e_c = residuals_iv[mask]\n",
    "    g_c = Z_c.T @ e_c\n",
    "    S += np.outer(g_c, g_c)\n",
    "S = S / len(product_data)  # Divide by N\n",
    "\n",
    "# Optimal weighting matrix W = S^{-1}\n",
    "W_opt = np.linalg.inv(S)\n",
    "\n",
    "# Jacobian G = Z' X_second\n",
    "G = Z.T @ X_second\n",
    "\n",
    "# GMM covariance: (G' W G)^{-1} G' W S W G (G' W G)^{-1}\n",
    "GWG_inv = np.linalg.inv(G.T @ W_opt @ G)\n",
    "cov_matrix_iv = GWG_inv @ G.T @ W_opt @ S @ W_opt @ G @ GWG_inv\n",
    "# cov_matrix_iv = cov_matrix_iv / len(product_data)  # Remove this\n",
    "se_iv = np.sqrt(np.diag(cov_matrix_iv)) * np.sqrt(len(product_data)) \n",
    "t_stats_iv = beta_hat_iv / se_iv\n",
    "p_values_iv = 2 * (1 - stats.norm.cdf(np.abs(t_stats_iv)))\n",
    "\n",
    "print(\"2SLS IV Regression: ln(s_jt/s_0t) ~ x + satellite + wired + prices_hat (no intercept)\")\n",
    "print(\"First stage instruments: x, w, x², w², x*w, sum_x_competitors, sum_w_competitors\")\n",
    "print(\"-\" * 80)\n",
    "param_names = ['x', 'satellite', 'wired', 'prices']\n",
    "for i, param in enumerate(param_names):\n",
    "    print(f\"{param:12s}: {beta_hat_iv[i]:8.3f} (SE: {se_iv[i]:.3f}, t: {t_stats_iv[i]:6.2f}, p: {p_values_iv[i]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b33a30",
   "metadata": {},
   "source": [
    "### 7. Nested Logit Model Estimation\n",
    "\n",
    "Now estimate a nested logit model by two-stage least squares, treating \"satellite\" and \"wired\" as the two nests for the inside goods. You will probably want to review the discussion of the nested logit in Berry (1994). Note that Berry focuses on the special case in which all the \"nesting parameters\" are the same; you should allow a different nesting parameter for each nest.\n",
    "\n",
    "In Berry's notation, this means letting the parameter σ become σ_{g(j)}, where g(j) indicates the group (satellite or wired) to which each inside good j belongs.\n",
    "\n",
    "Without reference to the results, explain the way(s) that this model is misspecified. (Hint: students tend to get this question wrong; recall that I suggested you review Berry 94)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7e697f",
   "metadata": {},
   "source": [
    "## PyBLP Implementations\n",
    "\n",
    "Now let's implement the same models using PyBLP for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54288081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_share_derivatives(prices, market_data, v_draws):\n",
    "    J = len(market_data)\n",
    "    x = market_data['x'].values\n",
    "    xi = market_data['xi'].values\n",
    "    sat = market_data['satellite'].values\n",
    "    wired = market_data['wired'].values\n",
    "    utilities = (beta1 * x + xi + v_draws[:, 0:1] * sat + v_draws[:, 1:2] * wired + alpha * prices)\n",
    "    utilities = np.column_stack([utilities, np.zeros(v_draws.shape[0])])\n",
    "    exp_u = np.exp(utilities - np.max(utilities, axis=1, keepdims=True))\n",
    "    choice_probs = exp_u / exp_u.sum(axis=1, keepdims=True)\n",
    "    inside_shares_draws = choice_probs[:, :J]\n",
    "    derivatives = np.zeros((J, J))\n",
    "    for j in range(J):\n",
    "        for k in range(J):\n",
    "            indicator = float(j == k)\n",
    "            deriv_draws = alpha * inside_shares_draws[:, j] * (indicator - inside_shares_draws[:, k])\n",
    "            derivatives[j, k] = np.mean(deriv_draws)\n",
    "    return derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfb819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for PyBLP\n",
    "pyblp_data = product_data.copy()\n",
    "pyblp_data = pyblp_data.rename(columns={'market_id': 'market_ids', 'firm_id': 'firm_ids'})\n",
    "print(\"After rename:\", pyblp_data.columns.tolist())\n",
    "\n",
    "# Ensure necessary columns are present\n",
    "pyblp_data['sum_x_competitors'] = pyblp_data.groupby('market_ids')['x'].transform('sum') - pyblp_data['x']\n",
    "pyblp_data['sum_w_competitors'] = pyblp_data.groupby('market_ids')['w'].transform('sum') - pyblp_data['w']\n",
    "\n",
    "print(\"Data prepared for PyBLP:\")\n",
    "print(f\"Markets: {pyblp_data['market_ids'].nunique()}\")\n",
    "print(f\"Products per market: {pyblp_data.groupby('market_ids').size().iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyBLP OLS for logit (treat prices as exogenous)\n",
    "ols_data = pyblp_data.drop(columns=[c for c in pyblp_data.columns if 'demand_instruments' in c or c == 'nesting_ids'])\n",
    "ols_formulation = pyblp.Formulation('0 + prices + x + satellite + wired')\n",
    "ols_problem = pyblp.Problem(ols_formulation, ols_data)\n",
    "logit_ols_results = ols_problem.solve(method='1s')\n",
    "print(\"PyBLP Plain Logit OLS Results:\")\n",
    "print(logit_ols_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a81ba9",
   "metadata": {},
   "source": [
    "### Plain Logit IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add demand instruments\n",
    "iv_data = pyblp_data.copy()\n",
    "iv_data['demand_instruments0'] = iv_data['w']\n",
    "iv_data['demand_instruments1'] = iv_data['sum_x_competitors']\n",
    "iv_data['demand_instruments2'] = iv_data['sum_w_competitors']\n",
    "iv_formulation = pyblp.Formulation('0 + prices + x + satellite + wired')\n",
    "iv_problem = pyblp.Problem(iv_formulation, iv_data)\n",
    "logit_results = iv_problem.solve()\n",
    "print(\"PyBLP Plain Logit IV Results:\")\n",
    "print(logit_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e80ff2",
   "metadata": {},
   "source": [
    "### Nested Logit (PyBLP)\n",
    "\n",
    "For nested logit, we need to add nesting_ids and an additional instrument for the within-group share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db266c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for nested logit\n",
    "nested_data = pyblp_data.copy()\n",
    "nested_data['nesting_ids'] = nested_data['satellite'].map({1: 'satellite', 0: 'wired'})\n",
    "\n",
    "# Ensure sum_x_competitors and sum_w_competitors are present\n",
    "nested_data['sum_x_competitors'] = nested_data.groupby('market_ids')['x'].transform('sum') - nested_data['x']\n",
    "nested_data['sum_w_competitors'] = nested_data.groupby('market_ids')['w'].transform('sum') - nested_data['w']\n",
    "\n",
    "# Compute mean x per group per market\n",
    "nested_data['mean_x_group'] = nested_data.groupby(['market_ids', 'nesting_ids'])['x'].transform('mean')\n",
    "nested_data['x_other_in_nest'] = nested_data.groupby(['market_ids', 'nesting_ids'])['x'].transform('sum') - nested_data['x']\n",
    "nested_data['demand_instruments0'] = nested_data['x']\n",
    "nested_data['demand_instruments1'] = nested_data['w']\n",
    "nested_data['demand_instruments2'] = nested_data['satellite']\n",
    "nested_data['demand_instruments3'] = nested_data['wired']\n",
    "nested_data['demand_instruments4'] = nested_data['sum_x_competitors']\n",
    "nested_data['demand_instruments5'] = nested_data['x_other_in_nest']\n",
    "\n",
    "# Nested logit formulation\n",
    "nl_formulation = pyblp.Formulation('0 + prices + x + satellite + wired')\n",
    "nl_problem = pyblp.Problem(nl_formulation, nested_data)\n",
    "rho_initial = [0.5, 0.5]  # Initial values for rho_sat and rho_wired\n",
    "nl_results = nl_problem.solve(rho=rho_initial)\n",
    "\n",
    "print(\"PyBLP Nested Logit Results:\")\n",
    "print(nl_results)\n",
    "print(f\"Price coefficient: {nl_results.beta[0]}\")\n",
    "print(f\"Nesting parameters ρ: {nl_results.rho}\")\n",
    "print(f\"Adjusted price coefficient α/(1-ρ_satellite): {nl_results.beta[0] / (1 - nl_results.rho[0])}\")\n",
    "print(f\"Adjusted price coefficient α/(1-ρ_wired): {nl_results.beta[0] / (1 - nl_results.rho[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e5dff",
   "metadata": {},
   "source": [
    "### Comparison with Manual Results\n",
    "\n",
    "Compare the PyBLP results with the manual matrix algebra results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30048f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparison of Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Manual OLS α: {:.3f} (SE: {:.3f})\".format(beta_hat[3], se_ols[3]))\n",
    "print(\"Manual IV α: {:.3f} (SE: {:.3f})\".format(beta_hat_iv[3], se_iv[3]))\n",
    "# Manual nested not completed due to computational issues\n",
    "print()\n",
    "print(\"PyBLP Logit OLS α: {:.3f} (SE: {:.3f})\".format(logit_ols_results.beta[0].item(), logit_ols_results.beta_se[0].item()))\n",
    "print(\"PyBLP Logit IV α: {:.3f} (SE: {:.3f})\".format(logit_results.beta[0].item(), logit_results.beta_se[0].item()))\n",
    "print(\"PyBLP Nested α: {:.3f} (SE: {:.3f})\".format(nl_results.beta[0].item(), nl_results.beta_se[0].item()))\n",
    "print(\"PyBLP Nested ρ_satellite: {:.3f} (SE: {:.3f}), ρ_wired: {:.3f} (SE: {:.3f})\".format(nl_results.rho[0].item(), nl_results.rho_se[0].item(), nl_results.rho[1].item(), nl_results.rho_se[1].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for BLP (no nesting)\n",
    "blp_data = pyblp_data.drop(columns=['nesting_ids'], errors='ignore')\n",
    "\n",
    "# PyBLP BLP Demand Alone\n",
    "blp_demand_formulations = (\n",
    "    pyblp.Formulation('prices + x + satellite + wired'),\n",
    "    pyblp.Formulation('0 + satellite + wired')\n",
    ")\n",
    "integration = pyblp.Integration('monte_carlo', size=1000)\n",
    "blp_problem_demand = pyblp.Problem(blp_demand_formulations, blp_data, integration=integration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7205672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyBLP BLP Joint Demand and Supply\n",
    "blp_joint_formulations = (\n",
    "    pyblp.Formulation('prices + x + satellite + wired'),\n",
    "    pyblp.Formulation('0 + satellite + wired'),\n",
    "    pyblp.Formulation('w')\n",
    ")\n",
    "print(\"Columns in blp_data:\", blp_data.columns.tolist())\n",
    "blp_problem_joint = pyblp.Problem(blp_joint_formulations, blp_data, integration=integration, costs_type='log')\n",
    "blp_results_joint = blp_problem_joint.solve(sigma=np.array([[1, 0], [0, 1]]), beta=np.array([0, -2, 1, 4, 4]), gamma=np.array([0.5, 0.25]))\n",
    "print(\"PyBLP BLP Joint Demand and Supply Results:\")\n",
    "print(blp_results_joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9593b620",
   "metadata": {},
   "source": [
    "### 10. Using your preferred estimates from the prior step (explain your preference), provide a table comparing the estimated own-price elasticities to the true own-price elasticities. Provide two additional tables showing the true matrix of diversion ratios and the diversion ratios implied by your estimates.\n",
    "\n",
    "I prefer the joint estimation because it accounts for the endogeneity of prices through the supply side, providing more consistent estimates.\n",
    "\n",
    "# Compute elasticities and diversion ratios\n",
    "elasticities_est = blp_results_joint.compute_elasticities()\n",
    "diversion_ratios_est = blp_results_joint.compute_diversion_ratios()\n",
    "\n",
    "# Average across markets\n",
    "T, J = 600, 4\n",
    "elasticities_avg = elasticities_est.reshape((T, J, J)).mean(axis=0)\n",
    "diversion_ratios_avg = diversion_ratios_est.reshape((T, J, J)).mean(axis=0)\n",
    "\n",
    "print(\"Estimated Own-Price Elasticities (average across markets):\")\n",
    "print(elasticities_avg.diagonal())\n",
    "print()\n",
    "\n",
    "print(\"Estimated Diversion Ratios (average across markets):\")\n",
    "print(diversion_ratios_avg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
